<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: theory - s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">theory</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-09T13:28:54.000Z" title="2023-11-9 2:28:54 ├F10: PM┤">2023-11-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-09T17:58:09.122Z" title="2023-11-9 6:58:09 ├F10: PM┤">2023-11-09</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a minute read (About 185 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/09/pai4/">Probabilistic Artificial Intelligence - Bayesian Deep Learning</a></p><div class="content"><h2><span id="swagstochastic-weight-averaging-gaussian">SWAG(Stochastic Weight Averaging Gaussian)</span></h2><p>This paper proposes a different approach to Bayesian deep learning: they use the information contained in the SGD trajectory to efficiently approximate the posterior distribution over the weights of the neural network [1].</p>
<h3><span id="swa">SWA</span></h3><p>This paper shows that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training [2].</p>
<h3><span id="cyclical-learning-rate-schedule">cyclical learning rate schedule</span></h3><h2><span id="calibration-of-modern-neural-networks">Calibration of Modern Neural Networks</span></h2><p>Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration.</p>
<h2><span id="references">references</span></h2><p>[1] Maddox W J, Izmailov P, Garipov T, et al. A simple baseline for bayesian uncertainty in deep learning[J]. Advances in neural information processing systems, 2019, 32.<br>[2] Izmailov P, Podoprikhin D, Garipov T, et al. Averaging weights leads to wider optima and better generalization[J]. arXiv preprint arXiv:1803.05407, 2018.<br>[3] Guo C, Pleiss G, Sun Y, et al. On calibration of modern neural networks[C]//International conference on machine learning. PMLR, 2017: 1321-1330.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-10-27T09:00:34.000Z" title="2023-10-27 11:00:34 ├F10: AM┤">2023-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-21T11:20:27.846Z" title="2024-2-21 12:20:27 ├F10: PM┤">2024-02-21</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">3 minutes read (About 426 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/10/27/pai3/">Probabilistic Artificial Intelligence - Markov Chain Monte Carlo Methods</a></p><div class="content"><h1><span id="markov-chain-monte-carlo-methods">Markov Chain Monte Carlo Methods</span></h1><p>The key idea of Markov chain Monte Carlo methods is to construct a Markov chain, which is efficient to simulate and has the stationary distribution p.</p>
<h2><span id="markov-chains">Markov Chains</span></h2><p><img src="/2023/10/27/pai3/image-21.png" alt="Alt text"></p>
<p>Intuitively, the Markov property states that future behavior is independent of past states given the present state.</p>
<p>Markov chains can be classified into different types based on their behavior. These classifications include time-homogeneous and time-inhomogeneous Markov chains, irreducible Markov chains, and periodic and aperiodic Markov chains.</p>
<p>We restrict our attention to time-homogeneous Markov chains. That is, the transition probabilities do not change over time, which can be characterized by a transition function.</p>
<p>Irreducible Markov chains are those in which every state can be reached from any other state, while periodic Markov chains exhibit a repeating pattern in their states. On the other hand, aperiodic Markov chains do not exhibit any regular pattern in their states. If there is no fixed period at which the probabilities return to the starting values, the chain is classified as aperiodic. Aperiodic Markov chains often display a more complex and unpredictable behavior compared to periodic ones.</p>
<h3><span id="stationarity">Stationarity</span></h3><p><img src="/2023/10/27/pai3/image-22.png" alt="Alt text"></p>
<p><img src="/2023/10/27/pai3/image-23.png" alt="Alt text"></p>
<h3><span id="convergence">Convergence</span></h3><p><img src="/2023/10/27/pai3/image-24.png" alt="Alt text"></p>
<p><img src="/2023/10/27/pai3/image-25.png" alt="Alt text"></p>
<p><img src="/2023/10/27/pai3/image-26.png" alt="Alt text"></p>
<p>A Markov Chain is called ergodic, if there exists a finite t such that every state can be reached from every state in exactly t steps.</p>
<h4><span id="fundamental-theorem-of-ergodic-markov-chains">Fundamental theorem of ergodic Markov chains</span></h4><p><img src="/2023/10/27/pai3/image-112.png" alt="Alt text"></p>
<h3><span id="detailed-balance-equation">Detailed Balance Equation</span></h3><p><img src="/2023/10/27/pai3/image-113.png" alt="Alt text"></p>
<h3><span id="ergodic-theorem">Ergodic Theorem</span></h3><p><img src="/2023/10/27/pai3/image-114.png" alt="Alt text"></p>
<p>This result is the fundamental reason for why Markov chain Monte Carlo methods are possible. In practice, one observes that Markov chain Monte Carlo methods have a so-called “burn-in” time during which the distribution of the Markov chain does not yet approximate the posterior distribution well. Typically, the first t0 samples are therefore discarded. It is not clear in general how T and t0 should be chosen such that the estimator is unbiased, rather they have to be tuned. </p>
<h2><span id="elementary-sampling-methods">Elementary Sampling Methods</span></h2><h3><span id="metropolis-hastings-algorithm">Metropolis-Hastings Algorithm</span></h3><p><img src="/2023/10/27/pai3/image-115.png" alt="Alt text"></p>
<h3><span id="gibbs-sampling">Gibbs Sampling</span></h3><p>A popular example of a Metropolis-Hastings algorithm is Gibbs sampling. </p>
<p><img src="/2023/10/27/pai3/image-116.png" alt="Alt text"></p>
<p>Intuitively, by re-sampling single coordinates according to the posterior distribution given the other coordinates, Gibbs sampling finds states that are successively “more” likely.</p>
<h2><span id="langevin-dynamics">Langevin Dynamics</span></h2><h3><span id="gibbs-distributions">Gibbs Distributions</span></h3><h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://www.collimator.ai/reference-guides/what-is-a-aperiodic-markov-chain">https://www.collimator.ai/reference-guides/what-is-a-aperiodic-markov-chain</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-10-20T08:17:16.000Z" title="2023-10-20 10:17:16 ├F10: AM┤">2023-10-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-02-21T11:20:32.124Z" title="2024-2-21 12:20:32 ├F10: PM┤">2024-02-21</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">7 minutes read (About 1016 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/10/20/pai2/">Probabilistic Artificial Intelligence - Variational Inference</a></p><div class="content"><h1><span id="variational-inference">Variational Inference</span></h1><p>The fundamental idea behind variational inference is to approximate the true posterior distribution using a “simpler” posterior that is as close as possible to the true posterior.</p>
<script type="math/tex; mode=display">
p(\theta\mid x_{1:n},y_{1:n})=\frac1Zp(\theta,y_{1:n}\mid x_{1:n})\approx q(\theta\mid\lambda)\doteq q_{\lambda}(\theta)</script><p>where λ represents the parameters of the variational posterior q, also called variational parameters.</p>
<h2><span id="laplace-approximation">Laplace Approximation</span></h2><p>A natural idea for approximating the posterior distribution is to use a Gaussian approximation (that is, a second-order Taylor approximation) around the mode of the posterior. Such an approximation is known as a Laplace approximation.</p>
<p>As an example, we will look at Laplace approximation in the context of Bayesian logistic regression. Bayesian logistic regression corresponds to Bayesian linear regression with a Bernoulli likelihood. </p>
<p>Intuitively, the Laplace approximation matches the shape of the true posterior around its mode but may not represent it accurately elsewhere — often leading to extremely overconfident predictions.</p>
<h2><span id="inference-with-a-variational">Inference with a Variational</span></h2><script type="math/tex; mode=display">
\begin{aligned}
p(y^{\star}\mid x^{\star},x_{1:n},y_{1:n})& =\int p(y^\star\mid x^\star,\boldsymbol{\theta})p(\boldsymbol{\theta}\mid x_{1:n},y_{1:n})d\boldsymbol{\theta}  \\
&\approx\int p(y^\star\mid x^\star,\boldsymbol{\theta})q_\lambda(\boldsymbol{\theta})d\boldsymbol{\theta}
&=\int\int p(y^\star\mid f^\star)p(f^\star\mid x^\star,\theta)q_\lambda(\theta)d\theta df^\star\\&=\int p(y^\star\mid f^\star)\int p(f^\star\mid x^\star,\theta)q_\lambda(\theta)d\theta df^\star\\&=\int p(y^\star\mid f^\star)q_\lambda(f^\star\mid x^\star)df^\star.\quad\quad
\end{aligned}</script><h2><span id="information-theory">Information Theory</span></h2><h3><span id="surprise">Surprise</span></h3><p>The surprise about an event with probability u is defined as $S[u] = -log u$.<br><img src="/2023/10/20/pai2/image-1.png" alt="Alt text"></p>
<h3><span id="entropy">Entropy</span></h3><p>The entropy of a distribution p is the average surprise about samples from p.if the entropy of p is large, we are more uncertain about x ∼ p than if the entropy of p were low.</p>
<script type="math/tex; mode=display">
\mathbb{H}[p]\doteq\mathbb{E}_{x\sim p}[\mathbb{S}[p(x)]]=\mathbb{E}_{x\sim p}[-\log p(x)].</script><h3><span id="cross-entropy">Cross-Entropy</span></h3><p><img src="/2023/10/20/pai2/image-2.png" alt="Alt text"><br>Cross-entropy can also be expressed in terms of the KL-divergence. Quite intuitively, the average surprise in samples from p with respect to the distribution q is given by the inherent uncertainty in p and the additional surprise that is due to us assuming the wrong data distribution q. The “closer” q is to the true data distribution p, the smaller is the additional average surprise.</p>
<script type="math/tex; mode=display">
\mathrm{H}[p\|q]=\mathrm{H}[p]+\mathrm{KL}(p\|q)\geq\mathrm{H}[p].</script><h2><span id="variational-families">Variational Families</span></h2><p>We can view variational inference more generally as a family of approaches aiming to approximate the true posterior distribution by one that is closest (according to some criterion) among a “simpler” class of distributions.<br><img src="/2023/10/20/pai2/image-8.png" alt="Alt text"></p>
<h2><span id="kullback-leibler-divergence">Kullback-Leibler Divergence</span></h2><p><img src="/2023/10/20/pai2/image-9.png" alt="Alt text"></p>
<p>In words, KL(p∥q) measures the additional expected surprise when observing samples from p that is due to assuming the (wrong) distribution q and which not inherent in the distribution p already. Intuitively, the KL-divergence measures the information loss when approximating p with q.<br><img src="/2023/10/20/pai2/image-10.png" alt="Alt text"></p>
<h3><span id="forward-and-reverse-kl-divergence">Forward and reverse KL-divergence</span></h3><p>KL(p∥q) is also called the forward (or inclusive) KL-divergence. In contrast, KL(q∥p) is called the reverse (or exclusive) KL-divergence.</p>
<p>It can be seen that the reverse KL-divergence tends to greedily select the mode and underestimating the variance which, in this case, leads to an overconfident prediction. The forward KL-divergence, in contrast, is more conservative and yields what one could consider the “desired” approximation.</p>
<p>The reverse KL-divergence is typically used in practice. This is for computational reasons. In principle, if the variational family Q is “rich enough”, minimizing the forward and reverse KL-divergences will yield the same result.</p>
<p>There is a nice interpretation of minimizing the forward KullbackLeibler divergence of the approximation $q_\lambda$ with respect to the true distribution p as being equivalent to maximizing the marginal model likelihood on a sample of infinite size. This interpretation is not useful in the setting where p is a posterior distribution over model parameters θ as a maximum likelihood estimate requires samples from p which we cannot obtain in this case.</p>
<h4><span id="kl-divergence-of-gaussians">KL-divergence of Gaussians</span></h4><p><img src="/2023/10/20/pai2/image-11.png" alt="Alt text"></p>
<p><img src="/2023/10/20/pai2/image-12.png" alt="Alt text"></p>
<p><img src="/2023/10/20/pai2/image-13.png" alt="Alt text"></p>
<h2><span id="evidence-lower-bound">Evidence Lower Bound</span></h2><p>The Evidence Lower Bound is a quantity maximization of which is equivalent to minimizing the KL-divergence. As its name suggests, the evidence lower bound is a (uniform) lower bound to the log-evidence $log p(y<em>{1:n}|x</em>{1:n})$.<br><img src="/2023/10/20/pai2/image-15.png" alt="Alt text"></p>
<p><img src="/2023/10/20/pai2/image-14.png" alt="Alt text"></p>
<p>Note that this inequality lower bounds the logarithm of an integral by an expectation of a logarithm over some variational distribution q. Hence, the ELBO is a family of lower bounds — one for each variational distribution. Such inequalities are called variational inequalities.</p>
<p><img src="/2023/10/20/pai2/image-16.png" alt="Alt text"></p>
<h3><span id="gradient-of-evidence-lower-bound">Gradient of Evidence Lower Bound</span></h3><p><img src="/2023/10/20/pai2/image-17.png" alt="Alt text"><br>Obtaining the gradient of the evidence lower bound is more difficult. This is because the expectation integrates over the measure $q_\lambda$, which depends on the variational parameters $\lambda$. Thus, we cannot move the gradient operator inside the expectation.</p>
<p>There are two main techniques which are used to rewrite the gradient in such a way that Monte Carlo sampling becomes possible. The first is to use score gradients. The second is the so-called reparameterization trick.</p>
<h4><span id="reparameterization-trick">reparameterization trick</span></h4><p><img src="/2023/10/20/pai2/image-18.png" alt="Alt text"><br><img src="/2023/10/20/pai2/image-19.png" alt="Alt text"></p>
<p><img src="/2023/10/20/pai2/image-20.png" alt="Alt text"></p>
<p>The procedure of approximating the true posterior using a variational posterior by maximizing the evidence lower bound using stochastic optimization is also called black box stochastic variational inference. The only requirement is that we can obtain unbiased gradient estimates from the evidence lower bound (and the likelihood).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-10-13T12:42:15.000Z" title="2023-10-13 2:42:15 ├F10: PM┤">2023-10-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-14T18:45:40.843Z" title="2023-10-14 8:45:40 ├F10: PM┤">2023-10-14</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">8 minutes read (About 1166 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/10/13/pai0/">Probabilistic Artificial Intelligence - Bayesian Linear Regression</a></p><div class="content"><h1><span id="bayesian-linear-regression">Bayesian Linear Regression</span></h1><h2><span id="linear-regression">Linear Regression</span></h2><p>Given a set of (x, y) pairs, linear regression aims to find a linear model that fits the data optimally.<br>Given the linear model $y=w^Tx$, we want to find optimal weights $w$.<br>There are many ways of estimating w from data, the most common being the least squares estimator:</p>
<script type="math/tex; mode=display">
\hat{w}_\mathrm{ls}\doteq\arg\min_{\boldsymbol{w}\in\mathbb{R}^d}\sum_{i=1}^n(y_i-\boldsymbol{w}^\top\boldsymbol{x}_i)^2=\arg\min_{\boldsymbol{w}\in\mathbb{R}^d}\|\boldsymbol{y}-\boldsymbol{X}\boldsymbol{w}\|_2^2,</script><p>A slightly different estimator is used for ridge regression:</p>
<script type="math/tex; mode=display">
\hat{w}_{\mathrm{ridge}}\doteq\arg\min_{w\in\mathbb{R}^d}\|y-Xw\|_2^2+\lambda\|w\|_2^2</script><p>As the formula shows, the squared $l_2$ regularization term $\lambda|w|_2^2$ penalizes large $w$ and thus reduces the complexity of the resulting model,so Ridge regression is more robust than standard linear regression in the presence of multicollinearity. Multicollinearity occurs when multiple independent inputs are highly correlated. In this case, their individual effects on the predicted variable cannot be estimated well. Classical linear regression is highly volatile to small input changes. The regularization of ridge regression reduces this volatility by introducing a bias on the weights towards 0.</p>
<h2><span id="uncertainty">uncertainty</span></h2><p>In practice, our data D is merely a sample of the process we are modeling. In these cases, we are looking for models that generalize to unseen data.<br>Therefore, it is useful to express the uncertainty about our model due to the lack of data. This uncertainty is commonly referred to as the epistemic uncertainty.<br>Usually, there is another source of uncertainty called aleatoric uncertainty, which originates directly from the process that we are modeling. This uncertainty is the noise in the labels that cannot be explained by the inputs.</p>
<h2><span id="weight-space-view">Weight-space View</span></h2><p>The most immediate and natural Bayesian interpretation of linear regression is to simply impose a prior on the weights $w$.</p>
<p>Assume that prior $w\sim\mathcal{N}(0,\sigma_p^2I)$ and likelihood $y_i\mid x_i,w\sim\mathcal{N}(w^\top x_i,\sigma_n^2).$ are both Gaussian, we will get the posterior distribution over the weights as:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\log p(w\mid x_{1:n},y_{1:n}) \\
&=\log p(w)+\log p(y_{1:n}\mid x_{1:n},w)+\mathrm{const} \\
&=\log p(w)+\sum_{i=1}^n\log p(y_i\mid x_i,w)+\mathrm{const}\\
&=-\frac1{2\sigma_p^2}\|w\|_2^2-\frac1{2\sigma_n^2}\sum_{i=1}^n(y_i-w^\top x_i)^2+\mathrm{const} \\
&=-\frac1{2\sigma_p^2}\|w\|_2^2-\frac1{2\sigma_n^2}\|y-Xw\|_2^2+\mathrm{const} \\
&=-\frac1{2\sigma_p^2}w^\top w-\frac1{2\sigma_n^2}\Big(w^\top X^\top Xw-2y^\top Xw+y^\top y\Big)+\mathrm{const.}\\
&=-\frac12(w-\mu)^\top\Sigma^{-1}(w-\mu)+\mathrm{const}
\end{aligned}</script><p>As the above is a quadratic form in $w$, it follows that the posterior distribution is a Gaussian.<br>This also shows that Gaussians with known variance and linear likelihood are self-conjugate. A distribution is said to be self-conjugate (or a conjugate prior is self-conjugate) if, when used as a prior distribution, it results in a posterior distribution that belongs to the same family of distributions. It can be shown more generally that Gaussians with known variance are self-conjugate to any Gaussian likelihood. For general distributions the posterior will not be closed-form. This is a very special property of Gaussians.<br>We can compute the MAP estimate for the weights,</p>
<script type="math/tex; mode=display">
\begin{gathered}
\hat{w}_{\mathrm{MAP}} =\underset{w}{\operatorname*{\arg\max}}\log p(y_{1:n}\mid x_{1:n},w)+\log p(w) \\
=\arg\min_w\|y-Xw\|_2^2+\frac{\sigma_n^2}{\sigma_p^2}\|w\|_2^2. 
\end{gathered}</script><p>we can find that this is simply the MLE loss with an additional $l_2$ regularization term and this coincides with the optimization objective of ridge regression with weight decay $\lambda=\frac{\sigma_n^2}{\sigma_p^2}$. Also, recall that the MAP estimate corresponds to the mode of the posterior distribution, which in the case of a Gaussian is simply its mean.(The mode of a probability distribution is the value where the distribution reaches its maximum point. In the context of the posterior distribution, the mode corresponds to the most probable value of the parameter given the observed data.).</p>
<p>A commonly used alternative to ridge regression is the least absolute shrinkage and selection operator (or lasso), which uses $l_1$ regularization.It turns out that lasso can also be viewed as Bayesian learning, using a Laplace prior.</p>
<p>Note that using point estimates like the MAP estimate does not quantify uncertainty in the weights. The MAP estimate simply collapses all mass of the posterior around its mode.This is especially harmful when we are unsure about the best model.</p>
<h2><span id="recursive-bayesian-updates">Recursive Bayesian Updates</span></h2><p>As data arrives online (i.e., in “real-time”), we can obtain the new posterior and use it to replace our prior.</p>
<h2><span id="non-linear-regression">Non-linear Regression</span></h2><p>We can use linear regression not only to learn linear functions. The trick is to apply a non-linear transformation $\phi:\mathbb{R}^d\to\mathbb{R}^e$.<br>In Polynomial regression, to learn polynomials of degree m in d input dimensions, we need to apply the nonlinear transformation</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{\phi}(x)& =[1,x_1,\ldots,x_d,x_1^2,\ldots,x_d^2,x_1\cdot x_2,\ldots,x_{d-1}\cdot x_d,  \\
&x_{d-m+1}\cdot\cdot\cdot\cdot\cdot x_d].
\end{aligned}</script><p>the dimension of the feature space grows exponentially in the degree of polynomials and input dimensions. Even for relatively small m and d, this becomes completely unmanageable.</p>
<h2><span id="function-space-view">Function-space View</span></h2><p>Previously, we have been interpreting it as a distribution over the weights $w$ of a linear function $\hat{f}=\boldsymbol{\Phi}w.$, we can equivalently consider a distribution directly over the estimated function values. Instead of considering a prior over the weights${w\sim\mathcal{N}}(0,\sigma_p^2I)$, we now impose a prior directly on the values of our model at the observations.Using that Gaussians are closed under linear maps, we obtain the equivalent prior:</p>
<script type="math/tex; mode=display">
f\mid X\sim\mathcal{N}(\boldsymbol{\Phi}\mathbb{E}[\boldsymbol{w}],\boldsymbol{\Phi}\mathrm{Var}[\boldsymbol{w}]\boldsymbol{\Phi}^\top)=\mathcal{N}(\boldsymbol{0},\underbrace{\sigma_p^2\boldsymbol{\Phi}\boldsymbol{\Phi}^\top}_{\boldsymbol{\kappa}})</script><p>K is the kernel matrix.The kernel function is:<br>$k(x,x^{\prime})\doteq\sigma_p^2\cdot\phi(x)^\top\phi(x^{\prime})$<br>The kernel matrix is a covariance matrix and the kernel function measures the covariance of the function values $k(x,x^{\prime})=\mathrm{Cov}\big[f(x),f(x^{\prime})\big].$<br>Moreover, note that we have reformulated the learning algorithm such that the feature space is now implicit in the choice of kernel, and the kernel is defined by inner products of (nonlinearly transformed) inputs. In other words, the choice of kernel implicitly determines the class of functions that f is sampled from, and encodes our prior beliefs. This is known as the kernel trick.</p>
<h2><span id="reference">reference</span></h2><p>[1] A. Krause, “Probabilistic  Artificial Intelligence”.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-10-12T08:54:35.000Z" title="2023-10-12 10:54:35 ├F10: AM┤">2023-10-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-20T19:24:11.427Z" title="2023-10-20 9:24:11 ├F10: PM┤">2023-10-20</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">14 minutes read (About 2055 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/10/12/pai1/">Probabilistic Artificial Intelligence - Gaussian Process</a></p><div class="content"><h1><span id="gaussian-process">Gaussian Process</span></h1><h2><span id="gaussian-distribution">Gaussian distribution</span></h2><p>Univariate Gaussian Distribution is simple, here we focus on multivariate graussian distribution, where each random variable is distributed normally and their joint distribution is also Gaussian.  The multivariate Gaussian distribution is defined by a mean vector $\mu$ and a covariance matrix $\Sigma$. The covariance matrix is always symmetric and positive semi-definite. why is Gaussian distribution so important? because under the assumptions of the central limit theorem, we can use it to model many events in the real world. Moreover, Gaussian distributions have the nice algebraic property of being closed under conditioning and marginalization. Being closed under conditioning and marginalization means that the resulting distributions from these operations are also Gaussian, which makes many problems in statistics and machine learning tractable. Conditioning is the cornerstone of Gaussian processes since it allows Bayesian inference.</p>
<h2><span id="grassian-process">Grassian process</span></h2><h3><span id="what-is-gp">what is GP</span></h3><p>A Gaussian process is an infinite set of random variables such that any finite number of them are jointly Gaussian.<br>A Gaussian process is characterized by a mean function $\mu$ and a covariance function (or kernel function) k. Intuitively, a Gaussian process can be interpreted as a normal distribution over functions and is therefore often called an infinite-dimensional Gaussian.</p>
<p>Here’s an analogy: Consider a multivariate normal distribution over a set of points in 2D space. Each draw from this distribution corresponds to a vector of values, one for each point. Now, extend this idea to an infinite number of points, and you get a function. The Gaussian process is like having a normal distribution over all possible functions that could describe your data.</p>
<h3><span id="mean-and-covariance-functions">Mean and covariance functions</span></h3><p>The prior mean function $m(⋅)$ describes the average function under the GP distribution before seeing any data. Therefore, it offers a straightforward way to incorporate prior knowledge about the function we wish to model. In the absence of this type of prior knowledge, a common choice is to set the prior mean function to zero, i.e., $m(⋅)≡0$. </p>
<p>The covariance function $k(x,x’)$ computes the covariance $cov[f(x),f(x′)]$ between the corresponding function values by evaluating the covariance function<br>k at the corresponding inputs x,x′(kernel trick ).Practically, the covariance function encodes structural assumptions about the class of functions we wish to model. These assumptions are generally at a high level and may include periodicity or differentiability. Practically, the covariance function encodes structural assumptions about the class of functions we wish to model. These assumptions are generally at a high level and may include periodicity or differentiability. </p>
<h3><span id="how-gp-works">How GP works</span></h3><p>For a given set of training points, there are potentially infinitely many functions that fit the data. Gaussian processes offer an elegant solution to this problem by assigning a probability to each of these functions. The goal of Gaussian processes is to learn this underlying distribution from training data. Respective to the test data X, we will denote the training data as Y. As we have mentioned before, the key idea of Gaussian processes is to model the underlying distribution of<br>X together with Y as a multivariate normal distribution.  The essential idea of Bayesian inference is to update the current hypothesis as new information becomes available. In the case of Gaussian processes, this information is the training data. Thus, we are interested in the conditional probability<br>$P(X∣Y)$.</p>
<p>In Gaussian processes we treat each test point as a random variable. A multivariate Gaussian distribution has the same number of dimensions as the number of random variables. Since we want to predict the function values at $∣X∣=N$ test points, the corresponding multivariate Gaussian distribution is also<br>N -dimensional. Making a prediction using a Gaussian process ultimately boils down to drawing samples from this distribution. We then interpret the i-th component of the resulting vector as the function value corresponding to the i-th test point.</p>
<h3><span id="marginal-likelihood-and-gp-training">Marginal likelihood and GP training</span></h3><p>A marginal likelihood is a likelihood function that has been integrated over the parameter space. In Bayesian statistics, it represents the probability of generating the observed sample from a prior and is therefore often referred to as model evidence or simply evidence.</p>
<p>The likelihood function represents the probability of observing the given data X given a specific set of parameter values $\theta$ in a statistical model. It expresses how well the parameters explain the observed data. The likelihood function is a key component in frequentist statistics. It is used to estimate the maximum likelihood estimates (MLE) of the parameters. </p>
<p>The marginal likelihood represents the probability of observing the data X without specifying a particular set of parameters. It is obtained by integrating (or summing) the likelihood function over all possible values of the parameters, weighted by the prior distribution of the parameters. The marginal likelihood is a key concept in Bayesian statistics. It serves as a normalizing constant, ensuring that the posterior distribution integrates (or sums) to 1. It is also used in Bayesian model comparison, where different models are compared based on their marginal likelihoods.</p>
<p>To train the GP, we maximize the marginal likelihood with respect to the GP hyperparameters,i.e., the parameters of the mean and covariance functions, which we summarize by $\theta$.</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(\mathbf{y}|\mathbf{X},\theta)& =\int p(\mathbf{y}|f,\mathbf{X})p(f|\mathbf{X})df  \\
&=\int\mathcal{N}(\mathbf{y}|f(\mathbf{X}),\sigma_n^2\mathbf{I})\mathcal{N}(f(\mathbf{X})|\mathbf{0},\mathbf{K})df(\mathbf{X}) \\
&=\mathcal{N}(\mathbf{y}|\mathbf{0},\mathbf{K}+\sigma_n^2\mathbf{I}),
\end{aligned}</script><p>Maximizing the marginal likelihood behaves much better than finding maximum likelihood $\operatorname*{argmax}<em>{f(\mathbf{X}),\sigma_n}p(\mathbf{y}|f(\mathbf{X}),\sigma_n^2\mathbf{I})$ or maximum a-posteriori point estimates $\mathop{\mathrm{argmax}}</em>{f(\mathbf{X}),\sigma_n}p(\mathbf{y}|f(\mathbf{X}),\sigma_n^2\mathbf{I})p(f(\mathbf{X})|\theta)$.<br>These two approaches would lead to overfitting, since it is possible to get arbitrarily high likelihoods by placing the function values $f(X)$ on top of the observations y and letting the the noise $\sigma_n$ tend to zero. In contrast, the marginal likelihood does not fit function values directly, but integrates them out.By averaging (integrating out) the direct model parameters, i.e., the function values, the marginal likelihood automatically trades off data fit and model complexity.Choose a model that is too inflexible, and the marginal likelihood<br>$p(y∣X,θ)$ will be low because few functions in the prior fit the data. A model that is too flexible spreads its density over too many datasets, and so $p(y∣X,θ)$ will also be low.</p>
<h3><span id="what-is-kernel">what is kernel</span></h3><p>If an algorithm is defined solely in terms of inner products in input space then it can be lifted into feature space by replacing occurrences of those inner products by k(x, x′); this is sometimes called the kernel trick. This technique is kernel trick particularly valuable in situations where it is more convenient to compute the kernel than the feature vectors themselves.</p>
<p>The kernel k, which is often also called covariance function, pairwise on all the points. The kernel receives two points<br>$t,t’ \in \mathbb{R}^n$ as an input and returns a similarity measure between those points in the form of a scalar.</p>
<script type="math/tex; mode=display">
      k: \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R},\quad 
      \Sigma = \text{Cov}(X,X’) = k(t,t’)</script><p>We evaluate this function for each pairwise combination of the test points to retrieve the covariance matrix. </p>
<p>Kernels can be separated into stationary and non-stationary kernels. Stationary kernels, such as the RBF kernel or the periodic kernel, are functions invariant to translations, and the covariance of two points is only dependent on their relative position. Non-stationary kernels, such as the linear kernel, do not have this constraint and depend on an absolute location.</p>
<p>The kernel is used to define the entries of the covariance matrix. Consequently, the covariance matrix determines which type of functions from the space of all possible functions are more probable.</p>
<p>A kernel function coulde be stationary or isotropic.  A kernel function is stationary if $k(x,x’)=k(x-x’)$. A kernel function is isotropic is $k(x,x’)=k(||x-x’||_2)$. Stationarity implies that the covariance function only depends on distances<br>$∥x−x’∥$ of the corresponding inputs, and not on the location of the individual data points. This means that if the inputs are close to each other, the corresponding function values are strongly correlated. </p>
<h4><span id="interpretation-of-the-hyperparameters">Interpretation of the hyperparameters</span></h4><p>Stationary covariance functions typically contain the term $\frac\tau l=\frac{|\mathbf{x}-\mathbf{x}^{\prime}|}l$. where<br>$l$ is a lengthscale parameter. Longer lengthscales cause long-range correlations, whereas for short lengthscales, function values are strongly correlated only if their respective inputs are very close to each other. This allows functions to vary strongly and display more flexibility in the range of the data.</p>
<p>The signal variance parameter $\sigma_f^2$ allows us to say something about the amplitude of the function we model. </p>
<h3><span id="training-tips">training tips</span></h3><p>The marginal likelihood is non-convex with potentially multiple local optima. Therefore, we may end up in (bad) local optima when we choose a gradient-based optimization method. In order to initialize these parameters to reasonable values when we optimize the marginal likelihood, we need to align them with what we know about the data, either empirically or using prior knowledge. Assume, we have training inputs<br>X and training targets y. We will see that the signal and noise variances can be initialized using statistics of the training targets, whereas the lengthscale parameters can be initialized using statistics of the training inputs. A reasonable intialization that works well in practice is to set the signal variance to the empirical variance of the observed function values, and the noise variance to a smaller value. </p>
<p>Local optima are the largest problem that prevent good lengthscales from being selected through gradient-based optimisation. Generally, we can observe two different types of local optima:</p>
<p>Long lengthscale, large noise. Often the lengthscale is so long that the prior only allows nearly linear functions in the posterior. As a consequence, a large amount of noise is required to account for the residuals, leading to a small signal-to-noise ratio. This looks like underfitting, as non-linearities in the data are modelled as noise instead of being learned as part of the function.<br>Short lengthscale, low noise. Short lengthscales allow the posterior mean to fit to small variations in the data. Often such solutions are accompanied by small noise, and therefore a high signal-to-noise ratio. Such solutions look like they overfit, since the means fit the data by making drastic and fast changes, while generalizing poorly. However, the short lengthscale also prevents the predictive error bars from being small, so all predictions will be made with high uncertainty. In the probabilistic sense, this also looks like underfitting.</p>
<p>Which optimum we end up in, depends on the initialization of our lengthscale as we are likely to end up in a local optimum nearest to our initial choice. In both cases, the optimizer is more likely to get stuck in a local optimum if the situations are a somewhat plausible explanations of the data. In practice, it is harder to get out of a long lengthscale situation since the optimizer often struggles to get beyond the (typically) huge plateau that is typical for very long lengthscales.</p>
<h4><span id="how-to-choose-a-kernel">How to choose a kernel</span></h4><p>The choice of kernel (a.k.a. covariance function) determines almost all the generalization properties of a GP model.<br>​In fact, you might decide that choosing the kernel is one of the main difficulties in doing inference - and just as you don’t know what the true parameters are, you also don’t know what the true kernel is. Probably, you should try out a few different kernels at least, and compare their marginal likelihood on your training data.</p>
<h4><span id="others">others</span></h4><p>The GP does not require any input normalization, but it can make sense to do so for numerical reasons.</p>
<h2><span id="reference">reference</span></h2><p><a target="_blank" rel="noopener" href="https://distill.pub/2019/visual-exploration-gaussian-processes/">https://distill.pub/2019/visual-exploration-gaussian-processes/</a><br><a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~duvenaud/cookbook/">https://www.cs.toronto.edu/~duvenaud/cookbook/</a> \<br><a target="_blank" rel="noopener" href="https://infallible-thompson-49de36.netlify.app/">https://infallible-thompson-49de36.netlify.app/</a> \<br>A. Krause, “Probabilistic  Artificial Intelligence”.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-31T15:53:12.000Z" title="2023-3-31 5:53:12 ├F10: PM┤">2023-03-31</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-12T17:27:05.212Z" title="2023-10-12 7:27:05 ├F10: PM┤">2023-10-12</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a minute read (About 204 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/31/speech/">speech</a></p><div class="content"><h2><span id="signal">signal</span></h2><p>spectrogram: A spectrogram of a time signal is a special two-dimensional representation that displays time in its horizontal axis and frequency in its vertical axis.</p>
<h2><span id="short-time-fourier-analysis">short-time Fourier analysis</span></h2><p>Why use it?<br>Some regions of speech signals shorter than 100 milliseconds often appear to be periodic, so that we can use the exact definition of Fourier<br>transform.</p>
<h3><span id="spectral-leakage">spectral leakage</span></h3><p>This phenomenon is called spectral leakage because the amplitude of one harmonic leaks over the rest and masks its value.</p>
<h2><span id="feature-extraction">feature extraction</span></h2><p>Representation of speech signals in the frequency domain is especially useful because the frequency structure of a phoneme is generally unique.</p>
<p>Sinusoids are important because speech signals can be decomposed as sums of sinusoids.</p>
<p>For voiced sounds there is typically more energy at low frequencies<br>than at high frequencies, also called roll-off. To make the spectrograms easier to read, sometimes the signal is first preemphasized (typically with a first-order difference FIR filter) to boost the high frequencies<br>to counter the roll-off of natural speech.</p>
<h2><span id="digital-systems">Digital Systems</span></h2><p>Linear Time-Invariant Systems and Linear Time-Varying Systems.</p>
<h2><span id="the-fourier-transform">The Fourier Transform</span></h2><h2><span id="z-transform">Z-Transform</span></h2><h2><span id="digital-filter">digital filter</span></h2><h2><span id="filterbank">filterbank</span></h2><p>A filterbank is a collection of filters that span the whole frequency spectrum.</p>
<h2><span id="short-time-analysis">short-time analysis</span></h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-12-23T15:44:05.000Z" title="2022-12-23 4:44:05 ├F10: PM┤">2022-12-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-12T17:27:34.376Z" title="2023-10-12 7:27:34 ├F10: PM┤">2023-10-12</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a minute read (About 169 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/12/23/Network-Representation-Learning/">Network Representation Learning</a></p><div class="content"><h2><span id="background">background</span></h2><p>Recording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course.</p>
<h2><span id="line">LINE</span></h2><p>Reproduce paper “LINE: Large-scale Information Network Embedding”.</p>
<h3><span id="alias-table-method">Alias Table Method</span></h3><p>It’s a method of effiently drawing samples from discrete distribution.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.keithschwarz.com/darts-dice-coins/">https://www.keithschwarz.com/darts-dice-coins/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/haolexiao/article/details/65157026">https://blog.csdn.net/haolexiao/article/details/65157026</a></p>
<h3><span id="negative-sampling">Negative Sampling</span></h3><h4><span id="word2vec">word2vec</span></h4><p>Original paper:<br>Efficient estimation of word representations in vector space.<br>reference:<br>word2vec Explained: Deriving Mikolov et al.’s<br>Negative-Sampling Word-Embedding Method</p>
<h4><span id="skip-gram-model">Skip-Gram Model</span></h4><p>Original papaer:Distributed Representations of Words and Phrases<br>and their Compositionality.<br>The idea behind the word2vec models is that the words that appear in the same context (near each other) should have similar word vectors. Therefore, we should consider some notion of similarity in our objective when training the model. This is done using the dot product since when vectors are similar, their dot product is larger.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.baeldung.com/cs/nlps-word2vec-negative-sampling">https://www.baeldung.com/cs/nlps-word2vec-negative-sampling</a></p>
<h2><span id="graphsage">graphSage</span></h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-26T19:10:33.000Z" title="2021-9-26 9:10:33 ├F10: PM┤">2021-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-09T13:37:23.731Z" title="2023-11-9 2:37:23 ├F10: PM┤">2023-11-09</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 269 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/26/ML-4/">第二十篇 机器学习(4)-uplift模型</a></p><div class="content"><h2><span id="uplift模型">uplift模型</span></h2><p>uplift模型中文为增益模型，是工业界因果推断与机器学习结合最成熟的算法之一。传统的监督学习模型，往往是对输入x去预测一个y，而增益模型注重于x的变化对y的影响，以广告为例，传统的监督学习往往是给定这个特征去预测用户是否会点击，而增益模型注重的是给这个客户投放广告与否对客户是否购买广告商品所产生的影响。</p>
<h3><span id="因果推断">因果推断</span></h3><p>因果推断是从观察到的数据中推断出变量之间的因果关系的过程。在统计学和数据科学中，因果推断涉及到尝试理解一个事件或行为是什么导致了另一个事件或行为。这与相关性或关联不同，因果推断试图确定一个变量的变化是否直接导致另一个变量的变化。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-25T14:43:07.000Z" title="2021-9-25 4:43:07 ├F10: PM┤">2021-09-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-09-25T08:46:55.795Z" title="2021-9-25 10:46:55 ├F10: AM┤">2021-09-25</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/25/DL/">第十九篇 深度学习(1)-梯度下降</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-02T20:07:25.000Z" title="2021-9-2 10:07:25 ├F10: PM┤">2021-09-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-09-25T08:40:05.043Z" title="2021-9-25 10:40:05 ├F10: AM┤">2021-09-25</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 72 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/02/RL/">第十七篇 强化学习(1)-马尔可夫决策过程</a></p><div class="content"><h3><span id="马尔可夫决策过程">马尔可夫决策过程</span></h3><p>马尔可夫性质：当前状态可以完全表征过程。</p>
<p>对于任意有限的马尔可夫决策过程，都存在一个最优策略，不差于其他所有可能的策略。</p>
<h4><span id="贝尔曼方程">贝尔曼方程</span></h4></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/theory/">Previous</a></div><div class="pagination-next"><a href="/categories/theory/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/theory/">1</a></li><li><a class="pagination-link is-current" href="/categories/theory/page/2/">2</a></li><li><a class="pagination-link" href="/categories/theory/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.PNG" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">76</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-02T11:52:28.000Z">2024-04-02</time></p><p class="title"><a href="/2024/04/02/llm2/">Problems record of using OpenAI&#039;s API</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-29T12:00:15.000Z">2024-03-29</time></p><p class="title"><a href="/2024/03/29/llm1/">Sampling</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-02-21T11:25:29.000Z">2024-02-21</time></p><p class="title"><a href="/2024/02/21/llm0/">Measuring sentence similarity</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-25T16:14:35.000Z">2024-01-25</time></p><p class="title"><a href="/2024/01/25/pai11/">pai - review notes</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-01-03T15:06:23.000Z">2024-01-03</time></p><p class="title"><a href="/2024/01/03/bigdata13/">bigdata - review notes</a></p><p class="categories"><a href="/categories/database/">database</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">43</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/probability/"><span class="tag">probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2024 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>