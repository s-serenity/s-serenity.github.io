<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-04T13:02:21.000Z" title="2024-11-4 9:02:21 ├F10: PM┤">2024-11-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T13:02:21.119Z" title="2024-11-4 9:02:21 ├F10: PM┤">2024-11-04</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/04/db0/">db0</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-04T13:02:02.000Z" title="2024-11-4 9:02:02 ├F10: PM┤">2024-11-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T13:02:02.785Z" title="2024-11-4 9:02:02 ├F10: PM┤">2024-11-04</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/04/op0/">op0</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-04T13:01:31.000Z" title="2024-11-4 9:01:31 ├F10: PM┤">2024-11-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T13:01:31.044Z" title="2024-11-4 9:01:31 ├F10: PM┤">2024-11-04</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/04/ca0/">ca0</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-04T12:59:32.000Z" title="2024-11-4 8:59:32 ├F10: PM┤">2024-11-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T13:14:27.433Z" title="2024-11-4 9:14:27 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/computer-science/">computer science</a></span><span class="level-item">a few seconds read (About 70 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/04/cn0/">计算机网络(1) - IP地址</a></p><div class="content"><h2><span id="ip地址">IP地址</span></h2><p>IP地址根据其结构被分为A、B、C、D和E五类，其中A、B、C类是最常见的用于公共网络的地址类别。D类用于多播，E类用于实验和未来使用。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-02T10:11:19.000Z" title="2024-11-2 6:11:19 ├F10: PM┤">2024-11-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-03T02:08:29.719Z" title="2024-11-3 10:08:29 ├F10: AM┤">2024-11-03</time></span><span class="level-item">2 minutes read (About 373 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/02/algo4/">算法（5）- 比特运算</a></p><div class="content"><h2><span id="比特运算">比特运算</span></h2><p>比特运算（Bitwise operations）是直接对整数的二进制位进行操作的运算。在Python中，比特运算符可以用来执行按位与（AND）、按位或（OR）、按位异或（XOR）、按位非（NOT）、左移（左移位）和右移（右移位）等操作。</p>
<h3><span id="brian-kernighan算法">Brian Kernighan算法</span></h3><p>Brian Kernighan算法是一种用于高效计算一个整数中二进制表示下1的个数的算法。这个算法的核心思想是利用位运算来快速减少计数的过程。算法基于这样一个观察：对于任意一个非零整数n，n和n-1进行按位与操作（n &amp; (n - 1)）的结果会将n的二进制表示中最右边的一个1变为0。</p>
<h3><span id="位运算的技巧">位运算的技巧</span></h3><p>通过与1进行按位与操作可以取得最右位并且判断一个数是奇数还是偶数。通过与(n-1)进行按位与操作可以清零最低位的1。对于十进制整数 x，我们可以用 x &amp; (1 &lt;&lt; k) 来判断 x 二进制表示的第 k 位（最低位为第 0 位）是否为 1。</p>
<h2><span id="参考文献">参考文献</span></h2><p><a target="_blank" rel="noopener" href="https://leetcode.cn/problems/counting-bits/solutions/627418/bi-te-wei-ji-shu-by-leetcode-solution-0t1i/?envType=study-plan-v2&amp;envId=leetcode-75">https://leetcode.cn/problems/counting-bits/solutions/627418/bi-te-wei-ji-shu-by-leetcode-solution-0t1i/?envType=study-plan-v2&amp;envId=leetcode-75</a></p>
<p><a target="_blank" rel="noopener" href="https://leetcode.cn/problems/minimum-flips-to-make-a-or-b-equal-to-c/solutions/101777/huo-yun-suan-de-zui-xiao-fan-zhuan-ci-shu-by-lee-2/?envType=study-plan-v2&amp;envId=leetcode-75">https://leetcode.cn/problems/minimum-flips-to-make-a-or-b-equal-to-c/solutions/101777/huo-yun-suan-de-zui-xiao-fan-zhuan-ci-shu-by-lee-2/?envType=study-plan-v2&amp;envId=leetcode-75</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-02T06:44:41.000Z" title="2024-11-2 2:44:41 ├F10: PM┤">2024-11-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-02T07:34:55.353Z" title="2024-11-2 3:34:55 ├F10: PM┤">2024-11-02</time></span><span class="level-item">3 minutes read (About 433 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/02/algo3/">算法（4）- 前缀树</a></p><div class="content"><h2><span id="前缀树">前缀树</span></h2><p>前缀树（Trie树），也称为字典树或单词查找树，是一种树形数据结构，专门用于高效存储和检索字符串集合中的词项。</p>
<p>前缀树是一种多叉树结构，其中每个节点代表一个字符串前缀，从根节点到任一节点的路径上的字符序列构成该节点对应的前缀。</p>
<h3><span id="前缀树的应用">前缀树的应用</span></h3><p>搜索引擎使用前缀树来快速检索和匹配用户输入的查询词。当用户输入一个查询词时，搜索引擎可以从前缀树的根节点开始，根据查询词中的字符逐个向下遍历节点，直到找到匹配的单词或其前缀。</p>
<p>搜索引擎可以利用前缀树提供自动补全建议和拼写检查。由于前缀树存储了大量的单词和它们的前缀，搜索引擎可以快速地根据用户已经输入的部分单词（前缀）给出完整的单词建议，或者指出拼写错误并提供正确的拼写。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class Trie:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.children = [None] * 26</span><br><span class="line">        self.isEnd = False</span><br><span class="line">    </span><br><span class="line">    def searchPrefix(self, prefix: str) -&gt; &quot;Trie&quot;:</span><br><span class="line">        node = self</span><br><span class="line">        for ch in prefix:</span><br><span class="line">            ch = ord(ch) - ord(&quot;a&quot;)</span><br><span class="line">            if not node.children[ch]:</span><br><span class="line">                return None</span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        return node</span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        node = self</span><br><span class="line">        for ch in word:</span><br><span class="line">            ch = ord(ch) - ord(&quot;a&quot;)</span><br><span class="line">            if not node.children[ch]:</span><br><span class="line">                node.children[ch] = Trie()</span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        node.isEnd = True</span><br><span class="line"></span><br><span class="line">    def search(self, word: str) -&gt; bool:</span><br><span class="line">        node = self.searchPrefix(word)</span><br><span class="line">        return node is not None and node.isEnd</span><br><span class="line"></span><br><span class="line">    def startsWith(self, prefix: str) -&gt; bool:</span><br><span class="line">        return self.searchPrefix(prefix) is not None</span><br></pre></td></tr></table></figure>
<h2><span id="参考文献">参考文献</span></h2><p>链接：<a target="_blank" rel="noopener" href="https://leetcode.cn/problems/implement-trie-prefix-tree/solutions/1/shi-xian-trie-qian-zhui-shu-by-leetcode-ti500/">https://leetcode.cn/problems/implement-trie-prefix-tree/solutions/1/shi-xian-trie-qian-zhui-shu-by-leetcode-ti500/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-27T01:50:02.000Z" title="2024-10-27 9:50:02 ├F10: AM┤">2024-10-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-03T02:10:40.102Z" title="2024-11-3 10:10:40 ├F10: AM┤">2024-11-03</time></span><span class="level-item">a minute read (About 197 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/27/algo2/">算法（3）- 堆/优先级队列</a></p><div class="content"><h2><span id="堆">堆</span></h2><p>堆是一种特殊的树形数据结构，通常使用数组来实现。堆具有以下特性：堆是一棵完全二叉树（Complete Binary Tree），即除了最后一层外，每一层都被填满，最后一层的节点都靠左排列。</p>
<p>最大堆（Max Heap）：父节点的值总是大于或等于其子节点的值。</p>
<p>最小堆（Min Heap）：父节点的值总是小于或等于其子节点的值。</p>
<h2><span id="优先级队列">优先级队列</span></h2><p>优先级队列（Priority Queue）是一种特殊的队列，其中每个元素都有一个优先级。元素的出队顺序取决于其优先级，而不是进入队列的先后顺序。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-26T09:11:10.000Z" title="2024-10-26 5:11:10 ├F10: PM┤">2024-10-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-26T11:30:42.910Z" title="2024-10-26 7:30:42 ├F10: PM┤">2024-10-26</time></span><span class="level-item"><a class="link-muted" href="/categories/engineering/">engineering</a></span><span class="level-item">8 minutes read (About 1126 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/26/DL2/">深度学习(3) - 计算框架PyTorch</a></p><div class="content"><h2><span id="pytorch">PyTorch</span></h2><h3><span id="张量">张量</span></h3><p>张量是一种专门的数据结构，与数组和矩阵非常相似。张量类似于 NumPy 的 ndarrays，但张量可以在 GPU 或其他硬件加速器上运行，张量也针对自动微分进行了优化。</p>
<p>默认情况下，张量是在 CPU 上创建的。我们需要使用 .to 方法将张量显式地移动到 GPU（在检查 GPU 是否可用后）。请记住，跨设备复制大型张量在时间和内存方面可能代价高昂！</p>
<p>将结果存储到操作数中的操作称为就地操作。它们用 <em> 后缀表示。例如：x.copy</em>(y)、x.t_() 将会改变 x。</p>
<h3><span id="数据加载">数据加载</span></h3><p>PyTorch 提供了两个数据基本类型：torch.utils.data.DataLoader 和 torch.utils.data.Dataset，它们使您可以使用预加载的数据集以及您自己的数据。</p>
<h3><span id="神经网络">神经网络</span></h3><p> torch.nn 命名空间提供了构建您自己的神经网络所需的所有构建块。PyTorch 中的每个模块都是 nn.Module 的子类。</p>
<h3><span id="自动微分">自动微分</span></h3><p> 在训练神经网络时，最常用的算法是 <strong>反向传播</strong>。在此算法中，参数（模型权重）会根据损失函数相对于给定参数的 <strong>梯度</strong> 进行调整。</p>
<p>为了计算这些梯度，PyTorch 有一个内置的微分引擎，称为 torch.autograd。它支持任何计算图的梯度自动计算。当我们需要计算损失函数相对于这些变量的梯度，我们设置了这些张量的requires<em>grad 属性。可以在创建张量时设置requires_grad的值，或者之后使用x.requires_grad</em>(True)方法。要计算这些导数，我们调用loss.backward()，然后从w.grad和b.grad中检索值。</p>
<p>要阻止一个张量被跟踪历史，可以调用.detach()方法将其与计算历史分离，并阻止它未来的计算记录被跟踪。为了防止跟踪历史记录(和使用内存），可以将代码块包装在 with torch.no_grad(): 中。</p>
<h3><span id="优化">优化</span></h3><p>在训练循环中，优化分三个步骤进行：<br>调用optimizer.zero_grad()重置模型参数的梯度。默认情况下，梯度会累加；为了防止重复计数，我们在每次迭代中显式地将其归零。</p>
<p>使用loss.backward()反向传播预测损失。PyTorch 将损失相对于每个参数的梯度存储起来。</p>
<p>在获得梯度后，我们调用optimizer.step()根据反向传播中收集的梯度调整参数。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">def train_loop(dataloader, model, loss_fn, optimizer):</span><br><span class="line">    size = len(dataloader.dataset)</span><br><span class="line">    # Set the model to training mode - important for batch normalization and dropout layers</span><br><span class="line">    # Unnecessary in this situation but added for best practices</span><br><span class="line">    model.train()</span><br><span class="line">    for batch, (X, y) in enumerate(dataloader):</span><br><span class="line">        # Compute prediction and loss</span><br><span class="line">        pred = model(X)</span><br><span class="line">        loss = loss_fn(pred, y)</span><br><span class="line"></span><br><span class="line">        # Backpropagation</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        if batch % 100 == 0:</span><br><span class="line">            loss, current = loss.item(), batch * batch_size + len(X)</span><br><span class="line">            print(f&quot;loss: &#123;loss:&gt;7f&#125;  [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def test_loop(dataloader, model, loss_fn):</span><br><span class="line">    # Set the model to evaluation mode - important for batch normalization and dropout layers</span><br><span class="line">    # Unnecessary in this situation but added for best practices</span><br><span class="line">    model.eval()</span><br><span class="line">    size = len(dataloader.dataset)</span><br><span class="line">    num_batches = len(dataloader)</span><br><span class="line">    test_loss, correct = 0, 0</span><br><span class="line"></span><br><span class="line">    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode</span><br><span class="line">    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        for X, y in dataloader:</span><br><span class="line">            pred = model(X)</span><br><span class="line">            test_loss += loss_fn(pred, y).item()</span><br><span class="line">            correct += (pred.argmax(1) == y).type(torch.float).sum().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= size</span><br><span class="line">    print(f&quot;Test Error: \n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \n&quot;)</span><br></pre></td></tr></table></figure></p>
<h3><span id="保存和加载模型">保存和加载模型</span></h3><h4><span id="保存和加载模型权重">保存和加载模型权重</span></h4><p>PyTorch 模型将学习到的参数存储在内部状态字典中，称为 state_dict。这些可以通过 torch.save 方法持久化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = models.vgg16(weights=&#x27;IMAGENET1K_V1&#x27;)</span><br><span class="line">torch.save(model.state_dict(), &#x27;model_weights.pth&#x27;)</span><br></pre></td></tr></table></figure>
<p>要加载模型权重，您需要首先创建一个相同模型的实例，然后使用 load_state_dict() 方法加载参数。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model</span><br><span class="line">model.load_state_dict(torch.load(&#x27;model_weights.pth&#x27;, weights_only=True))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure><br>注意请务必在推理之前调用 model.eval() 方法，以将 dropout 和批归一化层设置为评估模式。如果不这样做，将产生不一致的推理结果。</p>
<h4><span id="保存和加载具有形状的模型">保存和加载具有形状的模型</span></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, &#x27;model.pth&#x27;)</span><br><span class="line">model = torch.load(&#x27;model.pth&#x27;, weights_only=False),</span><br></pre></td></tr></table></figure>
<h2><span id="参考文献">参考文献</span></h2><p><a target="_blank" rel="noopener" href="https://pytorch.ac.cn/tutorials/beginner/basics/tensor_tutorial.html">https://pytorch.ac.cn/tutorials/beginner/basics/tensor_tutorial.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-25T08:28:05.000Z" title="2024-10-25 4:28:05 ├F10: PM┤">2024-10-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-26T05:03:37.759Z" title="2024-10-26 1:03:37 ├F10: PM┤">2024-10-26</time></span><span class="level-item">7 minutes read (About 1035 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/25/RS0/">Recommender Systems</a></p><div class="content"><h2><span id="recommender-systems">Recommender Systems</span></h2><h3><span id="collaborative-filtering">Collaborative Filtering</span></h3><p> In a broad sense, it is the process of filtering for information or patterns using techniques involving collaboration among multiple users, agents, and data sources. Overall, CF techniques can be categorized into: memory-based CF, model-based CF, and their hybrid.</p>
<h3><span id="matrix-factorization">Matrix Factorization</span></h3><p> Matrix factorization is a class of collaborative filtering models. Specifically, the model factorizes the user-item interaction matrix (e.g., rating matrix) into the product of two lower-rank matrices, capturing the low-rank structure of the user-item interactions.</p>
<p>Let $\mathbf{R} \in \mathbb{R}^{m \times n}$ denote the interaction matrix with m users and n items and the values of $\mathbf{R}$<br> represent explicit ratings. The user-item interaction will be factorized into a user latent matrix $\mathbf{P} \in \mathbb{R}^{m \times k}$ and  an item latent matrix $\mathbf{Q} \in \mathbb{R}^{n \times k}$. For a given item<br>i, the elements of $\mathbf{q}_i$<br> measure the extent to which the item possesses those characteristics such as the genres and languages of a movie. For a given user u<br>, the elements of $\mathbf{p}_u$<br> measure the extent of interest the user has in items’ corresponding characteristics.<br> The predicted ratings can be estimated by </p>
<script type="math/tex; mode=display">
 \hat{\mathbf{R}} = \mathbf{PQ}^\top</script><p> One major problem of this prediction rule is that users/items biases can not be modeled, so </p>
<script type="math/tex; mode=display">
 \hat{\mathbf{R}}_{ui} = \mathbf{p}_u\mathbf{q}^\top_i + b_u + b_i
 $$. 

 Then, we train the matrix factorization model by minimizing the mean squared error between predicted rating scores and real rating scores.</script><p> \underset{\mathbf{P}, \mathbf{Q}, b}{\mathrm{argmin}} \sum<em>{(u, i) \in \mathcal{K}} | \mathbf{R}</em>{ui} -<br>\hat{\mathbf{R}}_{ui} |^2 + \lambda (| \mathbf{P} |^2_F + | \mathbf{Q}<br>|^2_F + b_u^2 + b_i^2 )</p>
<script type="math/tex; mode=display">
where $\lambda$
 denotes the regularization rate.

### AutoRec 
Although the matrix factorization model achieves decent performance on the rating prediction task, it is essentially a linear model. Thus, such models are not capable of capturing complex nonlinear and intricate relationships that may be predictive of users’ preferences. 
AutoRec identifies collaborative filtering (CF) with an autoencoder architecture and aims to integrate nonlinear transformations into CF on the basis of explicit feedback. On the other hand, AutoRec differs from a traditional autoencoder: rather than learning the hidden representations, AutoRec focuses on learning/reconstructing the output layer. It uses a partially observed interaction matrix as input, aiming to reconstruct a completed rating matrix.

Let $\mathbf{R}_{*i}$
 denote the $i^\textrm{th}$
 column of the rating matrix, where unknown ratings are set to zeros by default.
The neural architecture is defined as:</script><p>h(\mathbf{R}<em>{*i}) = f(\mathbf{W} \cdot g(\mathbf{V} \mathbf{R}</em>{*i} + \mu) + b)</p>
<script type="math/tex; mode=display">

The following objective function aims to minimize the reconstruction error:</script><p>\underset{\mathbf{W},\mathbf{V},\mu, b}{\mathrm{argmin}} \sum<em>{i=1}^M{\parallel \mathbf{R}</em>{<em>i} - h(\mathbf{R}_{</em>i})\parallel_{\mathcal{O}}^2} +\lambda(| \mathbf{W} |_F^2 + | \mathbf{V}|_F^2)</p>
<script type="math/tex; mode=display">

where $\| \cdot \|_{\mathcal{O}}$
 means only the contribution of observed ratings are considered, that is, only weights that are associated with observed inputs are updated during back-propagation.

### Personalized Ranking
 In general, personalized ranking models can be optimized with pointwise, pairwise or listwise approaches. Pointwise approaches considers a single interaction at a time and train a classifier or a regressor to predict individual preferences. Matrix factorization and AutoRec are optimized with pointwise objectives. Pairwise approaches consider a pair of items for each user and aim to approximate the optimal ordering for that pair. Listwise approaches approximate the ordering of the entire list of items, for example, direct optimizing the ranking measures such as Normalized Discounted Cumulative Gain (NDCG).

 #### Bayesian Personalized Ranking Loss
 Bayesian personalized ranking (BPR) is a pairwise personalized ranking loss that is derived from the maximum posterior estimator. The training data of BPR consists of both positive and negative pairs (missing values). It assumes that the user prefers the positive item over all other non-observed items. We can formulate the maximum posterior estimator to derive the generic optimization criterion for the personalized ranking task.</script><p> \begin{split}\begin{aligned}<br>\textrm{BPR-OPT} : &amp;= \ln p(\Theta \mid &gt;<em>u) \<br>         &amp; \propto \ln p(&gt;_u \mid \Theta) p(\Theta) \<br>         &amp;= \ln \prod</em>{(u, i, j \in D)} \sigma(\hat{y}<em>{ui} - \hat{y}</em>{uj}) p(\Theta) \<br>         &amp;= \sum<em>{(u, i, j \in D)} \ln \sigma(\hat{y}</em>{ui} - \hat{y}<em>{uj}) + \ln p(\Theta) \<br>         &amp;= \sum</em>{(u, i, j \in D)} \ln \sigma(\hat{y}<em>{ui} - \hat{y}</em>{uj}) - \lambda_\Theta |\Theta |^2<br>\end{aligned}\end{split}</p>
<script type="math/tex; mode=display">
 Where $\Theta$
 represents the parameters of an arbitrary recommendation model, 
$>_u$ represents the desired personalized total ranking of all items for user.  
$\hat{y}_{ui}$ and $\hat{y}_{uj}$ 
 are the predicted scores of the user u to item i and j,respectively. 

 #### Hinge Loss</script><p> \sum<em>{(u, i, j \in D)} \max( m - \hat{y}</em>{ui} + \hat{y}_{uj}, 0)</p>
<p> $$<br> where m<br> is the safety margin size.</p>
<h3><span id="neumf">NeuMF</span></h3><p> This model leverages the flexibility and non-linearity of neural networks to replace dot products of matrix factorization, aiming at enhancing the model expressiveness. In specific, this model is structured with two subnetworks including generalized matrix factorization (GMF) and MLP and models the interactions from two pathways instead of simple dot products. The outputs of these two networks are concatenated for the final prediction scores calculation. </p>
<h3><span id="sequence-aware-recommender-systems">Sequence-Aware Recommender Systems</span></h3><p> Caser, short for convolutional sequence embedding recommendation model, adopts convolutional neural networks capture the dynamic pattern influences of users’ recent activities.   The main component of Caser consists of a horizontal convolutional network and a vertical convolutional network, aiming to uncover the union-level and point-level sequence patterns, respectively.  The goal of Caser is to recommend item by considering user general tastes as well as short-term intention.</p>
<h3><span id="factorization-machines">Factorization Machines</span></h3><p> The strengths of factorization machines over the linear regression and matrix factorization are: (1) it can model<br>$\chi$-way variable interactions, where $\chi$<br> is the number of polynomial order and is usually set to two. (2) A fast optimization algorithm associated with factorization machines can reduce the polynomial computation time to linear complexity, making it extremely efficient especially for high dimensional sparse inputs. </p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_recommender-systems/index.html">https://d2l.ai/chapter_recommender-systems/index.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-25T02:36:13.000Z" title="2024-10-25 10:36:13 ├F10: AM┤">2024-10-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-25T02:36:13.629Z" title="2024-10-25 10:36:13 ├F10: AM┤">2024-10-25</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/25/RL1/">RL1</a></p><div class="content"></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/10/">10</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.PNG" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">97</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">24</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/LLM/"><span class="level-start"><span class="level-item">LLM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-science/"><span class="level-start"><span class="level-item">computer science</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/engineering/"><span class="level-start"><span class="level-item">engineering</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-04T13:02:21.000Z">2024-11-04</time></p><p class="title"><a href="/2024/11/04/db0/">db0</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-04T13:02:02.000Z">2024-11-04</time></p><p class="title"><a href="/2024/11/04/op0/">op0</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-04T13:01:31.000Z">2024-11-04</time></p><p class="title"><a href="/2024/11/04/ca0/">ca0</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-04T12:59:32.000Z">2024-11-04</time></p><p class="title"><a href="/2024/11/04/cn0/">计算机网络(1) - IP地址</a></p><p class="categories"><a href="/categories/computer-science/">computer science</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-02T10:11:19.000Z">2024-11-02</time></p><p class="title"><a href="/2024/11/02/algo4/">算法（5）- 比特运算</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">43</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommender-System/"><span class="tag">Recommender System</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-network/"><span class="tag">computer network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2024 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>