<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-12-12T14:22:00.000Z" title="2023-12-12 3:22:00 ├F10: PM┤">2023-12-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-12T17:08:42.096Z" title="2023-12-12 6:08:42 ├F10: PM┤">2023-12-12</time></span><span class="level-item"><a class="link-muted" href="/categories/database/">database</a></span><span class="level-item">3 minutes read (About 454 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/12/12/bigdata12/">bigdata - Cube Data</a></p><div class="content"><h1><span id="on-line-analytic-processingolap">On-Line Analytic Processing(OLAP)</span></h1><p>On-Line Analytic Processing generally involves highly complex queries that use one or more aggregations.</p>
<h2><span id="olap-and-data-warehouses">OLAP and Data Warehouses</span></h2><p>Data from many separate databases may be integrated into the warehouse. The warehouse is usually only updated overnight. Data warehouses play an important role in OLAP applications. First, the warehouse is necessary to organize and centralize data in a way that supports OLAP queries. Second, OLAP queries are usually complex and touching much of the data and take too much time to be executed in a transaction-processing system with high throughput requirements.</p>
<h2><span id="a-multidimensional-view-of-olap-data">A Multidimensional View of OLAP Data</span></h2><p>In typical OLAP applications there is a central relation or collection of data called the fact table. Often, it helps to think of the objects in the fact table as arranged in a multidimensional space. Two broad directions that have been taken by specialized systemns that support cube-structured data for OLAP: ROLAP and MOLAP. ROLAP, which is Relational OLAP. In this approach, data may be stored in relations with a specialized structure called a “star schema”. MOLAP, which is Multidimensional OLAP. A specialized structure “data cude” is used to hold the data, including its aggregates.</p>
<h2><span id="star-schemas">Star Schemas</span></h2><p>A star schema consists of the schema for the fact table, which links to several other relations, called “dimension tables”. </p>
<h2><span id="slicing-and-dicing">Slicing and Dicing</span></h2><p>A choice of partition for each dimension “dices” the cude. The result is that the cude is divided into smaller cubes that represent groups of points whose statistics are aggregated by a query that performs this partitioning in its “group by” clause. Through the “where” clause, a query has the option of focusing on particular partitions alone one or more dimensions.(on a particular “slice” of the cube).<br><img src="/2023/12/12/bigdata12/image-82.png" alt="Alt text"></p>
<p><img src="/2023/12/12/bigdata12/image-83.png" alt="Alt text"></p>
<p><img src="/2023/12/12/bigdata12/image-84.png" alt="Alt text"></p>
<p><img src="/2023/12/12/bigdata12/image-85.png" alt="Alt text"></p>
<h1><span id="data-cubes">Data Cubes</span></h1><p>The formal data cube precomputes all possible aggregates in a systematic way. </p>
<h2><span id="the-cube-operator">The Cube Operator</span></h2><p>Given a fact table F, we can define an augmented table CUBE(F) that adds an additional value, denoted <em>, to each dimension. The </em> has the intuitive meaning “any,” and it represents aggregation along the dimension in which it appears. </p>
<h2><span id="the-cube-operator-in-sql">The Cube Operator in SQL</span></h2><p>SQL gives us a way to apply the cube operator within queries. If we add the term “WITH CUBE” to a group-by clause, then we get not only the tuple for each group, but also the tuples that represent aggregation along one or more of the dimensions along which we have grouped. These tuples appear in the result with NULL where we have used *.<br><img src="/2023/12/12/bigdata12/image-86.png" alt="Alt text"></p>
<p><img src="/2023/12/12/bigdata12/image-87.png" alt="Alt text"></p>
<p>However, SalesRollup wpuld not contain tuples such as<br><img src="/2023/12/12/bigdata12/image-88.png" alt="Alt text"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-12-12T14:21:07.000Z" title="2023-12-12 3:21:07 ├F10: PM┤">2023-12-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-13T20:10:17.476Z" title="2023-12-13 9:10:17 ├F10: PM┤">2023-12-13</time></span><span class="level-item"><a class="link-muted" href="/categories/database/">database</a></span><span class="level-item">9 minutes read (About 1361 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/12/12/bigdata11/">bigdata - Graph Database</a></p><div class="content"><h2><span id="why-graphs">Why graphs</span></h2><p>Now, we do know a way to avoid joins and studied it at length: denormalizing the data to (homogeneous) collections of trees is a way of “pre-computing” the joins statically, so that the data is already joined (via nesting) at runtime.</p>
<p>Now, why is it efficient? Because doing down a tree only necessitates following pointers in memory. But trees cannot have cycles. Graph databases provide a way of generalizing the use in-memory pointers to traverse data to the general case in which cycles are present: this is called “index-free adjacency.”</p>
<h2><span id="kinds-of-graph-databases">Kinds of graph databases</span></h2><p>There are many different graph database system products on the market, and they can be classified along several dimensions: Labeled property graph model vs. triple stores;Read-intensive vs. write-intensive;Local vs. distributed;Native vs. non-native. </p>
<h2><span id="graph-data-models">Graph data models</span></h2><h3><span id="labeled-property-graphs">Labeled property graphs</span></h3><p>Computer scientists need to go one step further and also design how to store graphs physically. One way of doing so is to create an associative array mapping each node to the list of nodes that it connects to via an edge (adjacency lists). Another storage form is with an adjacency matrix: each row and each column represent a node, and a 0 or a 1 indicate the absence or presence of an edge between the row node and the column node. </p>
<p>Now, this does not quite work for us, because labeled property graphs enhance mathematical graphs with extra ingredients: properties, and labels.<br>how to “convert” a relational table to a labeled property graph: labels can be seen as table names, nodes as records, and properties as the attribute values for the records. This shows that relational tables can be physically stored as labeled property graphs. Of course, this does not work the other way round: given a graph, it will often not be possible to convert it “back” to a table in this specific way.</p>
<h3><span id="triple-stores">Triple stores</span></h3><p>Triple stores are a different and simpler model. It views the graph as nodes and edges that all have labels, but without any properties. The graph is then represented as a list of edges, where each edge is a triple with the label of the origin node (called the subject), the label of the edge (called the property), and the label of the destination node (called the object).</p>
<p>Triple stores typically provide SPARQL capabilities to reason about and stored RDF data.</p>
<h2><span id="querying-graph-data">Querying graph data</span></h2><p>We will now have a look at query languages for querying graphs, with a focus on Cypher, which is neo4j’s query language.<br><img src="/2023/12/12/bigdata11/image-89.png" alt="Alt text"></p>
<h3><span id="cypher-philosophy">Cypher Philosophy</span></h3><p>Cypher enables a user (or an application acting on behalf of a user) to ask the database to find data that matches a specific pattern. Colloquially, we ask the database to “find things like this.” And the way we describe what “things like this” look like is to draw them, using ASCII art.</p>
<p>Like most query languages, Cypher is composed of clauses. The simplest queries consist of a MATCH clause followed by a RETURN clause. There are other clauses we can use in a Cypher query: WHERE,WITH…AS…,CREATE,MERGE,DELETE,SET,UNION,FORWACH and so on. </p>
<h3><span id="a-comparison-of-relational-and-graph-modeling">A Comparison of Relational and Graph Modeling</span></h3><p>Relational databases—with their rigid schemas and complex modeling characteristics—are not an especially good tool for supporting rapid change. What we need is a model that is closely aligned with the domain, but that doesn’t sacrifice performance, and that supports evolution while maintaining the integrity of the data as it undergoes rapid change and growth. That model is the graph model.</p>
<h3><span id="creating-a-graph">creating a graph</span></h3><p>In practice, we tend to use CREATE when we’re adding to the graph and don’t mind duplication, and MERGE when duplication is not permitted by the domain.</p>
<h3><span id="beginning-a-query">Beginning a Query</span></h3><p>In Cypher we always begin our queries from one or more well-known starting points in the graph—what are called bound nodes. Cypher uses any labels and property predicates supplied in the MATCH and WHERE clauses, together with metadata supplied by indexes and constraints, to find the starting points that anchor our graph patterns.</p>
<h3><span id="indexes-and-constraints">INDEXES AND CONSTRAINTS</span></h3><p>To support efficient node lookup, Cypher allows us to create indexes per label and property combinations. For unique property values we can also specify constraints that assure uniqueness.</p>
<h1><span id="neo4j">Neo4j</span></h1><p> Neo4j is a graph database with native processing capabilities as well as native graph storage.</p>
<h2><span id="native-graph-processing">Native Graph Processing</span></h2><p>Of the many different engine architectures, we say that a graph database has native processing capabilities if it exhibits a property called index-free adjacency.</p>
<p>A database engine that utilizes index-free adjacency is one in which each node maintains direct references to its adjacent nodes. Each node, therefore, acts as a micro-index of other nearby nodes, which is much cheaper than using global indexes. It means that query times are independent of the total size of the graph, and are instead simply proportional to the amount of the graph searched. A nonnative graph database engine, in contrast, uses (global) indexes to link nodes together.</p>
<p>Proponents for native graph processing argue that index-free adjacency is crucial for fast, efficient graph traversals. To understand why native graph processing is so much more efficient than graphs based on heavy indexing, consider the following. Depending on the implementation, index lookups could be O(log n) in algorithmic complexity versus O(1) for looking up immediate relationships. To traverse a network of m steps, the cost of the indexed approach, at O(m log n), dwarfs the cost of O(m) for an implementation that uses index-free adjacency.</p>
<h2><span id="native-graph-storage">Native Graph Storage</span></h2><p>Neo4j stores graph data in a number of different store files. Each store file contains the data for a specific part of the graph (e.g., there are separate stores for nodes, relationships, labels, and properties).The division of storage responsibilities—particularly the separation of graph structure from property data—facilitates performant graph traversals, even though it means the user’s view of their graph and the actual records on disk are structurally dissimilar.</p>
<p>Like most of the Neo4j store files, the node store is a fixed-size record store, where each record is nine bytes in length. Fixed-size records enable fast lookups for nodes in the store file. If we have a node with id 100, then we know its record begins 900 bytes into the file. Based on this format, the database can directly compute a record’s location, at cost O(1), rather than performing a search, which would be cost O(log n).</p>
<h2><span id="transactions">Transactions</span></h2><p>Transactions in Neo4j are semantically identical to traditional database transactions. Writes occur within a transaction context, with write locks being taken for consistency purposes on any nodes and relationships involved in the transaction. On successful completion of the transaction, changes are flushed to disk for durability, and the write locks released. These actions maintain the atomicity guarantees of the transaction. </p>
<h3><span id="core-api-traversal-framework-or-cypher">CORE API, TRAVERSAL FRAMEWORK, OR CYPHER?</span></h3><p>The Core API allows developers to fine-tune their queries so that they exhibit high affinity with the underlying graph. A well-written Core API query is often faster than any other approach. The downside is that such queries can be verbose, requiring considerable developer effort. Moreover, their high affinity with the underlying graph makes them tightly coupled to its structure. When the graph structure changes, they can often break. Cypher can be more tolerant of structural changes—things such as variable-length paths help mitigate variation and change.</p>
<p>The Traversal Framework is both more loosely coupled than the Core API (because it allows the developer to declare informational goals), and less verbose, and as a result a query written using the Traversal Framework typically requires less developer effort than the equivalent written using the Core API. Because it is a general-purpose framework, however, the Traversal Framework tends to perform marginally less well than a well-written Core API query.</p>
<h2><span id="references">references</span></h2><p>Robinson, I. et al. (2015). Graph Databases (2nd ed.)</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-12-07T14:26:41.000Z" title="2023-12-7 3:26:41 ├F10: PM┤">2023-12-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-07T14:26:41.939Z" title="2023-12-7 3:26:41 ├F10: PM┤">2023-12-07</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/12/07/pai10/">pai10</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-12-07T14:26:12.000Z" title="2023-12-7 3:26:12 ├F10: PM┤">2023-12-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-12T10:42:47.133Z" title="2023-12-12 11:42:47 ├F10: AM┤">2023-12-12</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 247 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/12/07/pai9/">pai - Model-free Approximate Reinforcement Learning</a></p><div class="content"><h1><span id="model-free-approximate-reinforcement-learning">Model-free Approximate Reinforcement Learning</span></h1><h2><span id="tabular-reinforcement-learning-as-optimization">Tabular Reinforcement Learning as Optimization</span></h2><p>In particular, in the tabular setting (i.e., over a discrete domain), we can parameterize the value function exactly by learning a separate parameter for each state.<br><img src="/2023/12/07/pai9/image-77.png" alt="Alt text"></p>
<p><img src="/2023/12/07/pai9/image-78.png" alt="Alt text"></p>
<p>Now, we cannot compute this derivative because we cannot compute the expectation. Firstly, the expectation is over the true value function which is unknown to us. Secondly, the expectation is over the transition model which we are trying to avoid in model-free methods. To resolve the first issue, analogously to TD-learning, instead of learning the true value function vπ which is unknown, we learn the bootstrapping estimate Vπ. To resolve the first issue, analogously to TD-learning, instead of learning the true value function vπ which is unknown, we learn the bootstrapping estimate Vπ. we will use a Monte Carlo estimate using a single sample. Recall that this is only possible because the transitions are conditionally independent given the state-action pair. </p>
<p><img src="/2023/12/07/pai9/image-79.png" alt="Alt text"></p>
<p><img src="/2023/12/07/pai9/image-80.png" alt="Alt text"></p>
<p>Therefore, TD-learning is essentially performing stochastic gradient descent using the TD-error as an unbiased gradient estimate.<br>Stochastic gradient descent with a bootstrapping estimate is also called stochastic semi-gradient descent.</p>
<h2><span id="value-function-approximation">Value Function Approximation</span></h2><h2><span id="sac">SAC</span></h2><h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665">https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665</a><br><a target="_blank" rel="noopener" href="https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/06-sac.ipynb">https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/06-sac.ipynb</a><br><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/algorithms/sac.html">https://spinningup.openai.com/en/latest/algorithms/sac.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-28T20:58:26.000Z" title="2023-11-28 9:58:26 ├F10: PM┤">2023-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-12T15:35:16.899Z" title="2023-12-12 4:35:16 ├F10: PM┤">2023-12-12</time></span><span class="level-item"><a class="link-muted" href="/categories/database/">database</a></span><span class="level-item">17 minutes read (About 2564 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/28/bigdata10/">bigdata - JSONiq</a></p><div class="content"><h1><span id="querying-denormalized-data">Querying denormalized data</span></h1><h2><span id="imperative-vs-declarative">imperative vs declarative</span></h2><p>Imperative programming is a programming paradigm that expresses computation as a series of statements that change a program’s state. In imperative programming, the focus is on describing how a program operates step by step. Common imperative languages include C, C++, Java, and Python.</p>
<p>In contrast to imperative programming, declarative programming focuses on describing what the program should accomplish rather than how to achieve it. In a declarative host language, the emphasis is on specifying the desired outcome or properties, and the language itself takes care of the underlying implementation details. Such as SQL, HTML.</p>
<h2><span id="motivation">motivation</span></h2><h3><span id="denormalized-data">Denormalized data</span></h3><p>it is characterized with two features: nestedness, and heterogeneity. In fact, denormalized datasets should not be seen as “broken tables pushed to their limits”, but rather as collections of trees. </p>
<h3><span id="features-of-a-query-language">Features of a query language</span></h3><p>A query language for datasets has three main features: Declarative, Functional, and Set-based. First, it is declarative. This means that the users do not focus on how the query is computed, but on what it should return. Being functional means that the query language is made of composable expressions that nest with each other, like a Lego game. Finally, it is set-based, in the sense that the values taken and returned by expressions are not only single values (scalars), but are large sequences of items (in the case of SQL, an item is a row).</p>
<h3><span id="query-languages-for-denormalized-data">Query languages for denormalized data</span></h3><p>For denormalized data though, sadly, the number of languages keeps increasing: the oldest ones being XQuery, JSONiq, but then now also JMESPath, SpahQL, JSON Query, PartiQL, UnQL, N1QL, ObjectPath, JSONPath, ArangoDB Query Language (AQL), SQL++, GraphQL, MRQL, Asterix Query Language (AQL), RQL.</p>
<h3><span id="jsoniq-as-a-data-calculator">JSONiq as a data calculator</span></h3><p>it can perform arithmetics, but also comparison and logic. It is, however, more powerful than a common calculator and supports more complex constructs, for example variable binding.<br>It also supports all JSON values. Any copy-pasted JSON value literally returns itself.<br>And, unlike a calculator, it can access storage. </p>
<h2><span id="the-jsoniq-data-model">The JSONiq Data Model</span></h2><p>Every expression of the JSONiq “data calculator” returns a sequence of items.An item can be either an object, an array, an atomic item, or a function item. A sequence can also be empty. Caution, the empty sequence is not the same logically as a null item.</p>
<h2><span id="navigation">Navigation</span></h2><p>The general idea of navigation is that it is possible to “dive” into the nested data with dots and square brackets (originally, these were slashes with XPath) – all in parallel: starting with an original collection of objects (or, possibly, a single document), each step (i.e., for each dot and each pair of square brackets) goes down the nested structure and returns another sequence of nested items. </p>
<h3><span id="object-lookups-dot-syntax">Object lookups (dot syntax)</span></h3><p>json-doc(“file.json”).o</p>
<h3><span id="array-unboxing-empty-square-bracket-syntax">Array unboxing (empty square bracket syntax)</span></h3><p>We can unbox the array, meaning, extract its members as a sequence of seven object items, with empty square brackets.json-doc(“file.json”).o[].</p>
<h3><span id="parallel-navigation">Parallel navigation</span></h3><p>The dot syntax, in fact, works on sequences, too and will extract the value associated with a key in every object of the sequence (anything else than an object is ignored and thrown away).</p>
<h3><span id="filtering-with-predicates-simple-square-bracket-syntax">Filtering with predicates (simple square bracket syntax)</span></h3><p>It is possible to filter any sequence with a predicate, where <script type="math/tex">in the predicate refers to the current item being tested. json-doc("file.json").o[].a.b[][</script>.c = 3].It is also possible to access the item at position n in a sequence with this same notation: json-doc(“file.json”).o[].a.b[][5].</p>
<h3><span id="array-lookup-double-square-bracket-syntax">Array lookup (double square bracket syntax)</span></h3><p>To access the n-th member of an array, you can use double-squarebrackets, like so:<br>json-doc(“file.json”).o[[2]].a.</p>
<h3><span id="a-common-pitfall-array-lookup-vs-sequence-predicates">A common pitfall: Array lookup vs. Sequence predicates</span></h3><p>Do not confuse sequence positions (single square brackets) with array positions (double square brackets)!<br>([1, 2], [3, 4])[2] -&gt; [ 3, 4 ]<br>([1, 2], [3, 4])[[2]] -&gt; 2 4</p>
<h2><span id="schema-discovery">Schema discovery</span></h2><h3><span id="collections">Collections</span></h3><p>many datasets are in fact found in the form of large collections of smaller objects (as in document stores). Such collections are access with a function call together with a name or (if reading from a data lake) a path.</p>
<h3><span id="getting-all-top-level-keys">Getting all top-level keys</span></h3><p>The keys function retrieves all keys. It can be called on the entire sequence of objects and will return all unique keys found (at the top level) in that collection.</p>
<h3><span id="getting-unique-values-associated-with-a-key">Getting unique values associated with a key</span></h3><p>With distinct-values, it is then possible to eliminate duplicates and look at unique values:<br>distinct-values(collection( “<a target="_blank" rel="noopener" href="https://www.rumbledb.org/samples/git-archive.jsonl">https://www.rumbledb.org/samples/git-archive.jsonl</a>“ ).type)</p>
<h3><span id="aggregations">Aggregations</span></h3><p>Aggregations can be made on entire sequences with a single function call:The five basic functions are count, sum, avg, min, max.<br>count(distinct-values(collection( “<a target="_blank" rel="noopener" href="https://www.rumbledb.org/samples/git-archive.jsonl">https://www.rumbledb.org/samples/git-archive.jsonl</a>“ ).type))</p>
<h2><span id="construction">Construction</span></h2><h3><span id="construction-of-atomic-values">Construction of atomic values</span></h3><p>Atomic values that are core to JSON can be constructed with exactly the same syntax as JSON.</p>
<h3><span id="construction-of-objects-and-arrays">Construction of objects and arrays</span></h3><p>In fact, one can copy-paste any JSON value, and it will always be recognized as a valid JSONiq query returning that value.</p>
<h3><span id="construction-of-sequences">Construction of sequences</span></h3><p>Sequences can be constructed (and concatenated) using commas.Increasing sequences of integers can also be built with the to keyword.</p>
<h2><span id="scalar-expressions">Scalar expressions</span></h2><p>Sequences of items can have any number of items. A few JSONiq expression (arithmetic, logic, value comparison…) work on the particular case that a sequence has zero or one items.</p>
<h3><span id="arithmetic">Arithmetic</span></h3><p>JSONiq supports basic arithmetic: addition (+), subtraction (-), division (div), integer division (idiv) and modulo (mod).If the data types are different, then conversions are made automatically. The empty sequence enjoys special treatment: if one of the sides (or both) is the empty sequence, then the arithmetic expression returns an empty sequence (no error). If one of the two sides is null (and the other side is not the empty sequence), then the arithmetic expression returns null. If one of the sides (or both) is not a number, null, or the empty sequence, then a type error is thrown.</p>
<h3><span id="string-manipulation">String manipulation</span></h3><p>String concatenation is done with a double vertical bar: “foo” || “bar”.<br>Most other string manipulation primitives are available from the rich JSONiq builtin function library:<br>concat(“foo”, “bar”),string-join((“foo”, “bar”, “foobar”), “-“),substr(“foobar”, 4, 3),<br>string-length(“foobar”). </p>
<h3><span id="value-comparison">Value comparison</span></h3><p>Sequences of one atomic item can be compared with eq (equal), ne (not equal), le (lower or equal), gt (greater or equal), lt (lower than) and gt (greater than).</p>
<h3><span id="logic">Logic</span></h3><p>JSONiq supports the three basic logic expressions and, or, and not. not has the highest precedence, then and, then or.<br>JSONiq also supports universal and existential quantification:<br>every $i in 1 to 10 satisfies $i gt 0, some $i in 1 to 10 satisfies $i gt 5. </p>
<p>If one of the two sides is not a sequence of a single Boolean item, then implicit conversions are made. This mechanism is called the Effective Boolean Value (EBV). For example, an empty sequence, or a sequence of one empty string, or a sequence of one zero integer, is considered false. A sequence of one non-empty string, or a sequence or one non-zero integer, or a sequence starting with one object (or array) is considered true.</p>
<h3><span id="general-comparison">General comparison</span></h3><p>JSONiq has a shortcut for existential quantification on value comparisons. This is called general comparison.</p>
<p>some $i in (1, 2, 3, 4, 5) satisfies $i eq 1 ==<br>(1, 2, 3, 4, 5) = 1.</p>
<h2><span id="composability">Composability</span></h2><h3><span id="data-flow">Data flow</span></h3><p>A few expressions give some control over the data flow by picking the output or this or that expression based on the value of another expression. This includes conditional expressions. This includes conditional expressions. This also includes try-catch expressions.</p>
<h2><span id="binding-variables-with-cascades-of-let-clauses">Binding variables with cascades of let clauses</span></h2><p>Variables in JSONiq start with a dollar sign. It is important to understand that this is not a variable assignment that would change the value of a variable. This is only a declarative binding. </p>
<h2><span id="flwor-expressions">FLWOR expressions</span></h2><p>One of the most important and powerful features of JSONiq is the FLWOR expression. It corresponds to SELECT-FROM-WHERE queries in SQL, however, it is considerably more expressive and generic than them in several aspects. In JSONiq the clauses can appear in any order with the exception of the first and last clause. JSONiq supports a let clause, which does not exist in SQL.<br>In SQL, when iterating over multiple tables in the FROM clause, they “do not see each other”. In JSONiq, for clauses (which correspond to FROM clauses in SQL), do see each other, meaning that it is possible to iterate in higher and higher levels of nesting by referring to a previous for variable.</p>
<h3><span id="for-clauses">For clauses</span></h3><p>It can thus be seen that the for clause is akin to the FROM clause in SQL, and the return is akin to the SELECT clause. Projection in JSONiq can be made with a project() function call, with the keys to keep.  It is possible to implement a join with a sequence of two for clauses and a predicate. Note that allowing empty can be used to perform a left outer join, i.e., to account for the case when there are no matching records in the second collection. </p>
<h3><span id="let-clauses">Let clauses</span></h3><p>A let clause outputs exactly one outgoing tuple for each incoming tuple (think of a map transformation in Spark). Let clauses also allow for joining the two datasets. </p>
<h3><span id="where-clauses">Where clauses</span></h3><p>Where clauses are used to filter variable bindings (tuples) based on a predicate on these variables. They are the equivalent to a WHERE clause in SQL.</p>
<h3><span id="order-by-clauses">Order by clauses</span></h3><p>Order by clauses are used to reorganize the order of the tuples, but without altering them. They are the same as ORDER BY clauses in SQL.It is also possible, like in SQL, to specify an ascending or a descending order. In case of ties between tuples, the order is arbitrary. But it is possible to sort on another variable in case there is a tie with the first one (compound sorting keys). It is possible to control what to do with empty sequences: they can be considered smallest or greatest.</p>
<h3><span id="group-by-clauses">Group by clauses</span></h3><p>Group by clauses organize tuples in groups based on matching keys, and then output only one tuple for each group, aggregating other variables (count, sum, max, min…). It is also possible to opt out of aggregating other (non-grouping-key) variables.</p>
<h2><span id="types">Types</span></h2><h3><span id="variable-types">Variable types</span></h3><p>Since every value in JSONiq is a sequence of item, a sequence type consists of two parts: an item type, and a cardinality.<br>Item types can be any of the builtin atomic types. as well as “object”, “array” and the most generic item type, “item”.<br>Cardinality can be one of the following four:Any number of items (suffix <em>); for example object</em>, One or more items (suffix +); for example array+,Zero or one item (suffix ?); for example integer,Exactly one item (no suffix); for example boolean?</p>
<h3><span id="type-expressions">Type expressions</span></h3><p>An “instance of” expression checks whether a sequences matches a sequence type, and returns true or false. A “cast as” expression casts single items to an expected item type.<br>A “castable as” expression tests whether a cast would succeed (in which case it returns true) or not (false).<br>A “treat as” expression checks whether its input sequence matches an expected type (like a type on a variable); if it does, the input sequence is returned unchanged. If not, an error is raised.</p>
<h3><span id="types-in-user-defined-functions">Types in user-defined functions</span></h3><p>JSONiq supports user-defined functions. Parameter types can be optionally specified, and a return type can also be optionally specified.</p>
<h3><span id="validating-against-a-schema">Validating against a schema</span></h3><p>It is possible to declare a schema, associating it with a user-defined type, and to validate a sequence of items against this user-defined type.</p>
<h2><span id="architecture-of-a-query-engine">Architecture of a query engine</span></h2><h3><span id="static-phase">Static phase</span></h3><p>When a query is received by an engine, it is text that needs to be parsed. The output of this is a tree structure called an Abstract Syntax Tree. An Abstract Syntax Tree, even though it already has the structure of a tree, is tightly tied to the original syntax. Thus, it needs to be converted into a more abstract Intermediate Representation called an expression tree. Every node in this tree corresponds to either an expression or a clause in the JSONiq language, making the design modular. At this point, static typing takes place, meaning that the engine infers the static type of each expression, that is, the most specific type possible expected at runtime (but without actually running the program). Engines like RumbleDB perform their optimization round on this Intermediate Representation. Once optimizations have been done, RumbleDB decides the mode with which each expression and clause will be evaluated (locally, sequentially, in parallel, in DataFrames, etc). The resulting expression tree is then converted to a runtime iterator tree; this is the query plan that will actually be evaluated by the engine.</p>
<h3><span id="dynamic-phase">Dynamic phase</span></h3><p>During the dynamic phase, the root of the tree is asked to produce a sequence of items, which is to be the final output of the query as a whole. Then, recursively, each node in the tree will ask its children to produce sequences of items (or tuple streams). Each node then combines the sequences of items (or tuple streams) it receives from its children in order to produce its own sequence of items according to its semantics, and pass it to its parent. </p>
<h4><span id="materialization">Materialization</span></h4><p>When a sequence of items is materialized, it means that an actual List (or Array, or Vector), native to the language of implementation (in this case Java) is stored in local memory, filled with the items. </p>
<h4><span id="streaming">Streaming</span></h4><p>When a sequence of items (or tuple stream) is produced and consumed in a streaming fashion, it means that the items (or tuples) are produced and consumed one by one, iteratively. But the whole sequence of items (or tuple stream) is never stored anywhere. The classical pattern for doing so is known as the Volcano iterator architecture.</p>
<p>However, there are two problems with this: first, it can take a lot of time to go through the entire sequence (imagine doing so with billions or trillions of items). Second, there are expressions or clauses that are not compatible with streaming (consider, for example, the group by or order by clause, which cannot be implemented without materializing their full input).</p>
<h4><span id="parallel-execution-with-rdds">Parallel execution (with RDDs)</span></h4><p>When a sequence becomes unreasonably large, RumbleDB switches to a parallel execution, leveraging Spark capabilities: the sequences of items are passed and processed as RDDs of Item objects.</p>
<h4><span id="parallel-execution-with-dataframes">Parallel execution (with DataFrames)</span></h4><p>The RDD implementation supports heterogeneous sequences by leveraging the polymorphism of Item objects. However, this is not efficient in the case that Items in the same sequence happen to have a regular structure. Thus, if the Items in a sequence are valid against a specific schema, or even against an array type or an atomic type, the underlying physical storage in memory relies on Spark DataFrames instead of RDDs.</p>
<p>To summarize, homogeneous sequences of the most common types are stored in DataFrames, and RDDs are used in all other cases.</p>
<h4><span id="parallel-execution-with-native-sql">Parallel execution (with Native SQL)</span></h4><p>In some cases (more in every release), RumbleDB is able to evaluate the query using only Spark SQL, compiling JSONiq to SQL directly instead of packing Java runtime iterators in UDFs. This leads to faster execution, because UDFs are slower than a native execution in SQL. This is because, to a SQL optimizer, UDFs are opaque and prevent automatic optimizations.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-28T13:19:33.000Z" title="2023-11-28 2:19:33 ├F10: PM┤">2023-11-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-12T15:35:34.301Z" title="2023-12-12 4:35:34 ├F10: PM┤">2023-12-12</time></span><span class="level-item"><a class="link-muted" href="/categories/database/">database</a></span><span class="level-item">17 minutes read (About 2537 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/28/bigdata9/">bigdata - MongoDB</a></p><div class="content"><h1><span id="document-stores">Document stores</span></h1><p>Can we rebuild a similar system for collections of trees, in the sense that we drop all three constraints: relational integrity, domain integrity, and atomic integrity? Document stores bring us one step in this direction.</p>
<h2><span id="challenges">Challenges</span></h2><h3><span id="schema-on-read">Schema on read</span></h3><p>In a relational database management system, it is not possible to populate a table without having defined its schema first. However, when encountering such denormalized data, in the real world, there is often no schema. In fact, one of the important features of a system that deals with denormalized data is the ability to discover a schema.</p>
<h3><span id="making-trees-fit-in-tables">Making trees fit in tables</span></h3><p>Several XML elements (or, likewise, several JSON objects) can be naturally mapped to a relational table with several rows if the collection is flat and homogeneous, but semi-structured data can generally be nested and heterogeneous. if we map nested and heterogeneous into a table,such mapping will at best have to be done for every single dataset, and requires in most cases a schema, whereas we are looking for a generic solution for semistructured data with no a-priori schema information.</p>
<h2><span id="document-stores">Document stores</span></h2><p>Document stores provide a native database management system for semi-structured data. Document stores work on collections of records, generalizing the way that relational tables can be seen as collections of rows. It is important to understand that document stores are optimized for the typical use cases of many records of small to medium sizes. Typically, a collection can have millions or billions of documents, while each single document weighs no more than 16 MB (or a size in a similar magnitude). Finally, a collection of documents need not have a schema: it is possible to insert random documents that have dissimilar structures with no problem at all. Most document stores, however, do provide the ability to add a schema. Document stores can generally do selection, projection, aggregation and sorting quite well, but many of them are typically not (yet) optimized for joining collections. In fact, often, their language or API does not offer any joining functionality at all, which pushes the burden to reimplement joins in a host language to the users. This is a serious breach of data independence.</p>
<h2><span id="implementations">Implementations</span></h2><p>There is a very large number of products in the document store space for both JSON and XML, let us mention for example MongoDB, CouchDB, ElasticSearch, Cloudant, existDB, ArangoDB, BaseX, MarkLogic, DocumentDB, CosmosDB, and so on. We will focus, as an example, on MongoDB.</p>
<h2><span id="physical-storage">Physical storage</span></h2><p>Just like the storage format is optimized for tabular data in a relational database management system, it is optimized for tree-like data in a document store. In MongoDB, the format is a binary version of JSON called BSON. BSON is basically based on a sequence of tokens that efficiently encode the JSON constructs found in a document. The immediate benefit of BSON is that it takes less space in storage than JSON stored as a text file: for example, null, true and false literals need four or five bytes in text format at best, while they can be efficiently encoded as single bytes in BSON. Furthermore, BSON supports additional types that JSON does not have, such as dates. </p>
<h2><span id="querying-paradigm-crud">Querying paradigm (CRUD)</span></h2><p>The API of MongoDB, like many document stores, is based on the CRUD paradigm. CRUD means Create, Read, Update, Delete and corresponds to low-level primitives similar to those for HBase. MongoDB supports several host languages to query collections via an API. This includes in particular JavaScript and Python, but many other languages are supported via drivers. We will use JavaScript here because this is the native host language of MongoDB. It is important to note that these APIs are not query languages. MongoDB also provides access to the data via a shall called mongo or, newly, mongosh. This is a simple JavaScript interface wrapped around the MongoDB’s node.js driver. </p>
<h3><span id="populating-a-collection">Populating a collection</span></h3><p>To create a collection, one can simply insert a document in it, and it will be automatically created if it does not exist.</p>
<p>MongoDB automatically adds to every inserted document a special field called “ id” and associated with a value called an Object ID and with a type of its own.Object IDs are convenient for deleting or updating a specific document with no ambiguity.</p>
<h3><span id="querying-a-collection">Querying a collection</span></h3><h4><span id="scan-a-collection">Scan a collection</span></h4><p>Asking for the contents of an entire collection is done with a simple find() call on the previous object:db.collection.find().This function does not in fact return the entire collection; rather, it returns some pointer, called a cursor, to the collection; the user can then iterate on the cursor in an imperative fashion in the host language.</p>
<h4><span id="selection">Selection</span></h4><p>It is possible to perform a selection on a collection by passing a parameter to find() that is a JSON object:<br>db.collection.find({ “Theory” : “Relativity” }). </p>
<p>A disjunction (OR) uses a special MongoDB keyword, prefixed with a dollar sign:<br>db.collection.find( { “$or” : [ { “Theory”:”Relativity” }, { “Last”:”Einstein” } ] } ).</p>
<p>MongoDB offers many other keywords, for example for comparison other than equality:<br>db.collection.find( { “Publications” : { “$gte” : 100 } } )</p>
<h4><span id="projection">Projection</span></h4><p>Projections are made with the second parameter of this same find() method. This is done in form of a JSON object associating all the desired keys in the projection with the value 1. db.scientists.find( { “Theory” : “Relativity” }, { “First” : 1, “Last”: 1 } ).</p>
<p>It is also possible to project fields away in the same way with 0s, however 1s and 0s cannot be mixed in the projection parameter, except in the specific above case of projecting away the object ID</p>
<h4><span id="counting">Counting</span></h4><p>Counting can be done by chaining a count() method call:<br>db.scientists.find( { “Theory” : “Relativity” } ).count().</p>
<h4><span id="sorting">Sorting</span></h4><p>Sorting can be done by chaining a sort() method call.<br>db.scientists.find( { “Theory” : “Relativity” }, { “First” : 1, “Last” : 1 } ).sort( { “First” : 1, “Name” : -1 } )</p>
<p>1 is for ascending order and -1 for descending order.It is also possible to add limits and offsets to paginate results also by chaining more method calls:<br>db.scientists.find( { “Theory” : “Relativity” }, { “First” : 1, “Last” : 1 } ).sort( { “First” : 1, “Name” : -1 } ).skip(30).limit(10).</p>
<p>Note that, contrary to intuition, the order of the calls does not matter, as this is really just the creation of a query plan by providing parameters (in any order).</p>
<h4><span id="duplicate-elimination">Duplicate elimination</span></h4><p>It is possible to obtain all the distinct values for one field with a distinct() call: db.scientists.distinct(“Theory”)</p>
<h3><span id="querying-for-heterogeneity">Querying for heterogeneity</span></h3><h4><span id="absent-fields">Absent fields</span></h4><p>Absent fields can be filtered with: db.scientists.find( { “Theory” : null } ). </p>
<h4><span id="filtering-for-values-across-types">Filtering for values across types</span></h4><p>db.collection.find( { “$or” : [ { “Theory”: “Relativity” }, { “Theory”: 42 }, { “Theory”: null } ] } )</p>
<p>db.scientists.find( { “Theory” : { “$in” : [“Relativity”, 42, null ] } } ).</p>
<p>MongoDB is also able to sort on fields that have heterogeneous data types. It does so by first order by type in some (arbitrary, but documented) order, and then within each type.</p>
<h3><span id="querying-for-nestedness">Querying for nestedness</span></h3><p>Nestedness in MongoDB is handled in several ad-hoc ways for specific use cases.</p>
<h4><span id="values-in-nested-objects">Values in nested objects</span></h4><p>We saw how to select documents based on values associated with a top-level keys. What about values that are not at the top-level, but in nested objects?<br>The first solution that might come to mind is something like this: db.scientists.find({ “Name” : { “First” : “Albert” } }) However, this query will not have the behavior many would have expected: instead of finding documents that have a value “Albert” associated with the key “First” in an object itself associated with the top-level key ”Name”, this query looks for an exact match of the entire object.<br>In order to include documents such as above, MongoDB uses a dot syntax: db.scientists.find({ “Name.First” : “Albert” }).</p>
<h4><span id="values-in-nested-arrays">Values in nested arrays</span></h4><p>MongoDB allows to filter documents based on whether a nested array contains a specific value, like so: db.scientists.find({ “Theories” : “Special relativity” }). </p>
<h4><span id="deleting-objects-from-a-collection">Deleting objects from a collection</span></h4><p>Objects can be deleted from a collection either one at a time with deleteOne(), or several at a time with deleteMany(): db.scientists.deleteMany( { “century” : “15” } ). </p>
<h4><span id="updating-objects-in-a-collection">Updating objects in a collection</span></h4><p>Documents can be updated with updateOne() and updateMany() by providing both a filtering criterion (with the same syntax as the first parameter of find()) and an update to apply. The command looks like so: db.scientists.updateMany( { “Last” : “Einstein” }, { $set : { “Century” : “20” } } ).</p>
<p>The granularity of updates is per document, that is, a single document can be updated by at most one query at the same time.However, within the same collection, several different documents can be modified concurrently by different queries in parallel.</p>
<h4><span id="complex-pipelines">Complex pipelines</span></h4><p>For grouping and such more complex queries, MongoDB provides an API in the form of aggregation pipelines.<br>db.scientists.aggregate( { $match : { “Century” : 20 }}, { $group : { “Year” : “$year”, “Count” : { “$sum” : 1 } } }, { $sort : { “Count” : -1 } }, { $limit : 5 } ).</p>
<h3><span id="limitations-of-a-document-store-querying-api">Limitations of a document store querying API</span></h3><p>Simple use cases are straightforward to handle, however more complex use cases require a lot of additional code in the host language, be it JavaScript or Python. An example is that joins must be taken care of by the end user in the host language: the burden of implementing more complex use cases is pushed to the end user.</p>
<h2><span id="architecture">Architecture</span></h2><p>The architecture of MongoDB follows similar principles to what we covered before: scaling out the hardware to multiple machine, and sharding as well as replicating the data.</p>
<h3><span id="sharding-collections">Sharding collections</span></h3><p>Collections in MongoDB can be sharded. Shards are determined by selecting one or several fields. (Lexicographically-ordered) intervals over these fields then determine the shards. The fields used to shard must be organized in a tree index structure.</p>
<h3><span id="replica-sets">Replica sets</span></h3><p>A replica set is a set of several nodes running the MongoDB server process. The nodes within the same replica set all have a copy of the same data.</p>
<p>Each shard of each collection is assigned to exactly one replica set. Note that this architecture is not the same as that of HDFS, in which the replicas are spread over the entire cluster with no notion of “walls” between replica sets and no two DataNodes having the exact same block replicas.</p>
<h3><span id="write-concerns">Write concerns</span></h3><p>When writing (be it delete, update or insert) to a collection, more exactly, to a specific shard of a collection, MongoDB checks that a specific minimum number of nodes (within the replica set that is responsible for the shard) have successfully performed the update.</p>
<h3><span id="motivation">Motivation</span></h3><p>A document store, unlike a data lake, manages the physical data layout. This has a cost: the need to import (ETL) data before it is possible to query it, but this cost comes with a nice benefit: index support, just like relational database management systems.</p>
<h3><span id="hash-indices">Hash indices</span></h3><p>Hash indices are used to optimize point queries and more generally query that select on a specific value of a field. The general idea is that all the values that a field takes in a specific collection can be hashed to an integer. The value, together with pointers to the corresponding documents, is then placed in a physical array in memory, at the position corresponding to this integer.</p>
<h3><span id="tree-indices">Tree indices</span></h3><p>Hash indices are great and fast, but have limitations: first, they consume space. The more one wants to avoid hash collisions, the larger the array needs to be. But more importantly, hash indices cannot support range queries. This is because hashes do not preserve the order of the values and distribute them “randomly” in the index array structure.</p>
<p>Range queries are supported with tree indices. Instead of an array, tree indices use some sort of tree structure in which they arrange the possible values of the indexed field, such that the values are ordered when traversing the tree in a depth-first-search manner. More precisely, the structure is called a B+-tree. Unlike a simple binary tree, nodes have a large number of children.</p>
<h3><span id="secondary-indices">Secondary indices</span></h3><p>By default, MongoDB always builds a tree index for the id field. Users can request to build hash and tree indices for more fields. These indices are called secondary indices.</p>
<p>The command for building a hash index looks like so: db.scientists.createIndex({ “Name.Last” : “hash” })</p>
<p>And for a tree index (1 means in ascending order, -1 would be descending): db.scientists.createIndex({ “Name.Last” : 1 }).</p>
<h3><span id="when-are-indices-useful">When are indices useful</span></h3><p>When building indices, it is important to get a feeling for whether a query will be faster or not with this index.</p>
<h3><span id="index-types">index types</span></h3><h4><span id="single-field-indexes">Single Field Indexes</span></h4><p>By default, all collections have an index on the _id field. You can add additional indexes to speed up important queries and operations. You can create a single-field index on any field in a document, including:Top-level document fields, Embedded documents ,Fields within embedded documents. When you create an index on an embedded document, only queries that specify the entire embedded document use the index. Queries on a specific field within the document do not use the index. In order for a dot notation query to use an index, you must create an index on the specific embedded field you are querying, not the entire embedded object. </p>
<h4><span id="compound-indexes">Compound Indexes</span></h4><p>Compound indexes collect and sort data from two or more fields in each document in a collection. Data is grouped by the first field in the index and then by each subsequent field.</p>
<p>The order of the indexed fields impacts the effectiveness of a compound index. Compound indexes contain references to documents according to the order of the fields in the index. To create efficient compound indexes, follow the ESR (Equality, Sort, Range) rule. The ESR (Equality, Sort, Range) Rule is to place fields that require exact matches first in your index. Sort follows equality matches because the equality matches reduce the number of documents that need to be sorted. Sorting after the equality matches also allows MongoDB to do a non-blocking sort. “Range” filters scan fields. The scan doesn’t require an exact match, which means range filters are loosely bound to index keys. To improve query efficiency, make the range bounds as tight as possible and use equality matches to limit the number of documents that must be scanned. MongoDB cannot do an index sort on the results of a range filter. Place the range filter after the sort predicate so MongoDB can use a non-blocking index sort.  </p>
<p>Compound indexes cannot support queries where the sort order does not match the index or the reverse of the index. </p>
<p>Index prefixes are the beginning subsets of indexed fields. Compound indexes support queries on all fields included in the index prefix. Index fields are parsed in order; if a query omits an index prefix, it is unable to use any index fields that follow that prefix.</p>
<h4><span id="multikey-indexes">Multikey Indexes</span></h4><p>Multikey indexes collect and sort data from fields containing array values. Multikey indexes improve performance for queries on array fields.</p>
<p>In a compound multikey index, each indexed document can have at most one indexed field whose value is an array. </p>
<h2><span id="exercise">exercise</span></h2><h3><span id="data-model">data model</span></h3><h4><span id="embedded-data-models">Embedded Data Models</span></h4><p>In general, embedding provides better performance for read operations, as well as the ability to request and retrieve related data in a single database operation. Embedded data models make it possible to update related data in a single atomic write operation.</p>
<h4><span id="normalized-data-models">Normalized Data Models</span></h4><p>Normalized data models describe relationships using references between documents.</p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://www.mongodb.com/docs/manual/core/data-model-design/">https://www.mongodb.com/docs/manual/core/data-model-design/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-17T15:56:37.000Z" title="2023-11-17 4:56:37 ├F10: PM┤">2023-11-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-07T20:28:48.516Z" title="2023-12-7 9:28:48 ├F10: PM┤">2023-12-07</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">8 minutes read (About 1193 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/17/pai8/">pai - Tabular Reinforcement Learning</a></p><div class="content"><h1><span id="tabular-reinforcement-learning">Tabular Reinforcement Learning</span></h1><h2><span id="the-reinforcement-learning-problem">The Reinforcement Learning Problem</span></h2><p>Reinforcement learning is concerned with probabilistic planning in unknown environments. In this chapter, we will begin by considering reinforcement learning with small state and action spaces. This setting is often called the tabular setting, as the value functions can be computed exhaustively for all states and stored in a table.</p>
<p>Clearly, the agent needs to trade exploring and learning about the environment with exploiting its knowledge to maximize rewards. In fact, Bayesian optimization can be viewed as reinforcement learning with a fixed state and a continuous action space: In each round, the agent plays an action, aiming to find the action that maximizes the reward.Another key challenge of reinforcement learning is that the observed data is dependent on the played actions.</p>
<h3><span id="trajectories">Trajectories</span></h3><p><img src="/2023/11/17/pai8/image-64.png" alt="Alt text"></p>
<p>Crucially, the newly observed states xt+1 and the rewards rt (across multiple transitions) are conditionally independent given the previous states xt and actions at. This independence property is crucial for being able to learn about the underlying Markov decision process. Notably, this implies that we can apply the law of large numbers (1.83) and Hoeffding’s inequality (1.87) to our estimators of both quantities.</p>
<p>The collection of data is commonly classified into two settings. In the episodic setting, the agent performs a sequence of “training” rounds (called episodes). In the beginning of each round, the agent is reset to some initial state. In contrast, in the continuous setting (or non-episodic,or online setting), the agent learns online. </p>
<h3><span id="control">control</span></h3><p>Another important distinction in how data is collected, is the distinction between on-policy and off-policy control. As the names suggest, on-policy methods are used when the agent has control over its own actions, in other words, the agent can freely choose to follow any policy. In contrast, off-policy methods can be used even when the agent cannot freely choose its actions. Off-policy methods are therefore able to make use of observational data.Off-policy methods are therefore more sample-efficient than on-policy methods. This is crucial, especially in settings where conducting experiments (i.e., collecting new data) is expensive.</p>
<p>On-Policy learning algorithms are the algorithms that evaluate and improve the same policy which is being used to select actions. Off-Policy learning algorithms evaluate and improve a policy that is different from Policy that is used for action selection.</p>
<p>To understand the difference between on-policy learning and off-policy learning one must first understand the difference between the behavior policy (i.e., sampling policy) and the update policy. The behavior policy is the policy an agent follows when choosing which action to take in the environment at each time step. The update policy is how the agent updates the Q-function. On-policy algorithms attempt to improve upon the current behavior policy that is used to make decisions and therefore these algorithms learn the value of the policy carried out by the agent, Off-policy algorithms learn the value of the optimal policy and can improve upon a policy that is different from the behavior policy. Determining if the update and behavior policy are the same or different can give us insight into whether or not the algorithm is on-policy or off-policy.</p>
<h2><span id="model-based-approaches">Model-based Approaches</span></h2><p>Approaches to reinforcement learning are largely categorized into two classes. Model-based approaches aim to learn the underlying Markov decision process. In contrast, model-free approaches learn the value function directly.</p>
<h3><span id="learning-the-underlying-markov-decision-process">Learning the Underlying Markov Decision Process</span></h3><p>A natural first idea is to use maximum likelihood estimation to approximate transition and reward function.</p>
<p><img src="/2023/11/17/pai8/image-65.png" alt="Alt text"></p>
<h3><span id="ε-greedy-algorithm">ε-greedy Algorithm</span></h3><p><img src="/2023/11/17/pai8/image-66.png" alt="Alt text"></p>
<p>The key problem of ε-greedy is that it explores the state space in an uninformed manner. In other words, it explores ignoring all past experience. It thus does not eliminate clearly suboptimal actions.</p>
<h3><span id="rmax-algorithm">Rmax Algorithm</span></h3><p>A key principle in effectively trading exploration and exploitation is “optimism in the face of uncertainty”. Let us apply this principle to the reinforcement learning setting. The key idea is to assume that the dynamics and rewards model “work in our favor” until we have learned “good estimates” of the true dynamics and rewards. </p>
<p><img src="/2023/11/17/pai8/image-67.png" alt="Alt text"></p>
<p>How many transitions are “enough”? We can use Hoeffding’s inequality to get a rough idea!</p>
<p><img src="/2023/11/17/pai8/image-68.png" alt="Alt text"></p>
<h3><span id="challenges">challenges</span></h3><h2><span id="model-free-approaches">Model-free Approaches</span></h2><p>A significant benefit to model-based reinforcement learning is that it is inherently off-policy. That is, any trajectory regardless of the policy used to obtain it can be used to improve the model of the underlying Markov decision process. In the model-free setting, this not necessarily true.</p>
<h3><span id="on-policy-value-estimation">On-policy Value Estimation</span></h3><p><img src="/2023/11/17/pai8/image-71.png" alt="Alt text"></p>
<p>Note that to estimate this expectation we use a single(!) sample.However, there is one significant problem in this approximation. Our approximation of vπ does in turn depend on the (unknown) true value of vπ. The key idea is to use a bootstrapping estimate of the value function instead. That is, in place of the true value function vπ, we will use a “running estimate” Vπ. In other words, whenever observing a new transition, we use our previous best estimate of vπ to obtain a new estimate Vπ.</p>
<p>Crucially, using a bootstrapping estimate generally results in biased estimates of the value function. Moreover, due to relying on a single sample, the estimates tend to have very large variance. </p>
<h4><span id="td-learning">TD-learning</span></h4><p>The variance of the estimate is typically reduced by mixing new estimates of the value function with previous estimates using a learning rate αt. This yields the temporal-difference learning algorithm.</p>
<p><img src="/2023/11/17/pai8/image-70.png" alt="Alt text"></p>
<p>TD-learning is a fundamentally on-policy method. That is, for the estimates Vπ to converge to the true value function vπ, the transitions that are used for the estimation must follow policy π. </p>
<h4><span id="sarsa">SARSA</span></h4><p><img src="/2023/11/17/pai8/image-69.png" alt="Alt text"></p>
<h3><span id="off-policy-value-estimation">Off-policy Value Estimation</span></h3><p><img src="/2023/11/17/pai8/image-72.png" alt="Alt text"><br>This adapted update rule explicitly chooses the subsequent action a′ according to policy π whereas SARSA absorbs this choice into the Monte Carlo approximation. The algorithm has analogous convergence guarantees to those of SARSA. Crucially, this algorithm is off-policy. As noted, the key difference to the on-policy TD-learning and SARSA is that our estimate of the Qfunction explicitly keeps track of the next-performed action. It does so for any action in any state.</p>
<h3><span id="q-learning">Q-learning</span></h3><p><img src="/2023/11/17/pai8/image-73.png" alt="Alt text"><br>Crucially, the Monte Carlo approximation of eq. (11.21) does not depend on the policy. Thus, Q-learning is an off-policy method.<br><img src="/2023/11/17/pai8/image-74.png" alt="Alt text"></p>
<h3><span id="optimistic-q-learning">Optimistic Q-learning</span></h3><p><img src="/2023/11/17/pai8/image-76.png" alt="Alt text"></p>
<h3><span id="challenges">Challenges</span></h3><p>We have seen that both the model-based Rmax algorithm and the modelfree Q-learning take time polynomial in the number of states |X| and the number of actions |A| to converge. While this is acceptable in small grid worlds, this is completely unacceptable for large state and action spaces.</p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://core-robotics.gatech.edu/2022/02/28/bootcamp-summer-2020-week-4-on-policy-vs-off-policy-reinforcement-learning/">https://core-robotics.gatech.edu/2022/02/28/bootcamp-summer-2020-week-4-on-policy-vs-off-policy-reinforcement-learning/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-17T15:56:14.000Z" title="2023-11-17 4:56:14 ├F10: PM┤">2023-11-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-01T20:35:17.631Z" title="2023-12-1 9:35:17 ├F10: PM┤">2023-12-01</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">4 minutes read (About 553 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/17/pai7/">pai - Markov Decision Processes</a></p><div class="content"><h1><span id="markov-decision-processes">Markov Decision Processes</span></h1><p>Planning deals with the problem of deciding which action an agent should play in a (stochastic) environment(An environment is stochastic as opposed to deterministic, when the outcome of actions is random.). A key formalism for probabilistic plan ning in known environments are so-called Markov decision processes.<br><img src="/2023/11/17/pai7/image-50.png" alt="Alt text"></p>
<p>Our fundamental objective is to learn how the agent should behave to optimize its reward. In other words, given its current state, the agent should decide (optimally) on the action to play. Such a decision map — whether optimal or not — is called a policy.</p>
<p><img src="/2023/11/17/pai7/image-51.png" alt="Alt text"></p>
<p><img src="/2023/11/17/pai7/image-52.png" alt="Alt text"></p>
<p>For the purpose of our discussion of Markov decision processes and reinforcement learning, we will focus on a very common reward called discounted payoff.</p>
<p><img src="/2023/11/17/pai7/image-53.png" alt="Alt text"></p>
<p><img src="/2023/11/17/pai7/image-54.png" alt="Alt text"></p>
<p>Because we assumed stationary dynamics, rewards, and policies, the discounted payoff starting from a given state x will be independent of the start time t.</p>
<h2><span id="bellman-expectation-equation">Bellman Expectation Equation</span></h2><p>Let us now see how we can compute the value function：</p>
<p><img src="/2023/11/17/pai7/image-55.png" alt="Alt text"></p>
<p>This equation is known as the Bellman expectation equation, and it shows a recursive dependence of the value function on itself. The intuition is clear: the value of the current state corresponds to the reward from the next action plus the discounted sum of all future rewards obtained from the subsequent states.</p>
<h2><span id="policy-evaluation">Policy Evaluation</span></h2><p>Bellman’s expectation equation tells us how we can find the value function vπ of a fixed policy π using a system of linear equations.</p>
<p><img src="/2023/11/17/pai7/image-56.png" alt="Alt text"></p>
<h3><span id="fixed-point-iteration">Fixed-point Iteration</span></h3><p><img src="/2023/11/17/pai7/image-57.png" alt="Alt text"></p>
<h2><span id="policy-optimization">Policy Optimization</span></h2><h3><span id="greedy-policies">Greedy Policies</span></h3><p><img src="/2023/11/17/pai7/image-58.png" alt="Alt text"></p>
<h3><span id="bellman-optimality-equation">Bellman Optimality Equation</span></h3><p><img src="/2023/11/17/pai7/image-59.png" alt="Alt text"></p>
<p><img src="/2023/11/17/pai7/image-60.png" alt="Alt text"><br>These equations are also called the Bellman optimality equations. Intuitively, the Bellman optimality equations express that the value of a state under an optimal policy must equal the expected return for the best action from that state. Bellman’s theorem is also known as Bellman’s optimality principle, which is a more general concept.</p>
<h3><span id="policy-iteration">Policy Iteration</span></h3><p><img src="/2023/11/17/pai7/image-61.png" alt="Alt text"></p>
<p>It can be shown that policy iteration converges to an exact solution in a polynomial number of iterations.Each iteration of policy iteration requires computing the value function, which we have seen to be of cubic complexity in the number of states. </p>
<h3><span id="value-iteration">Value Iteration</span></h3><p><img src="/2023/11/17/pai7/image-62.png" alt="Alt text"><br>Value iteration converges to an ε-optimal solution in a polynomial number of iterations. Unlike policy iteration, value iteration does not converge to an exact solution in general.an iteration of 7 Sparsity refers to the interconnectivity of the state space. When only few states are reachable from any state, we call an MDP sparse. value iteration can be performed in (virtually) constant time in sparse Markov decision processes.</p>
<h2><span id="partial-observability">Partial Observability</span></h2><p>In this section, we consider how Markov decision processes can be extended to a partially observable setting where the agent can only access noisy observations Yt of its state Xt.</p>
<p><img src="/2023/11/17/pai7/image-63.png" alt="Alt text"></p>
<p>Observe that a Kalman filter can be viewed as a hidden Markov model with conditional linear Gaussian motion and sensor models and a Gaussian prior on the initial state.</p>
<p>POMDPs can be reduced to a Markov decision process with an enlarged state space.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-17T15:41:00.000Z" title="2023-11-17 4:41:00 ├F10: PM┤">2023-11-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-23T13:41:44.612Z" title="2023-11-23 2:41:44 ├F10: PM┤">2023-11-23</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">8 minutes read (About 1138 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/17/pai6/">pai - Bayesian Optimization</a></p><div class="content"><h1><span id="bayesian-optimization">Bayesian Optimization</span></h1><p><img src="/2023/11/17/pai6/image-39.png" alt="Alt text"></p>
<h2><span id="exploration-exploitation-dilemma">Exploration-Exploitation Dilemma</span></h2><p>In Bayesian optimization, we want to learn a model of f ⋆ and use this model to optimize f ⋆ simultaneously. These goals are somewhat contrary. Learning a model of f ⋆ requires us to explore the input space while using the model to optimize f ⋆ requires us to focus on the most promising well-explored areas. This trade-off is commonly known as the exploration-exploitation dilemma.</p>
<p>It is common to use a so-called acquisition function to greedily pick the next point to sample based on the current model.</p>
<h2><span id="online-learning-and-bandits">Online Learning and Bandits</span></h2><p><img src="/2023/11/17/pai6/image-40.png" alt="Alt text"></p>
<h3><span id="multi-armed-banditsmab">Multi-Armed Bandits(MAB)</span></h3><p>The “multi-armed bandits” (MAB) problem is a classical, canonical formalization of the exploration-exploitation dilemma. In the MAB problem, we are provided with k possible actions (arms) and want to maximize our reward online within the time horizon T. We do not know the reward distributions of the actions in advance, however, so we need to trade learning the reward distribution with following the most promising action.</p>
<p>Bayesian optimization can be interpreted as a variant of the MAB problem where there can be a potentially infinite number of actions (arms), but their rewards are correlated (because of the smoothness of the Gaussian process prior). Smoothness means that nearby points in the input space are likely to have similar function values. Because of the smoothness property inherent in the Gaussian process prior, Bayesian optimization can make informed decisions about where to explore next in the input space. The model can leverage information from previously evaluated points to predict the behavior of the objective function at unexplored points more effectively.</p>
<h3><span id="regret">Regret</span></h3><p>The key performance metric in online learning is the regret.</p>
<p><img src="/2023/11/17/pai6/image-41.png" alt="Alt text"></p>
<p>Achieving sublinear regret requires balancing exploration with exploitation. Typically, online learning (and Bayesian optimization) consider stationary environments, hence the comparison to the static optimum.</p>
<h3><span id="acquisition-functions">Acquisition Functions</span></h3><p>Throughout our description of acquisition functions, we will focus on a setting where we model $f^⋆$ using a Gaussian process which we denote by f. The methods generalize to other means of learning $f^⋆$ such as Bayesian neural networks.</p>
<p><img src="/2023/11/17/pai6/image-42.png" alt="Alt text"></p>
<p>One possible acquisition function is uncertainty sampling. However, this acquisition function does not at all take into account the objective of maximizing $f^⋆$ and focuses solely on exploration. </p>
<p>Suppose that our model f of $f^⋆$  is well-calibrated, in the sense that the true function lies within its confidence bounds. Consider the best lower bound, that is, the maximum of the lower confidence bound. Now, if the true function is really contained in the confidence bounds, it must hold that the optimum is somewhere above this best lower bound.</p>
<p>Therefore, we only really care how the function looks like in the regions where the upper confidence bound is larger than the best lower bound. The key idea behind the methods that we will explore is to focus exploration on these plausible maximizers.</p>
<h3><span id="upper-confidence-bound">Upper Confidence Bound</span></h3><p><img src="/2023/11/17/pai6/image-43.png" alt="Alt text"><br>This acquisition function naturally trades exploitation by preferring a large posterior mean with exploration by preferring a large posterior variance.<br>This optimization problem is non-convex in general. However, we can use approximate global optimization techniques like Lipschitz optimization (in low dimensions) and gradient ascent with random initialization (in high dimensions). Another widely used option is to sample some random points from the domain, score them according to this criterion, and simply take the best one.</p>
<p><img src="/2023/11/17/pai6/image-44.png" alt="Alt text"><br>Observe that if the information gain is sublinear in T then we achieve sublinear regret and, in particular, converge to the true optimum. The term “sublinear” refers to a growth rate that is slower than linear. </p>
<p><img src="/2023/11/17/pai6/image-45.png" alt="Alt text"><br>Intuitively, to work even if the unknown function $f^⋆$  is not contained in the confidence bounds, we use βt to re-scale the confidence bounds to enclose $f^⋆$.</p>
<h3><span id="probability-of-improvement">Probability of Improvement</span></h3><p><img src="/2023/11/17/pai6/image-46.png" alt="Alt text"></p>
<p>Probability of improvement tends to be biased in favor of exploitation, as it prefers points with large posterior mean and small posterior variance.</p>
<h3><span id="expected-improvement">Expected Improvement</span></h3><p><img src="/2023/11/17/pai6/image-47.png" alt="Alt text"></p>
<p>Intuitively, expected improvement seeks a large expected improvement (exploitation) while also preferring states with a large variance (exploration).</p>
<h3><span id="thompson-sampling">Thompson Sampling</span></h3><p><img src="/2023/11/17/pai6/image-48.png" alt="Alt text"></p>
<p>Probability matching is exploratory as it prefers points with larger variance (as they automatically have a larger chance of being optimal), but at the same time exploitative as it effectively discards points with low posterior mean and low posterior variance. Unfortunately, it is generally difficult to compute π analytically given a posterior. Instead, it is common to use a sampling-based approximation of π.</p>
<p><img src="/2023/11/17/pai6/image-49.png" alt="Alt text"></p>
<p>In many cases, the randomness in the realizations of  ̃ ft+1 is already sufficient to effectively trade exploration and exploitation.</p>
<h2><span id="model-selection">Model Selection</span></h2><p>Selecting a model of f ⋆ is much harder than in the i.i.d. data setting of supervised learning. There are mainly the two following dangers, • the data sets collected in active learning and Bayesian optimization are small; and • the data points are selected dependently on prior observations. This leads to a specific danger of overfitting. In particular, due to feedback loops between the model and the acquisition function, one may end up sampling the same point repeatedly.</p>
<p>Another approach that often works fairly well is to occasionally (according to some schedule) select points uniformly at random instead of using the acquisition function. This tends to prevent getting stuck in suboptimal parts of the state space.</p>
<h2><span id="difference-betwwen-active-learning-and-bayesian-optimization">difference betwwen active learning and Bayesian Optimization</span></h2><p>Problem Setting:<br>Active Learning: Active learning typically deals with supervised learning tasks where there is a large pool of unlabeled instances, and the algorithm decides which instances to query for labels to improve the model.<br>Bayesian Optimization: Bayesian optimization deals with optimization problems where the objective function is unknown, expensive to evaluate, and possibly noisy. It aims to find the global optimum with as few evaluations as possible.</p>
<p>Nature of Queries:<br>Active Learning: In active learning, the queries are often in the form of “Which instance should be labeled next?” The goal is to select instances that will most benefit the model’s learning process.<br>Bayesian Optimization: In Bayesian optimization, the queries are in the form of “What point should be evaluated next in the input space to maximize/minimize the objective function?” The goal is to efficiently explore the input space and find the optimal configuration.</p>
<p>Algorithmic Approaches:<br>Active Learning: Active learning involves various strategies such as uncertainty sampling, query-by-committee, and diversity sampling to select informative instances for labeling.<br>Bayesian Optimization: Bayesian optimization employs probabilistic surrogate models (often Gaussian processes) to model the unknown objective function. Acquisition functions guide the search to balance exploration and exploitation efficiently.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-16T12:02:24.000Z" title="2023-11-16 1:02:24 ├F10: PM┤">2023-11-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-23T10:01:53.411Z" title="2023-11-23 11:01:53 ├F10: AM┤">2023-11-23</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">4 minutes read (About 596 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/11/16/pai5/">pai - active learning</a></p><div class="content"><h1><span id="active-learning">Active learning</span></h1><p>Active learning is a machine learning paradigm in which a model is trained on a dataset that is not entirely labeled. Instead of relying solely on a fully labeled dataset for training, active learning involves an iterative process where the model actively selects the most informative instances from an unlabeled pool, queries an oracle (typically a human annotator), and adds the newly labeled instances to the training set. The model is then retrained on the expanded labeled dataset.</p>
<p>The key idea behind active learning is to strategically choose the most valuable instances for labeling, with the goal of improving the model’s performance while minimizing the number of labeled instances needed. This process is especially beneficial when obtaining labeled data is expensive or time-consuming.</p>
<p>Active learning strategies vary in how they select instances for labeling. Common strategies include uncertainty sampling (select instances where the model is uncertain), query-by-committee (select instances where different model hypotheses disagree), and diversity sampling (select instances to ensure diverse coverage of the input space).</p>
<h2><span id="conditional-entropy">Conditional Entropy</span></h2><p><img src="/2023/11/16/pai5/image-29.png" alt="Alt text"></p>
<p>Intuitively, the conditional entropy of X given Y describes our average surprise about realizations of X given a particular realization of Y, averaged over all such possible realizations of Y. In other words, conditional entropy corresponds to the expected remaining uncertainty in X after we observe Y.</p>
<p><img src="/2023/11/16/pai5/image-30.png" alt="Alt text"><br>That is, the joint entropy of X and Y is given by the uncertainty about X and the additional uncertainty about Y given X.</p>
<h2><span id="mutual-information">Mutual Information</span></h2><p><img src="/2023/11/16/pai5/image-31.png" alt="Alt text"></p>
<p>In words, we subtract the uncertainty left about X after observing Y from our initial uncertainty about X. This measures the reduction in our uncertainty in X (as measured by entropy) upon observing Y.</p>
<p><img src="/2023/11/16/pai5/image-32.png" alt="Alt text"></p>
<p>Thus, the mutual information between X and Y can be understood as the approximation error (or information loss) when assuming that X and Y are independent.</p>
<p><img src="/2023/11/16/pai5/image-33.png" alt="Alt text"></p>
<p>Thus, the conditional mutual information corresponds to the reduction of uncertainty in X when observing Y, given we already observed Z.</p>
<p>Following our introduction of mutual information, it is natural to answer the question “where should I collect data?” by saying “wherever mutual information is maximized”.</p>
<h2><span id="submodularity-of-mutual-information">Submodularity of Mutual Information</span></h2><p><img src="/2023/11/16/pai5/image-34.png" alt="Alt text"></p>
<p><img src="/2023/11/16/pai5/image-35.png" alt="Alt text"></p>
<p>That is, “adding” x to the smaller set A yields more marginal gain than adding x to the larger set B. In other words, the function F has “diminishing returns”. In this way, submodularity can be interpreted as a notion of “concavity” for discrete functions.</p>
<p><img src="/2023/11/16/pai5/image-36.png" alt="Alt text"></p>
<h2><span id="maximizing-mutual-information">Maximizing Mutual Information</span></h2><h3><span id="uncertainty-sampling">Uncertainty Sampling</span></h3><p><img src="/2023/11/16/pai5/image-37.png" alt="Alt text"></p>
<p>Therefore, if f is modeled by a Gaussian and we assume homoscedastic noise, greedily maximizing mutual information corresponds to simply picking the point x with the largest variance. This strategy is also called uncertainty sampling.</p>
<h3><span id="heteroscedastic-noise">Heteroscedastic Noise</span></h3><p>Uncertainty sampling is clearly problematic if the noise is heteroscedastic. If there are a particular set of inputs with a large aleatoric uncertainty dominating the epistemic uncertainty, uncertainty sampling will continuously choose those points even though the epistemic uncertainty will not be reduced substantially.<br><img src="/2023/11/16/pai5/image-38.png" alt="Alt text"></p>
<p>Thus, we choose locations that trade large epistemic uncertainty with large aleatoric uncertainty. Ideally, we find a location where the epistemic uncertainty is large, and the aleatoric uncertainty is low, which promises a significant reduction of uncertainty around this location.</p>
<h3><span id="classification">Classification</span></h3><p>Here, uncertainty sampling corresponds to selecting samples that maximize the entropy of the predicted label yx.</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/8/">8</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.png" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">72</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-12T14:22:00.000Z">2023-12-12</time></p><p class="title"><a href="/2023/12/12/bigdata12/">bigdata - Cube Data</a></p><p class="categories"><a href="/categories/database/">database</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-12T14:21:07.000Z">2023-12-12</time></p><p class="title"><a href="/2023/12/12/bigdata11/">bigdata - Graph Database</a></p><p class="categories"><a href="/categories/database/">database</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-07T14:26:41.000Z">2023-12-07</time></p><p class="title"><a href="/2023/12/07/pai10/">pai10</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-07T14:26:12.000Z">2023-12-07</time></p><p class="title"><a href="/2023/12/07/pai9/">pai - Model-free Approximate Reinforcement Learning</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-28T20:58:26.000Z">2023-11-28</time></p><p class="title"><a href="/2023/11/28/bigdata10/">bigdata - JSONiq</a></p><p class="categories"><a href="/categories/database/">database</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">44</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/probability/"><span class="tag">probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2023 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>