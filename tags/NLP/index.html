<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: NLP - s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">NLP</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-10T08:27:35.000Z" title="2024-10-10 4:27:35 ├F10: PM┤">2024-10-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-11T12:17:39.987Z" title="2024-10-11 8:17:39 ├F10: PM┤">2024-10-11</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 27 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/10/llm8/">perplexity</a></p><div class="content"><h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/">https://thegradient.pub/understanding-evaluation-metrics-for-language-models/</a><br><a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/perplexity">https://huggingface.co/docs/transformers/perplexity</a><br><a target="_blank" rel="noopener" href="https://blog.uptrain.ai/decoding-perplexity-and-its-significance-in-llms/">https://blog.uptrain.ai/decoding-perplexity-and-its-significance-in-llms/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-07-04T07:14:44.000Z" title="2024-7-4 3:14:44 ├F10: PM┤">2024-07-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-07-04T13:15:33.232Z" title="2024-7-4 9:15:33 ├F10: PM┤">2024-07-04</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 10 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/07/04/llm7/">Important papers</a></p><div class="content"><h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/understanding-large-language-models">https://magazine.sebastianraschka.com/p/understanding-large-language-models</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-07-04T06:57:56.000Z" title="2024-7-4 2:57:56 ├F10: PM┤">2024-07-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-07-04T13:34:08.076Z" title="2024-7-4 9:34:08 ├F10: PM┤">2024-07-04</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">3 minutes read (About 431 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/07/04/llm6/">finetuning large language models</a></p><div class="content"><h2><span id="the-3-conventional-feature-based-and-finetuning-approaches">The 3 Conventional Feature-Based and Finetuning Approaches</span></h2><h3><span id="feature-based-approach">Feature-Based Approach</span></h3><p>In the feature-based approach, we load a pretrained LLM and apply it to our target dataset. Here, we are particularly interested in generating the output embeddings for the training set, which we can use as input features to train a classification model.</p>
<h3><span id="finetuning-i-updating-the-output-layers">Finetuning I – Updating The Output Layers</span></h3><p>A popular approach related to the feature-based approach described above is finetuning the output layers (we will refer to this approach as finetuning I). Similar to the feature-based approach, we keep the parameters of the pretrained LLM frozen. We only train the newly added output layers.</p>
<h3><span id="finetuning-ii-updating-all-layers">Finetuning II – Updating All Layers</span></h3><p>when optimizing the modeling performance, the gold standard for using pretrained LLMs is to update all layers.</p>
<h2><span id="parameter-efficient-finetuning-techniques-peft">parameter-efficient finetuning techniques (PEFT)</span></h2><p>To finetune LLM with high modeling performance while only requiring the training of only a small number of parameters. These methods are usually referred to as parameter-efficient finetuning techniques (PEFT). Techniques such as prefix tuning, adapters, and low-rank adaptation, all of which “modify” multiple layers, achieve much better predictive performance (at a low cost).</p>
<h2><span id="reinforcement-learning-with-human-feedback-rlhf">Reinforcement Learning with Human Feedback (RLHF)</span></h2><p>In RLHF, human feedback is collected by having humans rank or rate different model outputs, providing a reward signal. The collected reward labels can then be used to train a reward model that is then in turn used to guide the LLMs adaptation to human preferences.</p>
<p>The reward model itself is learned via supervised learning (typically using a pretrained LLM as base model). Next, the reward model is used to update the pretrained LLM that is to be adapted to human preferences — the training uses a flavor of reinforcement learning called proximal policy optimization.</p>
<h2><span id="prompt-tuning">prompt tuning</span></h2><p>In a nutshell, prompt tuning (different from prompting) appends a tensor to the embedded inputs of a pretrained LLM. The tensor is then tuned to optimize a loss function for the finetuning task and data while all other parameters in the LLM remain frozen. </p>
<p>The main idea behind prompt tuning, and parameter-efficient finetuning methods in general, is to add a small number of new parameters to a pretrained LLM and only finetune the newly added parameters to make the LLM perform better on (a) a target dataset (for example, a domain-specific dataset like medical or legal documents) and (b) a target task (for example, sentiment classification).</p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/finetuning-large-language-models">https://magazine.sebastianraschka.com/p/finetuning-large-language-models</a><br><a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/understanding-parameter-efficient">https://magazine.sebastianraschka.com/p/understanding-parameter-efficient</a><br><a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters">https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-05-18T09:08:37.000Z" title="2024-5-18 5:08:37 ├F10: PM┤">2024-05-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-18T17:34:57.680Z" title="2024-5-19 1:34:57 ├F10: AM┤">2024-05-19</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a minute read (About 114 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/05/18/llm5/">Batch processing for sequences</a></p><div class="content"><h2><span id="padding">padding</span></h2><p>In natural language processing (NLP), padding refers to the practice of adding special tokens to sequences (such as sentences or texts) so that all sequences in a batch have the same length. Padding is essential when working with mini-batch processing in neural networks because it ensures that all sequences in a batch can be processed simultaneously, despite their varying lengths.</p>
<h2><span id="attention-masks">Attention masks</span></h2><p>Attention masks are tensors with the exact same shape as the input IDs tensor, filled with 0s and 1s: 1s indicate the corresponding tokens should be attended to, and 0s indicate the corresponding tokens should not be attended to. </p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/en/chapter2/5?fw=pt">https://huggingface.co/learn/nlp-course/en/chapter2/5?fw=pt</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-05-18T07:17:07.000Z" title="2024-5-18 3:17:07 ├F10: PM┤">2024-05-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-18T15:00:50.634Z" title="2024-5-18 11:00:50 ├F10: PM┤">2024-05-18</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 296 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/05/18/llm4/">Tokenizers</a></p><div class="content"><h2><span id="what-is-tokenizer">what is tokenizer</span></h2><p>A tokenizer is a crucial component in natural language processing (NLP) and text analysis that breaks down text into smaller, manageable units called tokens. These tokens can be words, phrases, symbols, or other meaningful elements depending on the specific requirements of the application. </p>
<h2><span id="how-tokenizer-works">how tokenizer works</span></h2><p>There are different types of tokenizer methods.Whitespace Tokenizers, Punctuation-Based Tokenizers,  Word Tokenizers,Sentence Tokenizers,Character Tokenizers, N-gram Tokenizers, Regular Expression Tokenizers and<br>Subword Tokenizers.</p>
<h3><span id="word-tokenizers">Word Tokenizers</span></h3><p>Word tokenization, also known as lexical analysis, is the process of splitting a piece of text into individual words or tokens. Word tokenization typically involves breaking the text into words based on spaces and punctuation. </p>
<h3><span id="subword-tokenizers">Subword Tokenizers</span></h3><p>Subword tokenization algorithms rely on the principle that frequently used words should not be split into smaller subwords, but rare words should be decomposed into meaningful subwords. A subword tokenizer is a type of tokenizer used in natural language processing (NLP) that breaks down words into smaller units or subwords. This approach is particularly useful for handling rare or out-of-vocabulary words, reducing the vocabulary size, and improving the efficiency of language models.</p>
<h4><span id="common-subword-tokenization-methods">Common Subword Tokenization Methods</span></h4><h5><span id="byte-pair-encoding-bpe">Byte-Pair Encoding (BPE)</span></h5><p>BPE is an iterative algorithm that merges the most frequent pairs of characters or subwords in a corpus until a desired vocabulary size is reached.</p>
<h5><span id="wordpiece-tokenization">WordPiece Tokenization</span></h5><p>Similar to BPE, WordPiece builds a vocabulary of subwords based on frequency, optimizing for a balance between vocabulary size and the ability to handle rare words.</p>
<h5><span id="sentencepiece">SentencePiece</span></h5><p>SentencePiece is an unsupervised text tokenizer and detokenizer mainly designed for Neural Network-based text generation systems. It treats the input text as a sequence of Unicode characters and uses a subword model to create subwords.</p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/en/chapter2/4">https://huggingface.co/learn/nlp-course/en/chapter2/4</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-05-01T07:56:46.000Z" title="2024-5-1 3:56:46 ├F10: PM┤">2024-05-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-01T14:19:57.133Z" title="2024-5-1 10:19:57 ├F10: PM┤">2024-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/practice/">practice</a></span><span class="level-item">a few seconds read (About 37 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/05/01/llm3/">Natural Language Inference(Recognizing Textual Entailment)</a></p><div class="content"><h1><span id="definition">definition</span></h1><p>Natural language inference (NLI) is the task of determining whether a “hypothesis” is true (entailment), false (contradiction), or undetermined (neutral) given a “premise”.</p>
<h2><span id="benchmarks">benchmarks</span></h2><p>Benchmark datasets used for NLI include SNLI, MultiNLI, SciTail, SuperGLUE, RTE, WNLI.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-04-02T05:52:28.000Z" title="2024-4-2 1:52:28 ├F10: PM┤">2024-04-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-01T14:05:06.884Z" title="2024-5-1 10:05:06 ├F10: PM┤">2024-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/practice/">practice</a></span><span class="level-item">a few seconds read (About 49 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/04/02/llm2/">Problems record of using OpenAI&#039;s API</a></p><div class="content"><h1><span id="gpt">GPT</span></h1><h2><span id="gpt-35-turbo-instruct-generates-empty-text-after-calling-several-times">gpt-3.5-turbo-instruct generates empty text after calling several times.</span></h2><p>Tried adding space or adding newline, but didn’t work.</p>
<h2><span id="gpt-35-turbo-1106-generates-different-results-from-same-prompt-even-though-t-is-set-as-0">gpt-3.5-turbo-1106 generates different results from same prompt even though T is set as 0.</span></h2><p>Tried setting seed but did’t work. Switched to another version mitigated this problem.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-03-29T05:00:15.000Z" title="2024-3-29 1:00:15 ├F10: PM┤">2024-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-03-29T14:40:00.506Z" title="2024-3-29 10:40:00 ├F10: PM┤">2024-03-29</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 108 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/03/29/llm1/">Sampling</a></p><div class="content"><h1><span id="sampling">Sampling</span></h1><h2><span id="top-p-sampling">top-p sampling</span></h2><p>This method only considers the tokens whose cumulative probability exceed the probability p and then redistributes the probability mass across the remaining tokens so that the sum of probabilities is 1. </p>
<h2><span id="temperature">temperature</span></h2><p>What the temperature does is: it controls the relative weights in the probability distribution. It controls the extent to which differences in probability play a role in the sampling. At temperature t=0 this sampling technique turns into what we call greedy search/argmax sampling where the token with the highest probability is always selected. </p>
<h2><span id="reference">reference</span></h2><p><a target="_blank" rel="noopener" href="https://blog.ml6.eu/why-openais-api-models-cannot-be-forced-to-behave-fully-deterministically-4934a7e8f184">https://blog.ml6.eu/why-openais-api-models-cannot-be-forced-to-behave-fully-deterministically-4934a7e8f184</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-02-21T04:25:29.000Z" title="2024-2-21 12:25:29 ├F10: PM┤">2024-02-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-03-15T10:58:19.589Z" title="2024-3-15 6:58:19 ├F10: PM┤">2024-03-15</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 234 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/02/21/llm0/">Measuring sentence similarity</a></p><div class="content"><h2><span id="metrics">metrics</span></h2><h3><span id="bleu-bilingual-evaluation-understudy">BLEU (Bilingual Evaluation Understudy)</span></h3><p>BLEU computes a score based on the n-gram overlap between the generated text and the reference text, as well as the brevity penalty to handle cases where the generated text is too short. The score ranges from 0 to 1, where 1 indicates a perfect match with the reference translations.</p>
<h3><span id="rouge-recall-oriented-understudy-for-gisting-evaluation">ROUGE (Recall-Oriented Understudy for Gisting Evaluation)</span></h3><p>ROUGE score measures the similarity between the machine-generated summary and the reference summaries using overlapping n-grams, word sequences that appear in both the machine-generated summary and the reference summaries. ROUGE score ranges from 0 to 1, with higher values indicating better summary quality. </p>
<p>ROUGE scores are branched into ROUGE-N,ROUGE-L, and ROUGE-S.<br>ROUGE-N measures the overlap of n-grams (contiguous sequences of n words) between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the n-gram overlap.<br>ROUGE-L measures the longest common subsequence (LCS) between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the length of the LCS.<br>ROUGE-S measures the skip-bigram (bi-gram with at most one intervening word) overlap between the candidate text and the reference text. It computes the precision, recall, and F1-score based on the skip-bigram overlap. </p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb">https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-11T10:58:49.000Z" title="2023-7-11 6:58:49 ├F10: PM┤">2023-07-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-07-11T17:10:28.614Z" title="2023-7-12 1:10:28 ├F10: AM┤">2023-07-12</time></span><span class="level-item">a few seconds read (About 106 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/07/11/Regular-Expressions/">Regular Expressions</a></p><div class="content"><h2><span id="regular-expressions">Regular expressions</span></h2><p>A formal language for specifying text strings</p>
<h3><span id="rules">rules</span></h3><p>Disjunctions:<br>Letters inside square brackets[]: [A-Z]<br>pipe |: a|b|c<br>Negation in Disjunction: <sup><a href="#fn_Ss" id="reffn_Ss">Ss</a></sup></p>
<p>?:  When placed after a character or a group, the question mark makes it optional, meaning that the character or group can occur zero or one time.<br>When placed after a quantifier, such as <em>, +, or ?, it modifies the quantifier to be non-greedy or lazy. A non-greedy quantifier matches as few characters as possible, while a greedy quantifier matches as many characters as possible.
</em>:0 or more of previous char<br>+:1 or more of previous char<br>.:any char</p>
<p>Anchors:<br>^: The begining. $: The end.</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/tags/NLP/page/0/">Previous</a></div><div class="pagination-next"><a href="/tags/NLP/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/tags/NLP/">1</a></li><li><a class="pagination-link" href="/tags/NLP/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.PNG" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">84</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">22</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/LLM/"><span class="level-start"><span class="level-item">LLM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/engineering/"><span class="level-start"><span class="level-item">engineering</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-23T10:35:00.000Z">2024-10-23</time></p><p class="title"><a href="/2024/10/23/DL1/">深度学习(2)-计算性能</a></p><p class="categories"><a href="/categories/engineering/">engineering</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-22T08:11:40.000Z">2024-10-22</time></p><p class="title"><a href="/2024/10/22/math0/">Optimization</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-10T08:27:35.000Z">2024-10-10</time></p><p class="title"><a href="/2024/10/10/llm8/">perplexity</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-07-04T07:14:44.000Z">2024-07-04</time></p><p class="title"><a href="/2024/07/04/llm7/">Important papers</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-07-04T06:57:56.000Z">2024-07-04</time></p><p class="title"><a href="/2024/07/04/llm6/">finetuning large language models</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">43</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2024 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>