<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-01-03T12:49:28.000Z" title="2023-1-3 1:49:28 ├F10: PM┤">2023-01-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-23T13:47:44.807Z" title="2023-11-23 2:47:44 ├F10: PM┤">2023-11-23</time></span><span class="level-item"><a class="link-muted" href="/categories/development-tools/">development tools</a></span><span class="level-item">2 minutes read (About 272 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/01/03/toolnotes/">toolnotes</a></p><div class="content"><h2><span id="背景">背景</span></h2><p>记录平时学习和开发工程中使用工具的一些备忘点。</p>
<h2><span id="正文">正文</span></h2><p>用vim时，鼠标右键不能粘贴而是进入了visual模式，解决方法：：set mouse-=a</p>
<p>远程jupyter配置<br><a target="_blank" rel="noopener" href="https://juejin.cn/post/7026371559971520525">https://juejin.cn/post/7026371559971520525</a></p>
<p>For Debian / Ubuntu: .deb packages installed by apt and dpkg<br>For Rocky / Fedora / RHEL: .rpm packages installed by yum<br>For FreeBSD: .txz packages installed by pkg</p>
<p>ssh-keygen -t rsa -b 4096 -C “your_email@example.com”</p>
<p>Kill PyTorch Distributed Training Processes:<br>kill $(ps aux | grep YOUR_TRAINING_SCRIPT.py | grep -v grep | awk ‘{print $2}’)</p>
<p>git reset —soft HEAD^ 撤销commit<br>git reset —hard HEAD^ 撤销add</p>
<p> tokenizing in Unix: “tr” command<br> 分词文件排序和统计<br> tr -sc ’A-Za-z’ ’\n’ &lt; $file_name| sort | uniq -c</p>
<p> conda:<br> conda create -n python=3.7 yourenv pip</p>
<p> git find . -name “*.py”|xargs git add —</p>
<p>导出项目依赖：<br>pip install pipreqs<br>pipreqs ./ —encoding=utf-8 —force</p>
<p>inside docker container, cannot locate package with apt install:<br>echo “deb <a target="_blank" rel="noopener" href="http://archive.debian.org/debian">http://archive.debian.org/debian</a> stretch main” &gt; /etc/apt/sources.list</p>
<p><a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/743839/apt-get-update-failed-to-fetch-debian-amd64-packages-while-building-dockerfile-f">https://unix.stackexchange.com/questions/743839/apt-get-update-failed-to-fetch-debian-amd64-packages-while-building-dockerfile-f</a></p>
<h3><span id="plotneuralnet">PlotNeuralNet</span></h3><p> <a target="_blank" rel="noopener" href="https://pub.towardsai.net/creating-stunning-neural-network-visualizations-with-chatgpt-and-plotneuralnet-adab37589e5">https://pub.towardsai.net/creating-stunning-neural-network-visualizations-with-chatgpt-and-plotneuralnet-adab37589e5</a></p>
<h3><span id="remote-develop">remote develop</span></h3><p><a target="_blank" rel="noopener" href="https://devblogs.microsoft.com/python/remote-python-development-in-visual-studio-code/">https://devblogs.microsoft.com/python/remote-python-development-in-visual-studio-code/</a></p>
<h2><span id="references">references”</span></h2><p><a target="_blank" rel="noopener" href="https://leimao.github.io/blog/Kill-PyTorch-Distributed-Training-Processes/">https://leimao.github.io/blog/Kill-PyTorch-Distributed-Training-Processes/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-12-29T20:59:33.000Z" title="2022-12-29 9:59:33 ├F10: PM┤">2022-12-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-01-13T16:25:27.335Z" title="2023-1-13 5:25:27 ├F10: PM┤">2023-01-13</time></span><span class="level-item">8 minutes read (About 1239 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/12/29/PCA/">PCA</a></p><div class="content"><h2><span id="关于pca为什么要中心化">关于PCA为什么要中心化</span></h2><p>因为不做zero mean，根本做不了PCA。从线性变换的本质来说，PCA就是在线性空间做一个旋转（数据矩阵右乘协方差矩阵的特征向量矩阵），然后取低维子空间（实际上就是前n<em>components个特征向量张成的子空间）上的投影点来代替原本的点，以达到降维的目的，注意我说的，只做了旋转，没有平移，所以首先你要保证原本空间里的点是以原点为中心分布的，这就是zero mean的目的。另外如果自己手撸过PCA的算法就知道了，explained_variance</em>和explained<em>variance_ratio</em>是怎么实现的？explained<em>variance就是协方差矩阵的每个特征值除以sample数，而explained_variance_ratio</em>是每个特征值除以所有特征值之和。为什么这么简单呢？这也和zero mean有关，如果你用最大投影长度的证法去证明PCA就会在过程中很自然的发现这一点，在这里我就不展开了。</p>
<p>链接：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/40956812/answer/848527057">https://www.zhihu.com/question/40956812/answer/848527057</a></p>
<p>PCA 去中心化不一定是必需的，这一结论成立的前提是严格使用协方差矩阵的定义式 S=XXT−nμμT，而不是用 XXT 来当作协方差矩阵。</p>
<p> Centering is an important pre-processing step because it ensures that the resulting components are only looking at the variance within the dataset, and not capturing the overall mean of the dataset as an important variable (dimension). Without mean-centering, the first principal component found by PCA might correspond with the mean of the data instead of the direction of maximum variance.<br> <a target="_blank" rel="noopener" href="https://towardsdatascience.com/tidying-up-with-pca-an-introduction-to-principal-components-analysis-f876599af383">https://towardsdatascience.com/tidying-up-with-pca-an-introduction-to-principal-components-analysis-f876599af383</a></p>
<p> Why is minimizing squared residuals equivalent to maximizing variance?<br> Consider a datapoint  (row  of ). Then the contribution of that datapoint to the variance is , or equivalently the squared Euclidean length . Applying the Pythagorean theorem shows that this total variance equals the sum of variance lost (the squared residual) and variance remaining. Thus, it is equivalent to either maximize remaining variance or minimize lost variance to find the principal components. </p>
<p> <a target="_blank" rel="noopener" href="http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/">http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/</a></p>
<p> PCA can only be interpreted as the singular value decomposition of a data matrix when the columns have first been centered by their means.<br> <a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia">https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia</a></p>
<p> PCA focuses on “explaining” the data matrix using the sample means plus the eigencomponents.  When the column mean is far from the origin, the first right singular value is usually quite highly correlated with column mean - thus using PCA concentrates on the second, third and sometimes higher order singular vectors.  This is a loss of information when the mean is informative for the process under study.  On the other hand, when the scatterplot of the data is roughly elliptical, the PCs typically align with the major axes of the ellipse.  Due to the uncorrelatedness constraint, if the mean is far from the origin, the first singular vector will be close to the mean and the others will be tilted away form the major axes of the ellipse.  Thus the first singular vector will not be informative about the spread of the data, and the second and third singular values will not be in the most informative directions.  Generally, PCA will be more informative, particularly as a method for plotting the data, than uncentered SVD.<br> <a target="_blank" rel="noopener" href="https://online.stat.psu.edu/stat555/node/94/">https://online.stat.psu.edu/stat555/node/94/</a></p>
<p> Since X is zero centered we can think of them as capturing the spread of the data around the mean in a sense reminiscent of PCA.<br> <a target="_blank" rel="noopener" href="https://intoli.com/blog/pca-and-svd/">https://intoli.com/blog/pca-and-svd/</a></p>
<p> that reconstruction error is minimized by taking as columns of W some k orthonormal vectors maximizing the total variance of the projection.<br> <a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/130721/what-norm-of-the-reconstruction-error-is-minimized-by-the-low-rank-approximation">https://stats.stackexchange.com/questions/130721/what-norm-of-the-reconstruction-error-is-minimized-by-the-low-rank-approximation</a></p>
<p> PCA is a regressional model without intercept1. Thus, principal components inevitably come through the origin. If you forget to center your data, the 1st principal component may pierce the cloud not along the main direction of the cloud, and will be (for statistics purposes) misleading.<br><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/22329/how-does-centering-the-data-get-rid-of-the-intercept-in-regression-and-pca">https://stats.stackexchange.com/questions/22329/how-does-centering-the-data-get-rid-of-the-intercept-in-regression-and-pca</a></p>
<p>Centering brings in a big difference. PCA with centering maximizes SS deviations from the mean (i.e. variance); PCA on raw data maximizes SS deviations from the zero point.<br><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/489037/principal-components-with-and-without-centering?noredirect=1&amp;lq=1">https://stats.stackexchange.com/questions/489037/principal-components-with-and-without-centering?noredirect=1&amp;lq=1</a></p>
<h2><span id="svd-and-pca">SVD and PCA</span></h2><p>  <a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca">https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca</a></p>
<h2><span id="singular-value-decomposition">singular value decomposition</span></h2><p> SVD is basically a matrix factorization technique, which decomposes any matrix into 3 generic and familiar matrices.</p>
<h2><span id="eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</span></h2><p> The concept of eigenvectors is applicable only for square matrices. The vector space spanned by an eigenvector is called an eigenspace.<br> A square matrix is called a diagonalizable matrix if it can be written in the format: $ A=PDP^{-1} $, D is the diagonal matrix comprises of the eigenvalues as diagonal elements<br> A Symmetric Matrix where the matrix is equal to the transpose of itself.<br> Special properties of a Symmetric Matrix with respect to eigenvalues and eigenvectors:Has only Real eigenvalues;Always diagonalizable;Has orthogonal eigenvectors.<br> A matrix is called an Orthogonal Matrix if the transpose of the matrix is the inverse of that matrix.<br>ince the eigenvectors of a Symmetric matrix are orthogonal to each other, matrix P in the diagonalized matrix A is an orthogonal matrix. So we say that any Symmetric Matrix is Orthogonally Diagonalizable.</p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/singular-value-decomposition-and-its-applications-in-principal-component-analysis-5b7a5f08d0bd">https://towardsdatascience.com/singular-value-decomposition-and-its-applications-in-principal-component-analysis-5b7a5f08d0bd</a></p>
<p>% For the PCA derived from maximal preserved variance \cite{lee2007nonlinear}, we have the covariance<br>% of $\mathbf{y}$, which is<br>% \begin{equation}<br>% \mathbf{C}_{\mathbf{y} \mathbf{y}}=E\left{\mathbf{y} \mathbf{y}^T\right}<br>% \end{equation}<br>% This equation is valid only when $\mathbf{y}$ is centered.<br> The goal of PCA is to maximize the variance of the data along each of the principal components. Centering is an important step because it ensures that the resulting components are only looking at the variance of features, and not capturing the means of the features as important. Without mean-centering, the first principal component found by PCA might correspond with the mean of the data instead of the direction of maximum variance.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-12-23T15:44:05.000Z" title="2022-12-23 4:44:05 ├F10: PM┤">2022-12-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-10-12T17:27:34.376Z" title="2023-10-12 7:27:34 ├F10: PM┤">2023-10-12</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a minute read (About 169 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/12/23/Network-Representation-Learning/">Network Representation Learning</a></p><div class="content"><h2><span id="background">background</span></h2><p>Recording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course.</p>
<h2><span id="line">LINE</span></h2><p>Reproduce paper “LINE: Large-scale Information Network Embedding”.</p>
<h3><span id="alias-table-method">Alias Table Method</span></h3><p>It’s a method of effiently drawing samples from discrete distribution.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.keithschwarz.com/darts-dice-coins/">https://www.keithschwarz.com/darts-dice-coins/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/haolexiao/article/details/65157026">https://blog.csdn.net/haolexiao/article/details/65157026</a></p>
<h3><span id="negative-sampling">Negative Sampling</span></h3><h4><span id="word2vec">word2vec</span></h4><p>Original paper:<br>Efficient estimation of word representations in vector space.<br>reference:<br>word2vec Explained: Deriving Mikolov et al.’s<br>Negative-Sampling Word-Embedding Method</p>
<h4><span id="skip-gram-model">Skip-Gram Model</span></h4><p>Original papaer:Distributed Representations of Words and Phrases<br>and their Compositionality.<br>The idea behind the word2vec models is that the words that appear in the same context (near each other) should have similar word vectors. Therefore, we should consider some notion of similarity in our objective when training the model. This is done using the dot product since when vectors are similar, their dot product is larger.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.baeldung.com/cs/nlps-word2vec-negative-sampling">https://www.baeldung.com/cs/nlps-word2vec-negative-sampling</a></p>
<h2><span id="graphsage">graphSage</span></h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-13T20:05:16.000Z" title="2022-3-13 9:05:16 ├F10: PM┤">2022-03-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-03-13T13:05:16.592Z" title="2022-3-13 2:05:16 ├F10: PM┤">2022-03-13</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/13/thoughts/">thoughts</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-11-15T19:44:05.000Z" title="2021-11-15 8:44:05 ├F10: PM┤">2021-11-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-09T13:39:31.415Z" title="2023-11-9 2:39:31 ├F10: PM┤">2023-11-09</time></span><span class="level-item"><a class="link-muted" href="/categories/practice/">practice</a></span><span class="level-item">2 minutes read (About 249 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/11/15/ML-5/">第二十二篇 机器学习(5)--不平衡的分类问题</a></p><div class="content"><h2><span id="什么是不平衡的分类问题">什么是不平衡的分类问题</span></h2><p>在机器学习中，不平衡的分类问题指的是类别之间的样本分布不均匀，其中某一类的样本数量远远超过另一类。这种不平衡可能会对模型训练和性能评估产生影响，因为模型可能更倾向于预测样本数更多的类别，而对样本数较少的类别进行较差的预测。</p>
<h2><span id="如何解决">如何解决</span></h2><p>为了解决不平衡分类问题，可以考虑以下方法：增加少数类别的样本数或减少多数类别的样本数，以平衡类别分布。这包括上采样（增加少数类别样本）和下采样（减少多数类别样本）。调整分类阈值，使模型更倾向于识别少数类别。这可以通过调整模型输出的概率阈值来实现。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-26T20:05:21.000Z" title="2021-9-26 10:05:21 ├F10: PM┤">2021-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-11-15T12:44:43.300Z" title="2021-11-15 1:44:43 ├F10: PM┤">2021-11-15</time></span><span class="level-item"><a class="link-muted" href="/categories/programming-language/">programming language</a></span><span class="level-item">a few seconds read (About 93 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/26/java-1/">第二十一篇 java(2)- 集合框架</a></p><div class="content"><h3><span id="集合框架">集合框架</span></h3><p>java集合框架包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对(两个对象)的映射表。</p>
<h4><span id="collection">Collection</span></h4><p>Collection下包括Set、List、Queue，各自又包含了使用不同方式的实现。</p>
<h5><span id="set">Set</span></h5><p>Set下包括TreeSet，HashSet，LinkedHashSet。其中TreeSet基于红黑树实现。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-26T19:10:33.000Z" title="2021-9-26 9:10:33 ├F10: PM┤">2021-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-09T13:37:23.731Z" title="2023-11-9 2:37:23 ├F10: PM┤">2023-11-09</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 269 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/26/ML-4/">第二十篇 机器学习(4)-uplift模型</a></p><div class="content"><h2><span id="uplift模型">uplift模型</span></h2><p>uplift模型中文为增益模型，是工业界因果推断与机器学习结合最成熟的算法之一。传统的监督学习模型，往往是对输入x去预测一个y，而增益模型注重于x的变化对y的影响，以广告为例，传统的监督学习往往是给定这个特征去预测用户是否会点击，而增益模型注重的是给这个客户投放广告与否对客户是否购买广告商品所产生的影响。</p>
<h3><span id="因果推断">因果推断</span></h3><p>因果推断是从观察到的数据中推断出变量之间的因果关系的过程。在统计学和数据科学中，因果推断涉及到尝试理解一个事件或行为是什么导致了另一个事件或行为。这与相关性或关联不同，因果推断试图确定一个变量的变化是否直接导致另一个变量的变化。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-25T14:43:07.000Z" title="2021-9-25 4:43:07 ├F10: PM┤">2021-09-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-09-25T08:46:55.795Z" title="2021-9-25 10:46:55 ├F10: AM┤">2021-09-25</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/25/DL/">第十九篇 深度学习(1)-梯度下降</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-22T19:19:09.000Z" title="2021-9-22 9:19:09 ├F10: PM┤">2021-09-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-05-08T16:31:23.404Z" title="2024-5-8 6:31:23 ├F10: PM┤">2024-05-08</time></span><span class="level-item"><a class="link-muted" href="/categories/programming-language/">programming language</a></span><span class="level-item">4 minutes read (About 672 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/22/python-3/">第十八篇 python(4)-多进程</a></p><div class="content"><h2><span id="协程-线程与进程">协程、线程与进程</span></h2><p>协程、线程和进程是计算机编程中常用的并发编程概念。总的来说，协程适合于高并发、I/O 密集型的场景，可以减少线程切换的开销；线程适合于 CPU 密集型和需要实时响应的任务；而进程则适合于独立性强、资源隔离要求高的任务。在实际应用中，通常会根据任务的特点和需求选择合适的并发编程模型。</p>
<h3><span id="协程">协程</span></h3><p>协程是一种程序组件，类似于线程，但其执行过程是可中断的。<br>在协程中，执行可以在特定的位置暂停，并在需要时恢复。<br>协程通常在单个线程中运行，因此不涉及线程切换的开销，可以有效地利用系统资源。</p>
<h3><span id="线程">线程</span></h3><p>线程是操作系统能够进行运算调度的最小单位。<br>一个进程中可以包含多个线程，它们共享进程的内存空间和其他资源。<br>多线程编程允许程序同时执行多个任务，提高了程序的并发性和响应性。<br>线程之间的切换开销相对较小，但线程间的共享资源需要进行同步，以避免竞态条件和死锁等问题</p>
<h3><span id="进程">进程</span></h3><p>进程是程序执行时的一个实例，每个进程都有自己独立的内存空间和系统资源。<br>进程间相互独立，各自拥有独立的地址空间和资源，彼此之间通信需要特殊的机制。<br>多进程编程可以充分利用多核处理器，但进程间的切换开销相对较大，因为需要切换地址空间和资源上下文。</p>
<h3><span id="python如何使用协程-线程与进程">python如何使用协程、线程与进程</span></h3><p>在Python中，可以使用不同的工具来实现协程、线程和进程。<br>在Python中，协程通常使用 asyncio 库来实现。 线程可以使用内置的 threading 模块来实现。进程可以使用 multiprocessing 模块来实现。<br>需要注意的是，在Python中，由于全局解释器锁（GIL）的存在，多线程并不能有效利用多核处理器。因此，如果需要充分利用多核处理器，可以考虑使用多进程。而协程则是在单个线程中实现并发的一种方式，适合于I/O密集型任务。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-02T20:07:25.000Z" title="2021-9-2 10:07:25 ├F10: PM┤">2021-09-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-09-25T08:40:05.043Z" title="2021-9-25 10:40:05 ├F10: AM┤">2021-09-25</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">a few seconds read (About 72 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/02/RL/">第十七篇 强化学习(1)-马尔可夫决策过程</a></p><div class="content"><h3><span id="马尔可夫决策过程">马尔可夫决策过程</span></h3><p>马尔可夫性质：当前状态可以完全表征过程。</p>
<p>对于任意有限的马尔可夫决策过程，都存在一个最优策略，不差于其他所有可能的策略。</p>
<h4><span id="贝尔曼方程">贝尔曼方程</span></h4></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/5/">Previous</a></div><div class="pagination-next"><a href="/page/7/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link is-current" href="/page/6/">6</a></li><li><a class="pagination-link" href="/page/7/">7</a></li><li><a class="pagination-link" href="/page/8/">8</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.PNG" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">79</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-18T15:08:37.000Z">2024-05-18</time></p><p class="title"><a href="/2024/05/18/llm5/">Batch processing for sequences</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-18T13:17:07.000Z">2024-05-18</time></p><p class="title"><a href="/2024/05/18/llm4/">Tokenizers</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-01T13:56:46.000Z">2024-05-01</time></p><p class="title"><a href="/2024/05/01/llm3/">Natural Language Inference(Recognizing Textual Entailment)</a></p><p class="categories"><a href="/categories/practice/">practice</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-02T11:52:28.000Z">2024-04-02</time></p><p class="title"><a href="/2024/04/02/llm2/">Problems record of using OpenAI&#039;s API</a></p><p class="categories"><a href="/categories/practice/">practice</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-29T12:00:15.000Z">2024-03-29</time></p><p class="title"><a href="/2024/03/29/llm1/">Sampling</a></p><p class="categories"><a href="/categories/theory/">theory</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">43</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/probability/"><span class="tag">probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2024 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>