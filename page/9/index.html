<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Recording and sharing my learning process."><meta property="og:type" content="blog"><meta property="og:title" content="s-serenity"><meta property="og:url" content="http://yoursite.com/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="Recording and sharing my learning process."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="Algorithm study development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com"},"headline":"s-serenity","image":["http://yoursite.com/img/og_image.png"],"author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject","url":"http://yoursite.com/img/logo.svg"}},"description":"Recording and sharing my learning process."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-26T14:05:21.000Z" title="2021-9-26 10:05:21 ├F10: PM┤">2021-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-23T04:19:43.632Z" title="2024-10-23 12:19:43 ├F10: PM┤">2024-10-23</time></span><span class="level-item"><a class="link-muted" href="/categories/programming-language/">programming language</a></span><span class="level-item">a few seconds read (About 93 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/26/java-1/">java(2)- 集合框架</a></p><div class="content"><h3><span id="集合框架">集合框架</span></h3><p>java集合框架包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对(两个对象)的映射表。</p>
<h4><span id="collection">Collection</span></h4><p>Collection下包括Set、List、Queue，各自又包含了使用不同方式的实现。</p>
<h5><span id="set">Set</span></h5><p>Set下包括TreeSet，HashSet，LinkedHashSet。其中TreeSet基于红黑树实现。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-26T13:10:33.000Z" title="2021-9-26 9:10:33 ├F10: PM┤">2021-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T11:41:03.179Z" title="2024-11-4 7:41:03 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">2 minutes read (About 269 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/26/ML-4/">机器学习(4)-uplift模型</a></p><div class="content"><h2><span id="uplift模型">uplift模型</span></h2><p>uplift模型中文为增益模型，是工业界因果推断与机器学习结合最成熟的算法之一。传统的监督学习模型，往往是对输入x去预测一个y，而增益模型注重于x的变化对y的影响，以广告为例，传统的监督学习往往是给定这个特征去预测用户是否会点击，而增益模型注重的是给这个客户投放广告与否对客户是否购买广告商品所产生的影响。</p>
<h3><span id="因果推断">因果推断</span></h3><p>因果推断是从观察到的数据中推断出变量之间的因果关系的过程。在统计学和数据科学中，因果推断涉及到尝试理解一个事件或行为是什么导致了另一个事件或行为。这与相关性或关联不同，因果推断试图确定一个变量的变化是否直接导致另一个变量的变化。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-25T08:43:07.000Z" title="2021-9-25 4:43:07 ├F10: PM┤">2021-09-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-23T14:05:23.009Z" title="2024-10-23 10:05:23 ├F10: PM┤">2024-10-23</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">8 minutes read (About 1195 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/25/DL/">深度学习(1)-梯度下降</a></p><div class="content"><h2><span id="梯度下降">梯度下降</span></h2><p>梯度下降法的基本思想是沿着函数梯度的负方向移动，直到找到一个局部最小值点。</p>
<p>利用泰勒展开，我们可以得到</p>
<script type="math/tex; mode=display">f(x + \epsilon) = f(x) + \epsilon f'(x) + \mathcal{O}(\epsilon^2).</script><p>如果取$\epsilon = -\eta f’(x)$, 我们会有</p>
<script type="math/tex; mode=display">f(x - \eta f'(x)) = f(x) - \eta f'^2(x) + \mathcal{O}(\eta^2 f'^2(x)).</script><p>因为$\eta f’^2(x)&gt;0$, 当$\eta$足够小，我们会有<script type="math/tex">f(x - \eta f'(x)) \lessapprox f(x).</script>.<br>则通过$x \leftarrow x - \eta f’(x)$可以使得$f(x)$的值下降。</p>
<h2><span id="牛顿法">牛顿法</span></h2><p>牛顿法是一种基于二阶泰勒展开的优化方法，利用Hessian矩阵来加速收敛。</p>
<p>通过泰勒展开，我们有</p>
<script type="math/tex; mode=display">f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \boldsymbol{\epsilon}^\top \nabla f(\mathbf{x}) + \frac{1}{2} \boldsymbol{\epsilon}^\top \nabla^2 f(\mathbf{x}) \boldsymbol{\epsilon} + \mathcal{O}(\|\boldsymbol{\epsilon}\|^3).</script><p>$f(x)$为最小值时，我们有$f’(x)=0$，则有</p>
<script type="math/tex; mode=display">\nabla f(\mathbf{x}) + \mathbf{H} \boldsymbol{\epsilon} = 0 \textrm{ and hence }
\boldsymbol{\epsilon} = -\mathbf{H}^{-1} \nabla f(\mathbf{x}).</script><h2><span id="随机梯度下降">随机梯度下降</span></h2><p>对于梯度下降，如果是n个样本的训练数据集，我们就需要计算n次每个样本的损失梯度，<br>计算负担会随着n的升高而变重，因此就有了随机梯度下降，即每次计算梯度时，只是随机抽取<br>一个样本进行计算。<br>由于<script type="math/tex">\mathbb{E}_i \nabla f_i(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x}) = \nabla f(\mathbf{x}).</script><br>可以认为平均而言，随机梯度是对梯度的良好估计。</p>
<h2><span id="小批量随机梯度下降">小批量随机梯度下降</span></h2><p>小批量随机梯度下降和随机梯度下降所用的所有元素都是从训练集中随机抽取的，因此梯度的期望保持不变，但是方差显著降低了。<br>一般来说，小批量随机梯度下降比随机梯度下降和梯度下降的速度快，收敛风险较小。</p>
<h2><span id="动量法">动量法</span></h2><p>动量法是一种优化算法，它通过对过去的梯度进行加权平均，来改进梯度下降法的性能。动量法的基本思想是在每次迭代时，不仅考虑当前的梯度方向，还考虑过去梯度的方向，从而平滑了更新方向，有助于加速收敛并减少振荡。</p>
<script type="math/tex; mode=display">
\begin{split}\begin{aligned}
\mathbf{v}_t &\leftarrow \beta \mathbf{v}_{t-1} + \mathbf{g}_{t, t-1}, \\
\mathbf{x}_t &\leftarrow \mathbf{x}_{t-1} - \eta_t \mathbf{v}_t.
\end{aligned}\end{split}</script><h2><span id="adagrad">AdaGrad</span></h2><p>AdaGrad 的核心在于动态调整每个参数的学习率。每个参数的学习率是根据该参数的历史梯度的平方和来调整的。如果某个参数的历史梯度变化较大，那么它的学习率会相应减小；反之，如果某个参数的历史梯度变化较小，那么它的学习率会相应增大。</p>
<script type="math/tex; mode=display">
\begin{split}\begin{aligned}
    \mathbf{g}_t & = \partial_{\mathbf{w}} l(y_t, f(\mathbf{x}_t, \mathbf{w})), \\
    \mathbf{s}_t & = \mathbf{s}_{t-1} + \mathbf{g}_t^2, \\
    \mathbf{w}_t & = \mathbf{w}_{t-1} - \frac{\eta}{\sqrt{\mathbf{s}_t + \epsilon}} \cdot \mathbf{g}_t.
\end{aligned}\end{split}</script><h2><span id="rmsprop">RMSProp</span></h2><p>RMSprop（Root Mean Square Propagation）是一种自适应学习率优化算法，旨在克服AdaGrad等方法中学习率递减过快的问题。RMSprop通过使用指数加权移动平均（Exponential Moving Average, EMA）来计算梯度平方的平均值，从而动态调整每个参数的学习率。这种方法在一定程度上解决了AdaGrad累积历史梯度平方和导致学习率过早减小的问题。</p>
<script type="math/tex; mode=display">
\begin{split}\begin{aligned}
    \mathbf{s}_t & \leftarrow \gamma \mathbf{s}_{t-1} + (1 - \gamma) \mathbf{g}_t^2, \\
    \mathbf{x}_t & \leftarrow \mathbf{x}_{t-1} - \frac{\eta}{\sqrt{\mathbf{s}_t + \epsilon}} \odot \mathbf{g}_t.
\end{aligned}\end{split}</script><h2><span id="adadelta">Adadelta</span></h2><script type="math/tex; mode=display">
\begin{aligned}
    \mathbf{s}_t & = \rho \mathbf{s}_{t-1} + (1 - \rho) \mathbf{g}_t^2.
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
    \mathbf{g}_t' & = \frac{\sqrt{\Delta\mathbf{x}_{t-1} + \epsilon}}{\sqrt{\mathbf{s}_t + \epsilon}} \odot \mathbf{g}_t.
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
    \Delta \mathbf{x}_t & = \rho \Delta\mathbf{x}_{t-1} + (1 - \rho) {\mathbf{g}_t'}^2,
\end{aligned}</script><script type="math/tex; mode=display">
\begin{split}\begin{aligned}
    \mathbf{x}_t  & = \mathbf{x}_{t-1} - \mathbf{g}_t'. \\
\end{aligned}\end{split}</script><h2><span id="adam">Adam</span></h2><p>Adam 结合了 AdaGrad 和 RMSprop 的优点，同时解决了它们各自的缺点。Adam 通过使用梯度的一阶矩估计（即动量）和二阶矩估计（即 RMSprop 中的梯度平方的指数加权移动平均值）来动态调整每个参数的学习率。</p>
<script type="math/tex; mode=display">
\begin{split}\begin{aligned}
    \mathbf{v}_t & \leftarrow \beta_1 \mathbf{v}_{t-1} + (1 - \beta_1) \mathbf{g}_t, \\
    \mathbf{s}_t & \leftarrow \beta_2 \mathbf{s}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2.
\end{aligned}\end{split}</script><script type="math/tex; mode=display">
\hat{\mathbf{v}}_t = \frac{\mathbf{v}_t}{1 - \beta_1^t} \text{ and } \hat{\mathbf{s}}_t = \frac{\mathbf{s}_t}{1 - \beta_2^t}.</script><script type="math/tex; mode=display">
\mathbf{g}_t' = \frac{\eta \hat{\mathbf{v}}_t}{\sqrt{\hat{\mathbf{s}}_t} + \epsilon}.</script><script type="math/tex; mode=display">
\mathbf{x}_t \leftarrow \mathbf{x}_{t-1} - \mathbf{g}_t'.</script><h2><span id="参考文献">参考文献</span></h2><p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_optimization/gd.html">https://zh.d2l.ai/chapter_optimization/gd.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-22T13:19:09.000Z" title="2021-9-22 9:19:09 ├F10: PM┤">2021-09-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-25T02:09:48.634Z" title="2024-10-25 10:09:48 ├F10: AM┤">2024-10-25</time></span><span class="level-item"><a class="link-muted" href="/categories/programming-language/">programming language</a></span><span class="level-item">4 minutes read (About 672 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/22/python-3/">python(4)-多进程</a></p><div class="content"><h2><span id="协程-线程与进程">协程、线程与进程</span></h2><p>协程、线程和进程是计算机编程中常用的并发编程概念。总的来说，协程适合于高并发、I/O 密集型的场景，可以减少线程切换的开销；线程适合于 CPU 密集型和需要实时响应的任务；而进程则适合于独立性强、资源隔离要求高的任务。在实际应用中，通常会根据任务的特点和需求选择合适的并发编程模型。</p>
<h3><span id="协程">协程</span></h3><p>协程是一种程序组件，类似于线程，但其执行过程是可中断的。<br>在协程中，执行可以在特定的位置暂停，并在需要时恢复。<br>协程通常在单个线程中运行，因此不涉及线程切换的开销，可以有效地利用系统资源。</p>
<h3><span id="线程">线程</span></h3><p>线程是操作系统能够进行运算调度的最小单位。<br>一个进程中可以包含多个线程，它们共享进程的内存空间和其他资源。<br>多线程编程允许程序同时执行多个任务，提高了程序的并发性和响应性。<br>线程之间的切换开销相对较小，但线程间的共享资源需要进行同步，以避免竞态条件和死锁等问题</p>
<h3><span id="进程">进程</span></h3><p>进程是程序执行时的一个实例，每个进程都有自己独立的内存空间和系统资源。<br>进程间相互独立，各自拥有独立的地址空间和资源，彼此之间通信需要特殊的机制。<br>多进程编程可以充分利用多核处理器，但进程间的切换开销相对较大，因为需要切换地址空间和资源上下文。</p>
<h3><span id="python如何使用协程-线程与进程">python如何使用协程、线程与进程</span></h3><p>在Python中，可以使用不同的工具来实现协程、线程和进程。<br>在Python中，协程通常使用 asyncio 库来实现。 线程可以使用内置的 threading 模块来实现。进程可以使用 multiprocessing 模块来实现。<br>需要注意的是，在Python中，由于全局解释器锁（GIL）的存在，多线程并不能有效利用多核处理器。因此，如果需要充分利用多核处理器，可以考虑使用多进程。而协程则是在单个线程中实现并发的一种方式，适合于I/O密集型任务。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-09-02T14:07:25.000Z" title="2021-9-2 10:07:25 ├F10: PM┤">2021-09-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-25T08:16:36.318Z" title="2024-10-25 4:16:36 ├F10: PM┤">2024-10-25</time></span><span class="level-item"><a class="link-muted" href="/categories/theory/">theory</a></span><span class="level-item">7 minutes read (About 1002 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/09/02/RL/">强化学习(1)-马尔可夫决策过程</a></p><div class="content"><h2><span id="马尔可夫决策过程-markov-decision-process-mdp">马尔可夫决策过程 Markov Decision Process (MDP)</span></h2><p>马尔可夫决策过程（Markov Decision Process，简称 MDP）是强化学习中的一个重要概念，用于描述智能体在不确定环境下做出决策的数学模型。</p>
<p>MDP有几大要素：状态空间，动作空间，状态转移函数，奖励函数，折扣因子。</p>
<script type="math/tex; mode=display">
\textrm{MDP}: (\mathcal{S}, \mathcal{A}, T, r).</script><p>马尔可夫性质：当前状态可以完全表征过程。</p>
<p>MDP 的目标是找到一个最优策略，使得从任何初始状态出发，智能体在未来获得的累积奖励（回报）最大化。对于任意有限的马尔可夫决策过程，都存在一个最优策略，不差于其他所有可能的策略。</p>
<h2><span id="价值迭代">价值迭代</span></h2><h3><span id="价值函数">价值函数</span></h3><p>This is called the “value function” for the policy $\pi$:</p>
<script type="math/tex; mode=display">
V^\pi(s_0) = E_{a_t \sim \pi(s_t)} \Big[ R(\tau) \Big] = E_{a_t \sim \pi(s_t)} \Big[ \sum_{t=0}^\infty \gamma^t r(s_t, a_t) \Big],</script><p>The key idea behind all algorithms in reinforcement learning is that the value of state can be written as the average reward obtained in the first stage and the value function averaged over all possible next states.</p>
<script type="math/tex; mode=display">
V^\pi(s_0) = r(s_0, a_0) + \gamma\ E_{a_0 \sim \pi(s_0)} \Big[ E_{s_1 \sim P(s_1 \mid s_0, a_0)} \Big[ V^\pi(s_1) \Big] \Big].</script><script type="math/tex; mode=display">
V^\pi(s) = \sum_{a \in \mathcal{A}} \pi(a \mid s) \Big[ r(s,  a) + \gamma\  \sum_{s' \in \mathcal{S}} P(s' \mid s, a) V^\pi(s') \Big];\ \textrm{for all } s \in \mathcal{S}.</script><h3><span id="动作价值函数">动作价值函数</span></h3><p> This is defined to be the average return of a trajectory that begins at $s_0$<br> but when the action of the first stage is fixed to be $a_0$.</p>
<script type="math/tex; mode=display">
 Q^\pi(s_0, a_0) = r(s_0, a_0) + E_{a_t \sim \pi(s_t)} \Big[ \sum_{t=1}^\infty \gamma^t r(s_t, a_t) \Big],</script><script type="math/tex; mode=display">
 Q^\pi(s, a) = r(s, a) + \gamma \sum_{s' \in \mathcal{S}} P(s' \mid s, a) \sum_{a' \in \mathcal{A}} \pi(a' \mid s')\ Q^\pi(s', a');\ \textrm{ for all } s \in \mathcal{S}, a \in \mathcal{A}.</script><h3><span id="最优策略">最优策略</span></h3><script type="math/tex; mode=display">
 \pi^*(s) = \underset{a \in \mathcal{A}}{\mathrm{argmax}} \Big[ r(s, a) + \gamma \sum_{s' \in \mathcal{S}} P(s' \mid s, a)\ V^*(s') \Big].</script><h3><span id="价值迭代">价值迭代</span></h3><script type="math/tex; mode=display">
 V_{k+1}(s) = \max_{a \in \mathcal{A}} \Big\{ r(s,  a) + \gamma\  \sum_{s' \in \mathcal{S}} P(s' \mid s, a) V_k(s') \Big\};\ \textrm{for all } s \in \mathcal{S}.</script><script type="math/tex; mode=display">
 Q_{k+1}(s, a) = r(s, a) + \gamma \max_{a' \in \mathcal{A}} \sum_{s' \in \mathcal{S}} P(s' \mid s, a) Q_k (s', a');\ \textrm{ for all } s \in \mathcal{S}, a \in \mathcal{A}.</script><p> The main idea behind the Value Iteration algorithm is to use the principle of dynamic programming to find the optimal average return obtained from a given state. Note that implementing the Value Iteration algorithm requires that we know the Markov decision process (MDP), e.g., the transition and reward functions, completely.</p>
<h2><span id="贝尔曼方程">贝尔曼方程</span></h2><p>贝尔曼方程（Bellman Equation）是强化学习和动态规划领域的一个重要概念，它用来描述在一个马尔可夫决策过程（MDP）中，状态价值函数或动作价值函数之间的关系。</p>
<h2><span id="q-learning">Q-learning</span></h2><p>Q-learning is an algorithm to learn the value function without necessarily knowing the MDP.<br>Q-learning 是一种强化学习算法，它属于无模型学习方法的一部分，因为 Q-learning 不需要了解环境的确切模型就能学习。Q-learning 的目标是学习一个动作价值函数, 更新规则是基于贝尔曼方程的。</p>
<p>为了学习这个动作价值函数，定义了一个损失函数， 该损失函数度量了给定<br>Q-函数与通过贝尔曼方程所预测的理想<br>Q-函数之间的差异。</p>
<script type="math/tex; mode=display">
\hat{Q} = \min_Q \underbrace{\frac{1}{nT} \sum_{i=1}^n \sum_{t=0}^{T-1} (Q(s_t^i, a_t^i) - r(s_t^i, a_t^i) - \gamma \max_{a'} Q(s_{t+1}^i, a'))^2}_{\stackrel{\textrm{def}}{=} \ell(Q)}.</script><p>我们可以通过梯度下降来最小化这个损失函数。</p>
<script type="math/tex; mode=display">
\begin{split}\begin{aligned}Q(s_t^i, a_t^i) &\leftarrow Q(s_t^i, a_t^i) - \alpha \nabla_{Q(s_t^i,a_t^i)} \ell(Q) \\&=(1 - \alpha) Q(s_t^i,a_t^i) - \alpha \Big( r(s_t^i, a_t^i) + \gamma \max_{a'} Q(s_{t+1}^i, a') \Big),\end{aligned}\end{split}</script><h2><span id="参考文献">参考文献</span></h2><p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_reinforcement-learning/value-iter.html">https://d2l.ai/chapter_reinforcement-learning/value-iter.html</a></p>
<p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_reinforcement-learning/qlearning.html">https://d2l.ai/chapter_reinforcement-learning/qlearning.html</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-31T13:38:04.000Z" title="2021-8-31 9:38:04 ├F10: PM┤">2021-08-31</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-10-25T02:09:42.279Z" title="2024-10-25 10:09:42 ├F10: AM┤">2024-10-25</time></span><span class="level-item"><a class="link-muted" href="/categories/programming-language/">programming language</a></span><span class="level-item">a minute read (About 207 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/31/python-2/">python(3)-matplotlib绘图</a></p><div class="content"><h2><span id="安装">安装</span></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install matplotlib</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2><span id="简单例子">简单例子</span></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 数据</span><br><span class="line">x = [1, 2, 3, 4, 5]</span><br><span class="line">y = [2, 3, 5, 7, 11]</span><br><span class="line"></span><br><span class="line"># 绘图</span><br><span class="line">plt.plot(x, y)</span><br><span class="line"></span><br><span class="line"># 添加标题和标签</span><br><span class="line">plt.title(&#x27;Simple Line Plot&#x27;)</span><br><span class="line">plt.xlabel(&#x27;X-axis&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Y-axis&#x27;)</span><br><span class="line"></span><br><span class="line"># 显示图形</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2><span id="更多例子">更多例子</span></h2><h3><span id="多个子图">多个子图</span></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 数据</span><br><span class="line">x = np.linspace(0, 10, 100)</span><br><span class="line">y1 = np.sin(x)</span><br><span class="line">y2 = np.cos(x)</span><br><span class="line"></span><br><span class="line"># 创建一个包含两个子图的图形</span><br><span class="line">fig, (ax1, ax2) = plt.subplots(2, 1)</span><br><span class="line"></span><br><span class="line"># 在第一个子图中绘制正弦函数</span><br><span class="line">ax1.plot(x, y1, &#x27;r-&#x27;)</span><br><span class="line">ax1.set_title(&#x27;Sine Function&#x27;)</span><br><span class="line">ax1.set_xlabel(&#x27;X-axis&#x27;)</span><br><span class="line">ax1.set_ylabel(&#x27;Y-axis&#x27;)</span><br><span class="line"></span><br><span class="line"># 在第二个子图中绘制余弦函数</span><br><span class="line">ax2.plot(x, y2, &#x27;g--&#x27;)</span><br><span class="line">ax2.set_title(&#x27;Cosine Function&#x27;)</span><br><span class="line">ax2.set_xlabel(&#x27;X-axis&#x27;)</span><br><span class="line">ax2.set_ylabel(&#x27;Y-axis&#x27;)</span><br><span class="line"></span><br><span class="line"># 设置图形的整体标题</span><br><span class="line">plt.suptitle(&#x27;Sine and Cosine Functions&#x27;)</span><br><span class="line"></span><br><span class="line"># 自定义图形的风格</span><br><span class="line">plt.style.use(&#x27;ggplot&#x27;)</span><br><span class="line"></span><br><span class="line"># 调整子图的间距</span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line"># 显示图形</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-29T11:07:36.000Z" title="2021-8-29 7:07:36 ├F10: PM┤">2021-08-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T11:41:05.116Z" title="2024-11-4 7:41:05 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/algorithm/">algorithm</a></span><span class="level-item">a minute read (About 213 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/ML-3/">机器学习(4)-决策树</a></p><div class="content"><h2><span id="决策树">决策树</span></h2><p>决策树是一种用于分类和回归问题的监督学习算法。它通过树状图的结构来表示和推断决策规则。每个内部节点表示一个特征或属性，每个分支代表一个决策规则，而每个叶节点表示一个类别标签或一个数值。</p>
<p>决策树的学习过程形成了一个递归的分治算法，其中每个节点都对应于一个特征，并且通过节点上的决策规则将数据集分割成更纯的子集。在决策树的构建过程中，选择最佳特征和分割数据的目标是提高每个节点的纯度，使得决策树在训练数据上达到最佳的拟合效果。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-29T11:07:20.000Z" title="2021-8-29 7:07:20 ├F10: PM┤">2021-08-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T13:16:42.261Z" title="2024-11-4 9:16:42 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/algorithm/">algorithm</a></span><span class="level-item">6 minutes read (About 908 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/ML-2/">机器学习(3)-支持向量机</a></p><div class="content"><h2><span id="支持向量机">支持向量机</span></h2><p>支持向量机（Support Vector Machine，SVM）是一种用于分类和回归分析的监督学习算法。它的主要目标是找到一个超平面，将数据集划分成两个类别，同时使得两个类别中距离最近的数据点到该超平面的距离最大化。这两个最近的数据点被称为支持向量。</p>
<p>SVM 可以使用核函数来处理非线性可分的数据。核函数可以将输入特征映射到高维空间，从而在高维空间中找到一个线性超平面来解决原始空间中的非线性问题。</p>
<h2><span id="支持向量机公式">支持向量机公式</span></h2><h3><span id="硬间隔支持向量机hard-margin-svm">硬间隔支持向量机（Hard Margin SVM）</span></h3><p>硬间隔支持向量机适用于线性可分的数据集。</p>
<p>\subsubsection*{优化问题}</p>
<p>目标是最大化间隔，同时保证所有样本都正确分类：</p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script><p>约束条件：</p>
<script type="math/tex; mode=display">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1, \quad i = 1, 2, \ldots, n</script><p>其中：</p>
<ul>
<li>$ \mathbf{w} $ 是权重向量。</li>
<li>$ b $ 是偏置项。</li>
<li>$ \mathbf{x}_i $ 是第 $ i $ 个样本的特征向量。</li>
<li>$ y_i $ 是第 $ i $ 个样本的标签，取值为 $ \pm 1 $。</li>
</ul>
<h3><span id="软间隔支持向量机soft-margin-svm">软间隔支持向量机（Soft Margin SVM）</span></h3><p>软间隔支持向量机适用于线性不可分的数据集，允许一定程度的误分类。</p>
<p>\subsubsection*{优化问题}</p>
<p>目标是最大化间隔，同时引入松弛变量 $ \xi_i $ 来允许一些样本在间隔内部或错误分类：</p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b, \boldsymbol{\xi}} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i</script><p>约束条件：</p>
<script type="math/tex; mode=display">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad i = 1, 2, \ldots, n</script><p>其中：</p>
<ul>
<li>$ C $ 是正则化参数，控制误分类和间隔大小之间的平衡。</li>
<li>$ \xi_i $ 是松弛变量，表示第 $ i $ 个样本允许的误分类程度。</li>
</ul>
<h3><span id="对偶问题">对偶问题</span></h3><p>通过拉格朗日乘子法，可以将原始问题转化为对偶问题。</p>
<p>\subsubsection*{拉格朗日函数}</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}, \boldsymbol{\xi}, \boldsymbol{\mu}) = \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i - \sum_{i=1}^{n} \alpha_i [y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 + \xi_i] - \sum_{i=1}^{n} \mu_i \xi_i</script><p>其中：</p>
<ul>
<li>$ \alpha_i $ 是拉格朗日乘子。</li>
<li>$ \mu_i $ 是非负的拉格朗日乘子。</li>
</ul>
<p>\subsubsection*{对偶问题}</p>
<p>通过求解拉格朗日函数关于 $ \mathbf{w} $ 和 $ b $ 的偏导数并令其为零，可以得到对偶问题：</p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha}} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)</script><p>约束条件：</p>
<script type="math/tex; mode=display">0 \leq \alpha_i \leq C, \quad i = 1, 2, \ldots, n</script><script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script><h3><span id="决策函数">决策函数</span></h3><p>通过求解对偶问题，可以得到支持向量机的决策函数：</p>
<script type="math/tex; mode=display">f(\mathbf{x}) = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \cdot \mathbf{x} + b</script><p>其中，只有当 $ \alpha_i &gt; 0 $ 时，对应的样本 $ \mathbf{x}_i $ 才是支持向量。</p>
<h3><span id="核技巧kernel-trick">核技巧（Kernel Trick）</span></h3><p>对于非线性可分的数据集，可以通过核函数将数据映射到高维空间，使数据在高维空间中线性可分。</p>
<h3><span id="常见的核函数">常见的核函数</span></h3><ul>
<li><p><strong>线性核</strong>：</p>
<script type="math/tex; mode=display">K(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i \cdot \mathbf{x}_j</script></li>
<li><p><strong>多项式核</strong>：</p>
<script type="math/tex; mode=display">K(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i \cdot \mathbf{x}_j + c)^d</script></li>
<li><p><strong>高斯核（RBF核）</strong>：</p>
<script type="math/tex; mode=display">K(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\gamma \|\mathbf{x}_i - \mathbf{x}_j\|^2\right)</script></li>
<li><p><strong>Sigmoid核</strong>：</p>
<script type="math/tex; mode=display">K(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\gamma \mathbf{x}_i \cdot \mathbf{x}_j + c)</script></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-29T11:04:04.000Z" title="2021-8-29 7:04:04 ├F10: PM┤">2021-08-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T12:57:03.049Z" title="2024-11-4 8:57:03 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/algorithm/">algorithm</a></span><span class="level-item">6 minutes read (About 864 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/ML-1/">机器学习(2)-朴素贝叶斯</a></p><div class="content"><h2><span id="朴素贝叶斯">朴素贝叶斯</span></h2><p>朴素贝叶斯（Naive Bayes）是一种基于贝叶斯定理的分类算法，被广泛用于文本分类和其他分类问题。它被称为”朴素”是因为它假设每个特征与其他特征之间都是相互独立的，这是一个较为简化的假设，但在实践中，朴素贝叶斯通常表现得相当好。</p>
<p>在朴素贝叶斯中，我们考虑一个分类问题，其中 A 是类别，而 B 是特征。贝叶斯定理用于计算给定特征的情况下某个类别的概率。我们可以使用训练数据中的频率估计概率，并计算每个类别的概率。然后，给定一个新的特征向量，我们可以使用贝叶斯定理计算每个类别的后验概率，并选择具有最高概率的类别作为预测结果。</p>
<h2><span id="朴素贝叶斯公式">朴素贝叶斯公式</span></h2><h3><span id="贝叶斯定理">贝叶斯定理</span></h3><p>贝叶斯定理描述了在已知某些证据的情况下，某个假设的概率：</p>
<script type="math/tex; mode=display">P(A|B) = \frac{P(B|A) P(A)}{P(B)}</script><p>其中：</p>
<ul>
<li>( P(A|B) ) 是在事件 B 发生的情况下，事件 A 发生的后验概率。</li>
<li>( P(B|A) ) 是在事件 A 发生的情况下，事件 B 发生的条件概率。</li>
<li>( P(A) ) 是事件 A 发生的先验概率。</li>
<li>( P(B) ) 是事件 B 发生的边缘概率。</li>
</ul>
<p>\subsection*{朴素贝叶斯分类器}</p>
<p>在朴素贝叶斯分类器中，假设特征之间相互独立。对于一个给定的样本 ( x = (x_1, x_2, \ldots, x_n) )，我们需要计算每个类别的后验概率 ( P(C_k | x) )，并选择具有最高后验概率的类别作为预测结果。</p>
<h3><span id="后验概率">后验概率</span></h3><p>根据贝叶斯定理，后验概率可以表示为：</p>
<script type="math/tex; mode=display">P(C_k | x) = \frac{P(x | C_k) P(C_k)}{P(x)}</script><p>其中：</p>
<ul>
<li>( P(C_k | x) ) 是在特征向量 ( x ) 给定的情况下，类别 ( C_k ) 的后验概率。</li>
<li>( P(x | C_k) ) 是在类别 ( C_k ) 给定的情况下，特征向量 ( x ) 的条件概率。</li>
<li>( P(C_k) ) 是类别 ( C_k ) 的先验概率。</li>
<li>( P(x) ) 是特征向量 ( x ) 的边缘概率。</li>
</ul>
<h3><span id="条件概率">条件概率</span></h3><p>由于假设特征之间相互独立，条件概率 ( P(x | C_k) ) 可以分解为各个特征的条件概率的乘积：</p>
<script type="math/tex; mode=display">P(x | C_k) = P(x_1 | C_k) P(x_2 | C_k) \cdots P(x_n | C_k) = \prod_{i=1}^{n} P(x_i | C_k)</script><h3><span id="类别先验概率">类别先验概率</span></h3><p>类别先验概率 ( P(C_k) ) 通常通过训练数据中的类别频率来估计：</p>
<script type="math/tex; mode=display">P(C_k) = \frac{\text{类别 } C_k \text{ 的样本数}}{\text{总样本数}}</script><h3><span id="边缘概率">边缘概率</span></h3><p>边缘概率 ( P(x) ) 可以通过全概率公式计算：</p>
<script type="math/tex; mode=display">P(x) = \sum_{k=1}^{K} P(x | C_k) P(C_k)</script><p>但在实际应用中，通常不需要显式计算 ( P(x) )，因为它是所有类别的后验概率的归一化常数，不会影响类别的选择。</p>
<h3><span id="最大后验概率">最大后验概率</span></h3><p>选择具有最大后验概率的类别作为预测结果：</p>
<script type="math/tex; mode=display">\hat{C} = \arg\max_{C_k} P(C_k | x) = \arg\max_{C_k} \frac{P(x | C_k) P(C_k)}{P(x)} = \arg\max_{C_k} P(x | C_k) P(C_k)</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-29T10:59:15.000Z" title="2021-8-29 6:59:15 ├F10: PM┤">2021-08-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-11-04T11:54:56.436Z" title="2024-11-4 7:54:56 ├F10: PM┤">2024-11-04</time></span><span class="level-item"><a class="link-muted" href="/categories/algorithm/">algorithm</a></span><span class="level-item">3 minutes read (About 440 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/08/29/ML/">机器学习(1)-逻辑回归</a></p><div class="content"><h2><span id="逻辑回归">逻辑回归</span></h2><p>逻辑回归（Logistic Regression）是一种用于解决二分类问题的监督学习算法，尽管名称中包含”回归”一词，但实际上它用于分类任务。<br>逻辑回归使用一个假设函数（sigmoid函数），将输入特征的线性组合映射到一个在0和1之间的概率值。逻辑回归将概率值转换为二分类的决策，通常使用一个阈值（例如0.5）。逻辑回归使用交叉熵损失函数来衡量预测概率与实际标签之间的差异。损失函数的目标是最小化误差。</p>
<h2><span id="交叉熵损失函数cross-entropy-loss">交叉熵损失函数（Cross-Entropy Loss）</span></h2><script type="math/tex; mode=display">
L(y, p) = -[y \log(p) + (1 - y) \log(1 - p)]</script><h2><span id="逻辑回归的梯度计算">逻辑回归的梯度计算</span></h2><p>对于单个样本 $(x^{(i)}, y^{(i)})$，其损失为：</p>
<script type="math/tex; mode=display">
L(w, b) = -[y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})]</script><p>其中 $\hat{y}^{(i)} = \sigma(z^{(i)})$ 是模型的输出，$z^{(i)} = w^T x^{(i)} + b$，而 $\sigma(z) = \frac{1}{1 + e^{-z}}$ 是 sigmoid 函数。</p>
<p>对于整个训练集，总损失 $J(w, b)$ 为所有样本损失的平均值：</p>
<script type="math/tex; mode=display">
J(w, b) = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})]</script><h3><span id="对-w_j-的梯度">对 $w_j$ 的梯度</span></h3><script type="math/tex; mode=display">\frac{\partial J(w, b)}{\partial w_j} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}</script><h3><span id="对-b-的梯度">对 $b$ 的梯度</span></h3><script type="math/tex; mode=display">\frac{\partial J(w, b)}{\partial b} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})</script><h3><span id="参数更新">参数更新</span></h3><p>在每次迭代中，参数 $w$ 和 $b$ 会根据计算出的梯度进行更新：</p>
<script type="math/tex; mode=display">w_j := w_j - \alpha \frac{\partial J(w, b)}{\partial w_j}</script><script type="math/tex; mode=display">b := b - \alpha \frac{\partial J(w, b)}{\partial b}</script><p>其中 $\alpha$ 是学习率，控制着每次参数更新的步伐大小。</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/8/">Previous</a></div><div class="pagination-next"><a href="/page/10/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/8/">8</a></li><li><a class="pagination-link is-current" href="/page/9/">9</a></li><li><a class="pagination-link" href="/page/10/">10</a></li><li><a class="pagination-link" href="/page/11/">11</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/tx.PNG" alt="s-serenity"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">s-serenity</p><p class="is-size-6 is-block">student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">104</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">28</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/s-serenity" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/s-serenity"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/s-serenity" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/LLM/"><span class="level-start"><span class="level-item">LLM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-science/"><span class="level-start"><span class="level-item">computer science</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/computer-system/"><span class="level-start"><span class="level-item">computer system</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/database/"><span class="level-start"><span class="level-item">database</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/development-tools/"><span class="level-start"><span class="level-item">development tools</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/engineering/"><span class="level-start"><span class="level-item">engineering</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/others/"><span class="level-start"><span class="level-item">others</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/practice/"><span class="level-start"><span class="level-item">practice</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/programming-language/"><span class="level-start"><span class="level-item">programming language</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li><li><a class="level is-mobile" href="/categories/web-development/"><span class="level-start"><span class="level-item">web development</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-14T02:39:10.000Z">2024-11-14</time></p><p class="title"><a href="/2024/11/14/python-5/">python-5</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-07T09:03:42.000Z">2024-11-07</time></p><p class="title"><a href="/2024/11/07/SQL1/">SQL(2) - 开窗函数</a></p><p class="categories"><a href="/categories/database/">database</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-06T03:42:14.000Z">2024-11-06</time></p><p class="title"><a href="/2024/11/06/ir0/">信息检索（1）- BM25</a></p><p class="categories"><a href="/categories/algorithm/">algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-05T09:20:14.000Z">2024-11-05</time></p><p class="title"><a href="/2024/11/05/web0/">Web(1) - Cookie 和 Session</a></p><p class="categories"><a href="/categories/web-development/">web development</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-11-05T09:16:04.000Z">2024-11-05</time></p><p class="title"><a href="/2024/11/05/cpp1/">C++（2）- 静态成员函数</a></p><p class="categories"><a href="/categories/programming-language/">programming language</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">43</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elasticsearch/"><span class="tag">Elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommender-System/"><span class="tag">Recommender System</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/big-data/"><span class="tag">big data</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-network/"><span class="tag">computer network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-vision/"><span class="tag">computer vision</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/information-retrieval/"><span class="tag">information retrieval</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/operating-system/"><span class="tag">operating system</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/speech/"><span class="tag">speech</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tools/"><span class="tag">tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="s-serenity" height="28"></a><p class="is-size-7"><span>&copy; 2024 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>