<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Network Representation Learning - s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="backgroundRecording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course. LINEReproduce paper “LINE: Large-scale Information Ne"><meta property="og:type" content="article"><meta property="og:title" content="Network Representation Learning"><meta property="og:url" content="http://yoursite.com/2022/12/23/Network-Representation-Learning/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="backgroundRecording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course. LINEReproduce paper “LINE: Large-scale Information Ne"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:published_time" content="2022-12-23T15:44:05.000Z"><meta property="article:modified_time" content="2022-12-29T21:00:27.716Z"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="KTH"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2022/12/23/Network-Representation-Learning/"},"headline":"Network Representation Learning","image":["http://yoursite.com/img/og_image.png"],"datePublished":"2022-12-23T15:44:05.000Z","dateModified":"2022-12-29T21:00:27.716Z","author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject"}},"description":"backgroundRecording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course. LINEReproduce paper “LINE: Large-scale Information Ne"}</script><link rel="canonical" href="http://yoursite.com/2022/12/23/Network-Representation-Learning/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">s-serenity</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-12-23T15:44:05.000Z" title="2022-12-23 4:44:05 ├F10: PM┤">2022-12-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-12-29T21:00:27.716Z" title="2022-12-29 10:00:27 ├F10: PM┤">2022-12-29</time></span></div></div><h1 class="title is-3 is-size-4-mobile">Network Representation Learning</h1><div class="content"><h2><span id="background">background</span></h2><p>Recording studying during KTH. First blog about network representation learning, a project belongs to machine learning, advanced course.</p>
<h2><span id="line">LINE</span></h2><p>Reproduce paper “LINE: Large-scale Information Network Embedding”.</p>
<h3><span id="alias-table-method">Alias Table Method</span></h3><p>It’s a method of effiently drawing samples from discrete distribution.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.keithschwarz.com/darts-dice-coins/">https://www.keithschwarz.com/darts-dice-coins/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/haolexiao/article/details/65157026">https://blog.csdn.net/haolexiao/article/details/65157026</a></p>
<h3><span id="negative-sampling">Negative Sampling</span></h3><h4><span id="word2vec">word2vec</span></h4><p>Original paper:<br>Efficient estimation of word representations in vector space.<br>reference:<br>word2vec Explained: Deriving Mikolov et al.’s<br>Negative-Sampling Word-Embedding Method</p>
<h4><span id="skip-gram-model">Skip-Gram Model</span></h4><p>Original papaer:Distributed Representations of Words and Phrases<br>and their Compositionality.<br>The idea behind the word2vec models is that the words that appear in the same context (near each other) should have similar word vectors. Therefore, we should consider some notion of similarity in our objective when training the model. This is done using the dot product since when vectors are similar, their dot product is larger.<br>reference:<br><a target="_blank" rel="noopener" href="https://www.baeldung.com/cs/nlps-word2vec-negative-sampling">https://www.baeldung.com/cs/nlps-word2vec-negative-sampling</a></p>
<h2><span id="graphsage">graphSage</span></h2></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/KTH/">KTH</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/12/29/PCA/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">PCA</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/03/13/thoughts/"><span class="level-item">thoughts</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">s-serenity</a><p class="is-size-7"><span>&copy; 2023 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>