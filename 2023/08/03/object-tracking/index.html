<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>object tracking - s-serenity</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="s-serenity"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="s-serenity"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="object trackingMultiple Object Tracking(MOT) is the task of detecting various objects of interest in a video, tracking these detected objects in subsequent frames by assigning them a unique ID, and ma"><meta property="og:type" content="article"><meta property="og:title" content="object tracking"><meta property="og:url" content="http://yoursite.com/2023/08/03/object-tracking/"><meta property="og:site_name" content="s-serenity"><meta property="og:description" content="object trackingMultiple Object Tracking(MOT) is the task of detecting various objects of interest in a video, tracking these detected objects in subsequent frames by assigning them a unique ID, and ma"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:published_time" content="2023-08-03T07:41:10.000Z"><meta property="article:modified_time" content="2023-08-26T20:34:45.648Z"><meta property="article:author" content="s-serenity"><meta property="article:tag" content="computer vision"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://yoursite.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2023/08/03/object-tracking/"},"headline":"object tracking","image":["http://yoursite.com/img/og_image.png"],"datePublished":"2023-08-03T07:41:10.000Z","dateModified":"2023-08-26T20:34:45.648Z","author":{"@type":"Person","name":"s-serenity"},"publisher":{"@type":"Organization","name":"s-serenity","logo":{"@type":"ImageObject"}},"description":"object trackingMultiple Object Tracking(MOT) is the task of detecting various objects of interest in a video, tracking these detected objects in subsequent frames by assigning them a unique ID, and ma"}</script><link rel="canonical" href="http://yoursite.com/2023/08/03/object-tracking/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">s-serenity</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-03T07:41:10.000Z" title="2023-8-3 9:41:10 ├F10: AM┤">2023-08-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-08-26T20:34:45.648Z" title="2023-8-26 10:34:45 ├F10: PM┤">2023-08-26</time></span></div></div><h1 class="title is-3 is-size-4-mobile">object tracking</h1><div class="content"><h1><span id="object-tracking">object tracking</span></h1><p>Multiple Object Tracking(MOT) is the task of detecting various objects of interest in a video, tracking these detected objects in subsequent frames by assigning them a unique ID, and maintaining these unique IDs as the objects move around in a video in successive frames.Generally, multiple object tracking happens in two stages: object detection and object association. Object detection is the process of identifying all potential objects of interest in the current frame using object detectors such as Faster-RCNN or YOLO. Object association is the process of linking objects detected in the current frame with its corresponding objects from previous frames, referred to as tracklets. Object or instance association is usually done by predicting the object’s location at the current frame based on previous frames’ tracklets using the Kalman Filter followed by one-to-one linear assignment typically using the Hungarian Algorithm to minimise the total differences between the matching results.</p>
<h2><span id="metrics">Metrics</span></h2><h3><span id="motp-multiple-object-tracking-precision">MOTP (Multiple Object Tracking Precision)</span></h3><p>MOTP (Multi-Object Tracking Precision) expresses how well exact positions of the object are estimated. It is the total error in estimated position for matched ground truth-hypothesis pairs over all frames, averaged by the total number of matches made. This metric is not responsible for recognizing object configurations and evaluating object trajectories.</p>
<h3><span id="mota-multiple-object-tracking-accuracy">MOTA (Multiple Object Tracking Accuracy)</span></h3><p>MOTA (Multi-Object Tracking Accuracy) shows how many errors the tracker system has made in terms of Misses, False Positives, Mismatch errors, etc. Therefore, it can be derived from three error ratios: the ratio of Misses, the ratio of False positives, and the ratio of Mismatches over all the frames.</p>
<h3><span id="idf1-score-idf1">IDF1 score (IDF1)</span></h3><p>IDF1 score (IDF1) is the ratio of correctly identified detections over the average of ground truth and predicted detections.</p>
<h2><span id="benchmarks">Benchmarks</span></h2><h3><span id="otb">OTB</span></h3><h3><span id="kitti">KITTI</span></h3><h3><span id="mot16">MOT16</span></h3><h2><span id="methodsmodels">Methods(models)</span></h2><h3><span id="iou-tracker">IOU tracker</span></h3><p>The Intersection-Over-Union (IOU) tracker uses the IOU values among the detector’s bounding boxes between the two consecutive frames to perform the association between them or assign a new target ID if no match found.</p>
<h3><span id="simple-online-and-realtime-tracking-sort">Simple Online And Realtime Tracking (SORT)</span></h3><p>Simple Online And Realtime Tracking (SORT) is a lean implementation of a tracking-by detection framework.SORT uses the position and size of the bounding boxes for both motion estimation and data association through frames. SORT combines location and motion cues by adopting a Kalman filter to predict the location of the tracklets in the new frame, then computes the IoU between the detection boxes and the predicted boxes as the similarity.</p>
<h3><span id="deepsort">DeepSORT</span></h3><p>DeepSORT replaces the association metric with a more informed metric that combines motion and appearance information. In particular, a “deep appearance” distance metric is added. The core idea is to obtain a vector that can be used to represent a given image. DeepSort adopts a stand-alone RE-ID model to extract appearance features from the detection boxes. After similarity computation matching strategy assigns identities to the objects. This can be done by the Hungarian Algorithm or greedy assignment.</p>
<h3><span id="fairmot">FairMOT</span></h3><p>FairMOT is a new tracking approach built on top of the anchor-free object detection architecture CenterNet.It has a simple network structure that consists of two homogeneous branches for detecting objects and extracting re-ID features.</p>
<h3><span id="transmot">TransMOT</span></h3><p>TransMOT is a new spatial-temporal graph Transformer that solves all these issues. It arranges the trajectories of all the tracked objects as a series of sparse weighted graphs that are constructed using the spatial relationships of the targets. TransMOT then uses these graphs to create a spatial graph transformer encoder layer, a temporal transformer encoder layer, and a spatial transformer decoder layer to model the spatial-temporal relationships of the objects.</p>
<h3><span id="bytetrack">ByteTrack</span></h3><p>BYTE is an effective association method that utilizes all detection boxes from high scores to low ones in the matching process.BYTE is built on the premise that the similarity with tracklets provides a strong cue to distinguish the objects and background in low score detection boxes. BYTE first matches the high score detection boxes to the tracklets based on motion similarity. It uses Kalman Filter to predict the location of the tracklets in the new frame. The motion similarity is computed by the IoU of the predicted box and the detection box. Then, it performs the second matching between the unmatched tracklets.</p>
<p>The primary innovation of BYTETrack is keeping non-background low confidence detection boxes which are typically discarded after the initial filtering of detections and use these low-score boxes for a secondary association step. Typically, occluded detection boxes have lower confidence scores than the threshold, but still contain some information about the objects which make their confidence score higher than purely background boxes. Hence, these low confidence boxes are still meaningful to keep track of during the association stage.</p>
<h3><span id="comparison-of-deepsort-and-bytetrack">Comparison of DeepSort and ByteTrack</span></h3><p>DeepSort uses a pre-trained object detection model to detect objects in each frame and a Siamese network to match the detected objects based on their appearance features. It also uses Kalman filters to predict the locations of the objects in the next frame. ByteTrack, on the other hand, uses a lightweight Siamese network architecture that takes in two input frames and outputs a similarity score. It also uses a simple but effective data augmentation technique to improve its performance on challenging datasets.</p>
<h2><span id="using-bytetrack">using ByteTrack</span></h2><p>ByteTracker initiates a new tracklet only if a detection is not matched with any previous tracklet and the bounding box score is higher than a threshold.  </p>
<h2><span id="references">references</span></h2><p><a target="_blank" rel="noopener" href="https://www.datature.io/blog/introduction-to-bytetrack-multi-object-tracking-by-associating-every-detection-box">https://www.datature.io/blog/introduction-to-bytetrack-multi-object-tracking-by-associating-every-detection-box</a><br><a target="_blank" rel="noopener" href="https://pub.towardsai.net/multi-object-tracking-metrics-1e602f364c0c">https://pub.towardsai.net/multi-object-tracking-metrics-1e602f364c0c</a><br><a target="_blank" rel="noopener" href="https://learnopencv.com/object-tracking-and-reidentification-with-fairmot/">https://learnopencv.com/object-tracking-and-reidentification-with-fairmot/</a><br><a target="_blank" rel="noopener" href="https://medium.com/augmented-startups/top-5-object-tracking-methods-92f1643f8435">https://medium.com/augmented-startups/top-5-object-tracking-methods-92f1643f8435</a><br><a target="_blank" rel="noopener" href="https://medium.com/@pedroazevedo6/object-tracking-state-of-the-art-2022-fe9457b77382">https://medium.com/@pedroazevedo6/object-tracking-state-of-the-art-2022-fe9457b77382</a></p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/computer-vision/">computer vision</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/08/10/opencv/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">opencv</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/07/20/Neural-Networks/"><span class="level-item">Neural Networks</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">s-serenity</a><p class="is-size-7"><span>&copy; 2023 s-serenity</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>